import{v as e,O as t,T as s}from"./vendor-JrpKAf2Q.js";import"./react-vendor-CQK77wC2.js";function n(e,t){e&&e(t)}function i(e){return e.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}const r=class{constructor(){let e=function(...t){return e._call(...t)};return Object.setPrototypeOf(e,new.target.prototype)}_call(...e){throw Error("Must implement _call method in subclass")}};function o(e){return Number.isInteger(e)||"bigint"==typeof e}function a(e){const t=[];let s=e;for(;Array.isArray(s);)t.push(s.length),s=s[0];return t}function l(e,t,s=void 0){const n=e[t];if(void 0!==n)return delete e[t],n;if(void 0===s)throw Error(`Key ${t} does not exist in object.`);return s}function c(...e){return Array.prototype.concat.apply([],e)}function d(...e){return e.reduce((e,t)=>e.flatMap(e=>t.map(t=>[e,t])))}function h(e,t){return Math.abs((e+t)%(2*t)-t)}const _={},u=Object.freeze(Object.defineProperty({__proto__:null,default:_},Symbol.toStringTag,{value:"Module"}));let p;const f=["wasm"];"undefined"!=typeof process&&"node"===process?.release?.name?(p=_??u,f.unshift("cpu")):(p=e??t,"undefined"!=typeof navigator&&/iP(hone|od|ad).+16_4.+AppleWebKit/.test(navigator.userAgent)&&(p.env.wasm.simd=!1));const{env:m}=p,g="2.17.2",w="undefined"!=typeof self&&"caches"in self,y=!S(_),x=!S(_),k=y&&x,b=k?_.dirname(_.dirname(_.fileURLToPath(import.meta.url))):"./",v=k?_.join(b,"/.cache/"):null,M="/models/",A=k?_.join(b,M):M;m?.wasm&&(m.wasm.wasmPaths=k?_.join(b,"/dist/"):`https://cdn.jsdelivr.net/npm/@xenova/transformers@${g}/dist/`);const z={backends:{onnx:m,tfjs:{}},__dirname:b,version:g,allowRemoteModels:!0,remoteHost:"https://huggingface.co/",remotePathTemplate:"{model}/resolve/{revision}/",allowLocalModels:!0,localModelPath:A,useFS:y,useBrowserCache:w,useFSCache:y,cacheDir:v,useCustomCache:!1,customCache:null};function S(e){return 0===Object.keys(e).length}var C={};class E{_CONTENT_TYPE_MAP={txt:"text/plain",html:"text/html",css:"text/css",js:"text/javascript",json:"application/json",png:"image/png",jpg:"image/jpeg",jpeg:"image/jpeg",gif:"image/gif"};constructor(e){if(this.filePath=e,this.headers=new Headers,this.exists=_.existsSync(e),this.exists){this.status=200,this.statusText="OK";let t=_.statSync(e);this.headers.set("content-length",t.size.toString()),this.updateContentType();let s=this;this.body=new ReadableStream({start(e){s.arrayBuffer().then(t=>{e.enqueue(new Uint8Array(t)),e.close()})}})}else this.status=404,this.statusText="Not Found",this.body=null}updateContentType(){const e=this.filePath.toString().split(".").pop().toLowerCase();this.headers.set("content-type",this._CONTENT_TYPE_MAP[e]??"application/octet-stream")}clone(){let e=new E(this.filePath);return e.exists=this.exists,e.status=this.status,e.statusText=this.statusText,e.headers=new Headers(this.headers),e}async arrayBuffer(){return(await _.promises.readFile(this.filePath)).buffer}async blob(){const e=await _.promises.readFile(this.filePath);return new Blob([e],{type:this.headers.get("content-type")})}async text(){return await _.promises.readFile(this.filePath,"utf8")}async json(){return JSON.parse(await this.text())}}function T(e,t=null,s=null){let n;try{n=new URL(e)}catch(i){return!1}return!(t&&!t.includes(n.protocol)||s&&!s.includes(n.hostname))}async function F(e){if(z.useFS&&!T(e,["http:","https:","blob:"]))return new E(e);if("undefined"!=typeof process&&"node"===process?.release?.name){const t=!!C?.TESTING_REMOTELY,s=z.version,n=new Headers;if(n.set("User-Agent",`transformers.js/${s}; is_ci/${t};`),T(e,["http:","https:"],["huggingface.co","hf.co"])){const e=C?.HF_TOKEN??C?.HF_ACCESS_TOKEN;e&&n.set("Authorization",`Bearer ${e}`)}return fetch(e,{headers:n})}return fetch(e)}const P={400:"Bad request error occurred while trying to load file",401:"Unauthorized access to file",403:"Forbidden access to file",404:"Could not locate file",408:"Request timeout error occurred while trying to load file",500:"Internal server error error occurred while trying to load file",502:"Bad gateway error occurred while trying to load file",503:"Service unavailable error occurred while trying to load file",504:"Gateway timeout error occurred while trying to load file"};class L{constructor(e){this.path=e}async match(e){let t=_.join(this.path,e),s=new E(t);return s.exists?s:void 0}async put(e,t){const s=Buffer.from(await t.arrayBuffer());let n=_.join(this.path,e);try{await _.promises.mkdir(_.dirname(n),{recursive:!0}),await _.promises.writeFile(n,s)}catch(i){}}}async function I(e,t,s=!0,i={}){if(!z.allowLocalModels){if(i.local_files_only)throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");if(!z.allowRemoteModels)throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.")}let r;if(n(i.progress_callback,{status:"initiate",name:e,file:t}),!r&&z.useBrowserCache){if("undefined"==typeof caches)throw Error("Browser cache is not available in this environment.");try{r=await caches.open("transformers-cache")}catch(w){}}if(!r&&z.useFSCache&&(r=new L(i.cache_dir??z.cacheDir)),!r&&z.useCustomCache){if(!z.customCache)throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");if(!z.customCache.match||!z.customCache.put)throw new Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache");r=z.customCache}const o=i.revision??"main";let a,l,c=O(e,t),d=O(z.localModelPath,c),h=O(z.remoteHost,z.remotePathTemplate.replaceAll("{model}",e).replaceAll("{revision}",encodeURIComponent(o)),t),_="main"===o?c:O(e,o,t),u=r instanceof L?_:h,p=!1;r&&(l=await async function(e,...t){for(let s of t)try{let t=await e.match(s);if(t)return t}catch(w){continue}}(r,d,u));const f=void 0!==l;if(void 0===l){if(z.allowLocalModels)if(T(c,["http:","https:"])){if(i.local_files_only)throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${c}.`);if(!z.allowRemoteModels)throw new Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${c}.`)}else try{l=await F(d),a=d}catch(w){}if(void 0===l||404===l.status){if(i.local_files_only||!z.allowRemoteModels){if(s)throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${d}".`);return null}if(l=await F(h),200!==l.status)return function(e,t,s){if(!s)return null;throw Error(`${P[e]??`Error (${e}) occurred while trying to load file`}: "${t}".`)}(l.status,h,s);a=u}p=r&&"undefined"!=typeof Response&&l instanceof Response&&200===l.status}n(i.progress_callback,{status:"download",name:e,file:t});const m={status:"progress",name:e,file:t};let g;return i.progress_callback?f&&"undefined"!=typeof navigator&&/firefox/i.test(navigator.userAgent)?(g=new Uint8Array(await l.arrayBuffer()),n(i.progress_callback,{...m,progress:100,loaded:g.length,total:g.length})):g=await async function(e){const t=e.headers.get("Content-Length");let s=parseInt(t??"0"),r=new Uint8Array(s),o=0;const a=e.body.getReader();return await async function e(){const{done:t,value:l}=await a.read();if(t)return;let c=o+l.length;if(c>s){s=c;let e=new Uint8Array(s);e.set(r),r=e}return r.set(l,o),o=c,(e=>{n(i.progress_callback,{...m,...e})})({progress:o/s*100,loaded:o,total:s}),e()}(),r}(l):g=new Uint8Array(await l.arrayBuffer()),p&&a&&void 0===await r.match(a)&&await r.put(a,new Response(g,{headers:l.headers})).catch(e=>{}),n(i.progress_callback,{status:"done",name:e,file:t}),g}async function B(e,t,s=!0,n={}){let i=await I(e,t,s,n);if(null===i)return{};let r=new TextDecoder("utf-8").decode(i);return JSON.parse(r)}function O(...e){return(e=e.map((t,s)=>(s&&(t=t.replace(new RegExp("^/"),"")),s!==e.length-1&&(t=t.replace(new RegExp("/$"),"")),t))).join("/")}function N(e,[t,s,n],[i,r],o="bilinear",a=!1){const l=r/n,c=i/s,d=new e.constructor(i*r*t),h=s*n,_=i*r;for(let u=0;u<i;++u)for(let i=0;i<r;++i){const o=u*r+i,a=(i+.5)/l-.5,p=(u+.5)/c-.5;let f=Math.floor(a),m=Math.floor(p);const g=Math.min(f+1,n-1),w=Math.min(m+1,s-1);f=Math.max(f,0),m=Math.max(m,0);const y=a-f,x=p-m,k=(1-y)*(1-x),b=y*(1-x),v=(1-y)*x,M=y*x,A=m*n,z=w*n,S=A+f,C=A+g,E=z+f,T=z+g;for(let s=0;s<t;++s){const t=s*h;d[s*_+o]=k*e[t+S]+b*e[t+C]+v*e[t+E]+M*e[t+T]}}return d}function j(e,t,s){const n=new Array(s.length),i=new Array(s.length);for(let a=s.length-1,l=1;a>=0;--a)i[a]=l,n[a]=t[s[a]],l*=n[a];const r=s.map((e,t)=>i[s.indexOf(t)]),o=new e.constructor(e.length);for(let a=0;a<e.length;++a){let s=0;for(let e=t.length-1,n=a;e>=0;--e)s+=n%t[e]*r[e],n=Math.floor(n/t[e]);o[s]=e[a]}return[o,n]}function $(e){const t=V(e)[0],s=e.map(e=>Math.exp(e-t)),n=s.reduce((e,t)=>e+t,0);return s.map(e=>e/n)}function D(e){return $(e).map(e=>Math.log(e))}function q(e,t){let s=0;for(let n=0;n<e.length;++n)s+=e[n]*t[n];return s}function R(e,t=0){return e=Array.from(e).map((e,t)=>[t,e]).sort((e,t)=>t[1]-e[1]),null!==t&&t>0&&(e=e.slice(0,t)),e}function U(e,t){return q(e,t)/(G(e)*G(t))}function G(e){return Math.sqrt(e.reduce((e,t)=>e+t*t,0))}function W(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],s=0;for(let n=1;n<e.length;++n)e[n]<t&&(t=e[n],s=n);return[t,s]}function V(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],s=0;for(let n=1;n<e.length;++n)e[n]>t&&(t=e[n],s=n);return[Number(t),s]}function X(e){return e>0&&!(e&e-1)}class K{constructor(e){if(this.size=0|e,this.size<=1||!X(this.size))throw new Error("FFT size must be a power of two larger than 1");this._csize=e<<1,this.table=new Float64Array(2*this.size);for(let s=0;s<this.table.length;s+=2){const e=Math.PI*s/this.size;this.table[s]=Math.cos(e),this.table[s+1]=-Math.sin(e)}let t=0;for(let s=1;this.size>s;s<<=1)++t;this._width=t%2==0?t-1:t,this._bitrev=new Int32Array(1<<this._width);for(let s=0;s<this._bitrev.length;++s){this._bitrev[s]=0;for(let e=0;e<this._width;e+=2){const t=this._width-e-2;this._bitrev[s]|=(s>>>e&3)<<t}}}createComplexArray(){return new Float64Array(this._csize)}fromComplexArray(e,t){const s=t||new Array(e.length>>>1);for(let n=0;n<e.length;n+=2)s[n>>>1]=e[n];return s}toComplexArray(e,t){const s=t||this.createComplexArray();for(let n=0;n<s.length;n+=2)s[n]=e[n>>>1],s[n+1]=0;return s}transform(e,t){if(e===t)throw new Error("Input and output buffers must be different");this._transform4(e,t,1)}realTransform(e,t){if(e===t)throw new Error("Input and output buffers must be different");this._realTransform4(e,t,1)}inverseTransform(e,t){if(e===t)throw new Error("Input and output buffers must be different");this._transform4(e,t,-1);for(let s=0;s<e.length;++s)e[s]/=this.size}_transform4(e,t,s){const n=this._csize;let i,r,o=1<<this._width,a=n/o<<1;const l=this._bitrev;if(4===a)for(i=0,r=0;i<n;i+=a,++r){const s=l[r];this._singleTransform2(t,e,i,s,o)}else for(i=0,r=0;i<n;i+=a,++r){const n=l[r];this._singleTransform4(t,e,i,n,o,s)}const c=this.table;for(o>>=2;o>=2;o>>=2){a=n/o<<1;const t=a>>>2;for(i=0;i<n;i+=a){const n=i+t-1;for(let r=i,a=0;r<n;r+=2,a+=o){const n=r,i=n+t,o=i+t,l=o+t,d=e[n],h=e[n+1],_=e[i],u=e[i+1],p=e[o],f=e[o+1],m=e[l],g=e[l+1],w=c[a],y=s*c[a+1],x=_*w-u*y,k=_*y+u*w,b=c[2*a],v=s*c[2*a+1],M=p*b-f*v,A=p*v+f*b,z=c[3*a],S=s*c[3*a+1],C=m*z-g*S,E=m*S+g*z,T=d+M,F=h+A,P=d-M,L=h-A,I=x+C,B=k+E,O=s*(x-C),N=s*(k-E);e[n]=T+I,e[n+1]=F+B,e[i]=P+N,e[i+1]=L-O,e[o]=T-I,e[o+1]=F-B,e[l]=P-N,e[l+1]=L+O}}}}_singleTransform2(e,t,s,n,i){const r=e[n],o=e[n+1],a=e[n+i],l=e[n+i+1];t[s]=r+a,t[s+1]=o+l,t[s+2]=r-a,t[s+3]=o-l}_singleTransform4(e,t,s,n,i,r){const o=2*i,a=3*i,l=e[n],c=e[n+1],d=e[n+i],h=e[n+i+1],_=e[n+o],u=e[n+o+1],p=e[n+a],f=e[n+a+1],m=l+_,g=c+u,w=l-_,y=c-u,x=d+p,k=h+f,b=r*(d-p),v=r*(h-f);t[s]=m+x,t[s+1]=g+k,t[s+2]=w+v,t[s+3]=y-b,t[s+4]=m-x,t[s+5]=g-k,t[s+6]=w-v,t[s+7]=y+b}_realTransform4(e,t,s){const n=this._csize;let i,r,o=1<<this._width,a=n/o<<1;const l=this._bitrev;if(4===a)for(i=0,r=0;i<n;i+=a,++r){const s=l[r];this._singleRealTransform2(t,e,i,s>>>1,o>>>1)}else for(i=0,r=0;i<n;i+=a,++r){const n=l[r];this._singleRealTransform4(t,e,i,n>>>1,o>>>1,s)}const c=this.table;for(o>>=2;o>=2;o>>=2){a=n/o<<1;const t=a>>>1,r=t>>>1,l=r>>>1;for(i=0;i<n;i+=a)for(let n=0,a=0;n<=l;n+=2,a+=o){const o=i+n,d=o+r,h=d+r,_=h+r,u=e[o],p=e[o+1],f=e[d],m=e[d+1],g=e[h],w=e[h+1],y=e[_],x=e[_+1],k=u,b=p,v=c[a],M=s*c[a+1],A=f*v-m*M,z=f*M+m*v,S=c[2*a],C=s*c[2*a+1],E=g*S-w*C,T=g*C+w*S,F=c[3*a],P=s*c[3*a+1],L=y*F-x*P,I=y*P+x*F,B=k+E,O=b+T,N=k-E,j=b-T,$=A+L,D=z+I,q=s*(A-L),R=s*(z-I);if(e[o]=B+$,e[o+1]=O+D,e[d]=N+R,e[d+1]=j-q,0===n){e[h]=B-$,e[h+1]=O-D;continue}if(n===l)continue;const U=i+r-n,G=i+t-n;e[U]=N-s*R,e[U+1]=-j-s*q,e[G]=B-s*$,e[G+1]=s*D-O}}const d=n>>>1;for(let h=2;h<d;h+=2)e[n-h]=e[h],e[n-h+1]=-e[h+1]}_singleRealTransform2(e,t,s,n,i){const r=e[n],o=e[n+i];t[s]=r+o,t[s+1]=0,t[s+2]=r-o,t[s+3]=0}_singleRealTransform4(e,t,s,n,i,r){const o=2*i,a=3*i,l=e[n],c=e[n+i],d=e[n+o],h=e[n+a],_=l+d,u=l-d,p=c+h,f=r*(c-h);t[s]=_+p,t[s+1]=0,t[s+2]=u,t[s+3]=-f,t[s+4]=_-p,t[s+5]=0,t[s+6]=u,t[s+7]=f}}class H{constructor(e){const t=2*(e-1),s=2*(2*e-1),n=2**Math.ceil(Math.log2(s));this.bufferSize=n,this._a=t;const i=new Float64Array(s),r=new Float64Array(n);this._chirpBuffer=new Float64Array(n),this._buffer1=new Float64Array(n),this._buffer2=new Float64Array(n),this._outBuffer1=new Float64Array(n),this._outBuffer2=new Float64Array(n);const o=-2*Math.PI/e,a=Math.cos(o),l=Math.sin(o);for(let c=0;c<s>>1;++c){const t=(c+1-e)**2/2,s=Math.sqrt(a**2+l**2)**t,n=t*Math.atan2(l,a),o=2*c;i[o]=s*Math.cos(n),i[o+1]=s*Math.sin(n),r[o]=i[o],r[o+1]=-i[o+1]}this._slicedChirpBuffer=i.subarray(t,s),this._f=new K(n>>1),this._f.transform(this._chirpBuffer,r)}_transform(e,t,s){const n=this._buffer1,i=this._buffer2,r=this._outBuffer1,o=this._outBuffer2,a=this._chirpBuffer,l=this._slicedChirpBuffer,c=this._a;if(s)for(let d=0;d<l.length;d+=2){const e=d+1,s=t[d>>1];n[d]=s*l[d],n[e]=s*l[e]}else for(let d=0;d<l.length;d+=2){const e=d+1;n[d]=t[d]*l[d]-t[e]*l[e],n[e]=t[d]*l[e]+t[e]*l[d]}this._f.transform(r,n);for(let d=0;d<a.length;d+=2){const e=d+1;i[d]=r[d]*a[d]-r[e]*a[e],i[e]=r[d]*a[e]+r[e]*a[d]}this._f.inverseTransform(o,i);for(let d=0;d<o.length;d+=2){const t=o[d+c],s=o[d+c+1],n=l[d],i=l[d+1];e[d]=t*n-s*i,e[d+1]=t*i+s*n}}transform(e,t){this._transform(e,t,!1)}realTransform(e,t){this._transform(e,t,!0)}}class Q{constructor(e){this.fft_length=e,this.isPowerOfTwo=X(e),this.isPowerOfTwo?(this.fft=new K(e),this.outputBufferSize=2*e):(this.fft=new H(e),this.outputBufferSize=this.fft.bufferSize)}realTransform(e,t){this.fft.realTransform(e,t)}transform(e,t){this.fft.transform(e,t)}}function Y(e,t){if(t%2==0||t<=0)throw new Error("Window size must be a positive odd number");const s=new e.constructor(e.length),n=new e.constructor(t),i=Math.floor(t/2);for(let r=0;r<e.length;++r){let t=0;for(let s=-i;s<=i;++s){let i=r+s;i<0?i=Math.abs(i):i>=e.length&&(i=2*(e.length-1)-i),n[t++]=e[i]}n.sort(),s[r]=n[i]}return s}function J(e,t){const s=Math.pow(10,t);return Math.round(e*s)/s}function Z(e){const t=Math.round(e);return Math.abs(e)%1==.5?t%2==0?t:t-1:t}const ee=Object.freeze({float32:Float32Array,float64:Float64Array,string:Array,int8:Int8Array,uint8:Uint8Array,int16:Int16Array,uint16:Uint16Array,int32:Int32Array,uint32:Uint32Array,int64:BigInt64Array,uint64:BigUint64Array,bool:Uint8Array}),te=p.Tensor;class se{dims;type;data;size;constructor(...e){return e[0]instanceof te?Object.assign(this,e[0]):Object.assign(this,new te(e[0],e[1],e[2])),new Proxy(this,{get:(e,t)=>{if("string"==typeof t){let s=Number(t);if(Number.isInteger(s))return e._getitem(s)}return e[t]},set:(e,t,s)=>e[t]=s})}*[Symbol.iterator](){const[e,...t]=this.dims;if(t.length>0){const s=t.reduce((e,t)=>e*t);for(let n=0;n<e;++n)yield this._subarray(n,s,t)}else yield*this.data}_getitem(e){const[t,...s]=this.dims;if(e=ce(e,t),s.length>0){const t=s.reduce((e,t)=>e*t);return this._subarray(e,t,s)}return new se(this.type,[this.data[e]],s)}indexOf(e){for(let t=0;t<this.data.length;++t)if(this.data[t]==e)return t;return-1}_subarray(e,t,s){const n=e*t,i=(e+1)*t,r="subarray"in this.data?this.data.subarray(n,i):this.data.slice(n,i);return new se(this.type,r,s)}item(){if(1!==this.data.length)throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`);return this.data[0]}tolist(){return function(e,t){const s=e.length;if(s!==t.reduce((e,t)=>e*t))throw Error(`cannot reshape array of size ${s} into shape (${t})`);let n=e;for(let i=t.length-1;i>=0;i--)n=n.reduce((e,s)=>{let n=e[e.length-1];return n.length<t[i]?n.push(s):e.push([s]),e},[[]]);return n[0]}(this.data,this.dims)}sigmoid(){return this.clone().sigmoid_()}sigmoid_(){for(let e=0;e<this.data.length;++e)this.data[e]=1/(1+Math.exp(-this.data[e]));return this}mul(e){return this.clone().mul_(e)}mul_(e){for(let t=0;t<this.data.length;++t)this.data[t]*=e;return this}add(e){return this.clone().add_(e)}add_(e){for(let t=0;t<this.data.length;++t)this.data[t]+=e;return this}clone(){return new se(this.type,this.data.slice(),this.dims.slice())}slice(...e){let t=[],s=[];for(let a=0;a<this.dims.length;++a){let n=e[a];if(null==n)s.push([0,this.dims[a]]),t.push(this.dims[a]);else if("number"==typeof n)n=ce(n,this.dims[a],a),s.push([n,n+1]);else{if(!Array.isArray(n)||2!==n.length)throw new Error(`Invalid slice: ${n}`);{if(n[0]>n[1])throw new Error(`Invalid slice: ${n}`);let e=[Math.max(n[0],0),Math.min(n[1],this.dims[a])];s.push(e),t.push(e[1]-e[0])}}}let n=s.map(([e,t])=>t-e),i=n.reduce((e,t)=>e*t),r=new this.data.constructor(i);const o=this.stride();for(let a=0;a<i;++a){let e=0;for(let t=n.length-1,i=a;t>=0;--t){const r=n[t];e+=(i%r+s[t][0])*o[t],i=Math.floor(i/r)}r[a]=this.data[e]}return new se(this.type,r,t)}permute(...e){return ne(this,e)}transpose(...e){return this.permute(...e)}sum(e=null,t=!1){return this.norm(1,e,t)}norm(e="fro",t=null,s=!1){if("fro"===e)e=2;else if("string"==typeof e)throw Error(`Unsupported norm: ${e}`);if(null===t){let t=this.data.reduce((t,s)=>t+s**e,0)**(1/e);return new se(this.type,[t],[])}t=ce(t,this.dims.length);const n=this.dims.slice();n[t]=1;const i=new this.data.constructor(this.data.length/this.dims[t]);for(let r=0;r<this.data.length;++r){let s=0;for(let e=this.dims.length-1,i=r,o=1;e>=0;--e){const r=this.dims[e];e!==t&&(s+=i%r*o,o*=n[e]),i=Math.floor(i/r)}i[s]+=this.data[r]**e}if(1!==e)for(let r=0;r<i.length;++r)i[r]=i[r]**(1/e);return s||n.splice(t,1),new se(this.type,i,n)}normalize_(e=2,t=1){t=ce(t,this.dims.length);const s=this.norm(e,t,!0);for(let n=0;n<this.data.length;++n){let e=0;for(let s=this.dims.length-1,i=n,r=1;s>=0;--s){const n=this.dims[s];s!==t&&(e+=i%n*r,r*=this.dims[s]),i=Math.floor(i/n)}this.data[n]/=s.data[e]}return this}normalize(e=2,t=1){return this.clone().normalize_(e,t)}stride(){return function(e){const t=new Array(e.length);for(let s=e.length-1,n=1;s>=0;--s)t[s]=n,n*=e[s];return t}(this.dims)}squeeze(e=null){return new se(this.type,this.data,ae(this.dims,e))}squeeze_(e=null){return this.dims=ae(this.dims,e),this}unsqueeze(e=null){return new se(this.type,this.data,le(this.dims,e))}unsqueeze_(e=null){return this.dims=le(this.dims,e),this}flatten_(e=0,t=-1){t=(t+this.dims.length)%this.dims.length;let s=this.dims.slice(0,e),n=this.dims.slice(e,t+1),i=this.dims.slice(t+1);return this.dims=[...s,n.reduce((e,t)=>e*t,1),...i],this}flatten(e=0,t=-1){return this.clone().flatten_(e,t)}view(...e){let t=-1;for(let s=0;s<e.length;++s)if(-1===e[s]){if(-1!==t)throw new Error("Only one dimension can be inferred");t=s}if(-1!==t){const s=e.reduce((e,s,n)=>n!==t?e*s:e,1);e[t]=this.data.length/s}return new se(this.type,this.data,e)}neg_(){for(let e=0;e<this.data.length;++e)this.data[e]=-this.data[e];return this}neg(){return this.clone().neg_()}clamp_(e,t){for(let s=0;s<this.data.length;++s)this.data[s]=Math.min(Math.max(this.data[s],e),t);return this}clamp(e,t){return this.clone().clamp_(e,t)}round_(){for(let e=0;e<this.data.length;++e)this.data[e]=Math.round(this.data[e]);return this}round(){return this.clone().round_()}to(e){if(this.type===e)return this;if(!ee.hasOwnProperty(e))throw new Error(`Unsupported type: ${e}`);return new se(e,ee[e].from(this.data),this.dims)}}function ne(e,t){const[s,n]=j(e.data,e.dims,t);return new se(e.type,s,n)}function ie(e,[t,s],n="bilinear",i=!1){const r=e.dims.at(-3)??1,o=e.dims.at(-2),a=e.dims.at(-1);let l=N(e.data,[r,o,a],[t,s],n,i);return new se(e.type,l,[r,t,s])}function re(e,t){let s=[e.dims[0],e.dims[2]],n=new e.data.constructor(s[0]*s[1]),[i,r,o]=e.dims,a=0;for(let l=0;l<i;++l){let s=l*o*r;for(let i=0;i<o;++i){let c=0,d=0,h=l*r,_=s+i;for(let s=0;s<r;++s){let n=Number(t.data[h+s]);d+=n,c+=e.data[_+s*o]*n}let u=c/d;n[a++]=u}}return new se(e.type,n,s)}function oe(e,t,{eps:s=1e-5}={}){if(2!==e.dims.length)throw new Error("`layer_norm` currently only supports 2D input.");const[n,i]=e.dims;if(1!==t.length&&t[0]!==i)throw new Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");const[r,o]=_e(e,1,0,!0),a=new e.data.constructor(e.data.length);for(let l=0;l<n;++l){const t=l*i;for(let n=0;n<i;++n){const i=t+n;a[i]=(e.data[i]-o.data[l])/(r.data[l]+s)}}return new se(e.type,a,e.dims)}function ae(e,t){return e=e.slice(),null===t?e=e.filter(e=>1!==e):"number"==typeof t?1===e[t]&&e.splice(t,1):Array.isArray(t)&&(e=e.filter((e,s)=>1!==e||!t.includes(s))),e}function le(e,t){return t=ce(t,e.length+1),(e=e.slice()).splice(t,0,1),e}function ce(e,t,s=null){if(e<-t||e>=t)throw new Error(`IndexError: index ${e} is out of bounds for dimension${null===s?"":" "+s} with size ${t}`);return e<0&&(e=(e%t+t)%t),e}function de(e,t=0){t=ce(t,e[0].dims.length);const s=e[0].dims.slice();s[t]=e.reduce((e,s)=>e+s.dims[t],0);const n=s.reduce((e,t)=>e*t,1),i=new e[0].data.constructor(n),r=e[0].type;if(0===t){let t=0;for(let s of e)i.set(s.data,t),t+=s.data.length}else{let n=0;for(let r=0;r<e.length;++r){let o=e[r];for(let e=0;e<o.data.length;++e){let r=0;for(let i=o.dims.length-1,a=e,l=1;i>=0;--i){const e=o.dims[i];let c=a%e;i===t&&(c+=n),r+=c*l,l*=s[i],a=Math.floor(a/e)}i[r]=o.data[e]}n+=o.dims[t]}}return new se(r,i,s)}function he(e,t=0){return de(e.map(e=>e.unsqueeze(t)),t)}function _e(e,t=null,s=1,n=!1){if(null===t){const t=e.data.reduce((e,t)=>e+t,0)/e.data.length,n=Math.sqrt(e.data.reduce((e,s)=>e+(s-t)**2,0)/(e.data.length-s)),i=new se(e.type,[t],[]);return[new se(e.type,[n],[]),i]}const i=ue(e,t=ce(t,e.dims.length),n),r=e.dims.slice();r[t]=1;const o=new e.data.constructor(e.data.length/e.dims[t]);for(let a=0;a<e.data.length;++a){let s=0;for(let n=e.dims.length-1,i=a,o=1;n>=0;--n){const a=e.dims[n];n!==t&&(s+=i%a*o,o*=r[n]),i=Math.floor(i/a)}o[s]+=(e.data[a]-i.data[s])**2}for(let a=0;a<o.length;++a)o[a]=Math.sqrt(o[a]/(e.dims[t]-s));return n||r.splice(t,1),[new se(e.type,o,r),i]}function ue(e,t=null,s=!1){if(null===t){let t=e.data.reduce((e,t)=>e+t,0);return new se(e.type,[t/e.data.length],[])}t=ce(t,e.dims.length);const n=e.dims.slice();n[t]=1;const i=new e.data.constructor(e.data.length/e.dims[t]);for(let r=0;r<e.data.length;++r){let s=0;for(let i=e.dims.length-1,o=r,a=1;i>=0;--i){const r=e.dims[i];i!==t&&(s+=o%r*a,a*=n[i]),o=Math.floor(o/r)}i[s]+=e.data[r]}if(1!==e.dims[t])for(let r=0;r<i.length;++r)i[r]=i[r]/e.dims[t];return s||n.splice(t,1),new se(e.type,i,n)}function pe(e){const[t,s]=e.dims,n=[t+1,s+1],i=new se("float32",new Float32Array(n[0]*n[1]).fill(1/0),n),r=new se("float32",new Float32Array(n[0]*n[1]).fill(-1),n);i[0].data[0]=0;for(let d=1;d<s+1;++d)for(let s=1;s<t+1;++s){const t=i[s-1][d-1].item(),n=i[s-1][d].item(),o=i[s][d-1].item();let a,l;t<n&&t<o?(a=t,l=0):n<t&&n<o?(a=n,l=1):(a=o,l=2),i[s].data[d]=e[s-1][d-1].item()+a,r[s].data[d]=l}let o=t,a=s;r.data.fill(2,0,n[1]);for(let d=0;d<n[0];++d)r[d].data[0]=1;let l=[],c=[];for(;o>0||a>0;)switch(l.push(o-1),c.push(a-1),r[o][a].item()){case 0:--o,--a;break;case 1:--o;break;case 2:--a;break;default:throw new Error(`Internal error in dynamic time warping. Unexpected trace[${o}, ${a}]. Please file a bug report.`)}return l.reverse(),c.reverse(),[l,c]}function fe(e){const t=e.reduce((e,t)=>e*t,1);return new se("int64",new BigInt64Array(t).fill(1n),e)}function me(e){return fe(e.dims)}function ge(e,t){if(2!==e.dims.length)throw new Error("The tensor must have 2 dimensions");if(e.dims.at(-1)%8!=0)throw new Error("The last dimension of the tensor must be a multiple of 8");if(!["binary","ubinary"].includes(t))throw new Error("The precision must be either 'binary' or 'ubinary'");const s="binary"===t,n=s?"int8":"uint8",i=s?Int8Array:Uint8Array,r=e.data,o=new i(r.length/8);for(let a=0;a<r.length;++a){const e=r[a]>0?1:0,t=Math.floor(a/8),n=a%8;o[t]|=e<<7-n,s&&0===n&&(o[t]-=128)}return new se(n,o,[e.dims[0],e.dims[1]/8])}class we{constructor(e=(e,t)=>e>t){this._heap=[],this._comparator=e}get size(){return this._heap.length}isEmpty(){return 0===this.size}peek(){return this._heap[0]}push(...e){return this.extend(e)}extend(e){for(const t of e)this._heap.push(t),this._siftUp();return this.size}pop(){const e=this.peek(),t=this.size-1;return t>0&&this._swap(0,t),this._heap.pop(),this._siftDown(),e}replace(e){const t=this.peek();return this._heap[0]=e,this._siftDown(),t}_parent(e){return(e+1>>>1)-1}_left(e){return 1+(e<<1)}_right(e){return e+1<<1}_greater(e,t){return this._comparator(this._heap[e],this._heap[t])}_swap(e,t){const s=this._heap[e];this._heap[e]=this._heap[t],this._heap[t]=s}_siftUp(){let e=this.size-1;for(;e>0&&this._greater(e,this._parent(e));)this._swap(e,this._parent(e)),e=this._parent(e)}_siftDown(){let e=0;for(;this._left(e)<this.size&&this._greater(this._left(e),e)||this._right(e)<this.size&&this._greater(this._right(e),e);){const t=this._right(e)<this.size&&this._greater(this._right(e),this._left(e))?this._right(e):this._left(e);this._swap(e,t),e=t}}}class ye{constructor(){this.root=xe.default()}extend(e){for(let t of e)this.push(t)}push(e){let t=this.root;for(let s of e){let e=t.children.get(s);void 0===e&&(e=xe.default(),t.children.set(s,e)),t=e}t.isLeaf=!0}*commonPrefixSearch(e){let t=this.root,s="";for(let n=0;n<e.length&&void 0!==t;++n){const i=e[n];s+=i,t=t.children.get(i),void 0!==t&&t.isLeaf&&(yield s)}}}class xe{constructor(e,t){this.isLeaf=e,this.children=t}static default(){return new xe(!1,new Map)}}class ke{constructor(e,t,s){this.sentence=e,this.len=e.length,this.bosTokenId=t,this.eosTokenId=s,this.nodes=[],this.beginNodes=Array.from({length:this.len+1},()=>[]),this.endNodes=Array.from({length:this.len+1},()=>[]);const n=new be(this.bosTokenId,0,0,0,0),i=new be(this.eosTokenId,1,this.len,0,0);this.nodes.push(n.clone()),this.nodes.push(i.clone()),this.beginNodes[this.len].push(i),this.endNodes[0].push(n)}insert(e,t,s,n){const i=this.nodes.length,r=new be(n,i,e,t,s);this.beginNodes[e].push(r),this.endNodes[e+t].push(r),this.nodes.push(r)}viterbi(){const e=this.len;let t=0;for(;t<=e;){if(0==this.beginNodes[t].length)return[];for(let e of this.beginNodes[t]){e.prev=null;let s=0,n=null;for(let i of this.endNodes[t]){const t=i.backtraceScore+e.score;(null===n||t>s)&&(n=i.clone(),s=t)}if(null===n)return[];e.prev=n,e.backtraceScore=s}++t}const s=[],n=this.beginNodes[e][0].prev;if(null===n)return[];let i=n.clone();for(;null!==i.prev;){s.push(i.clone());const e=i.clone();i=e.prev.clone()}return s.reverse(),s}piece(e){return this.sentence.slice(e.pos,e.pos+e.length)}tokens(){return this.viterbi().map(e=>this.piece(e))}tokenIds(){return this.viterbi().map(e=>e.tokenId)}}class be{constructor(e,t,s,n,i){this.tokenId=e,this.nodeId=t,this.pos=s,this.length=n,this.score=i,this.prev=null,this.backtraceScore=0}clone(){const e=new be(this.tokenId,this.nodeId,this.pos,this.length,this.score);return e.prev=this.prev,e.backtraceScore=this.backtraceScore,e}}async function ve(e,t){const s=await Promise.all([B(e,"tokenizer.json",!0,t),B(e,"tokenizer_config.json",!0,t)]);return null!==t.legacy&&(s[1].legacy=t.legacy),s}function Me(e,t=!0){if(void 0!==e.Regex){let t=e.Regex.replace(/\\([#&~])/g,"$1");for(const[e,s]of Te)t=t.replaceAll(e,s);return new RegExp(t,"gu")}if(void 0!==e.String){const s=i(e.String);return new RegExp(t?s:`(${s})`,"gu")}return null}function Ae(e){return new Map(Object.entries(e))}function ze(e){const t=e.dims;switch(t.length){case 1:return e.tolist();case 2:if(1!==t[0])throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");return e.tolist()[0];default:throw new Error(`Expected tensor to have 1-2 dimensions, got ${t.length}.`)}}function Se(e){return e.replace(/ \./g,".").replace(/ \?/g,"?").replace(/ \!/g,"!").replace(/ ,/g,",").replace(/ \' /g,"'").replace(/ n\'t/g,"n't").replace(/ \'m/g,"'m").replace(/ \'s/g,"'s").replace(/ \'ve/g,"'ve").replace(/ \'re/g,"'re")}function Ce(e){return e.replace(/[\u0300-\u036f]/g,"")}const Ee="\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E",Te=new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)","(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"]]);class Fe{constructor(e){this.content=e.content,this.id=e.id,this.single_word=e.single_word??!1,this.lstrip=e.lstrip??!1,this.rstrip=e.rstrip??!1,this.special=e.special??!1,this.normalized=e.normalized??null}}class Pe extends r{constructor(e){super(),this.config=e,this.vocab=[],this.tokens_to_ids=new Map,this.unk_token_id=void 0,this.unk_token=void 0,this.end_of_word_suffix=void 0,this.fuse_unk=this.config.fuse_unk??!1}static fromConfig(e,...t){switch(e.type){case"WordPiece":return new Le(e);case"Unigram":return new Ie(e,...t);case"BPE":return new je(e);default:if(e.vocab)return new $e(e,...t);throw new Error(`Unknown TokenizerModel type: ${e.type}`)}}_call(e){let t=this.encode(e);return this.fuse_unk&&(t=function(e,t,s){const n=[];let i=0;for(;i<e.length;)if(n.push(e[i]),(s.get(e[i])??t)===t)for(;i<e.length&&(s.get(e[i])??t)===t;)++i;else++i;return n}(t,this.unk_token_id,this.tokens_to_ids)),t}encode(e){throw Error("encode should be implemented in subclass.")}convert_tokens_to_ids(e){return e.map(e=>this.tokens_to_ids.get(e)??this.unk_token_id)}convert_ids_to_tokens(e){return e.map(e=>this.vocab[e]??this.unk_token)}}class Le extends Pe{constructor(e){super(e),this.tokens_to_ids=Ae(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.max_input_chars_per_word=e.max_input_chars_per_word??100,this.vocab=new Array(this.tokens_to_ids.size);for(const[t,s]of this.tokens_to_ids)this.vocab[s]=t}encode(e){const t=[];for(const s of e){const e=[...s];if(e.length>this.max_input_chars_per_word){t.push(this.unk_token);continue}let n=!1,i=0;const r=[];for(;i<e.length;){let t=e.length,s=null;for(;i<t;){let n=e.slice(i,t).join("");if(i>0&&(n=this.config.continuing_subword_prefix+n),this.tokens_to_ids.has(n)){s=n;break}--t}if(null===s){n=!0;break}r.push(s),i=t}n?t.push(this.unk_token):t.push(...r)}return t}}class Ie extends Pe{constructor(e,t){super(e);const s=e.vocab.length;this.vocab=new Array(s),this.scores=new Array(s);for(let n=0;n<s;++n){const t=e.vocab[n];this.vocab[n]=t[0],this.scores[n]=t[1]}this.unk_token_id=e.unk_id,this.unk_token=this.vocab[e.unk_id],this.tokens_to_ids=new Map(this.vocab.map((e,t)=>[e,t])),this.bosToken=" ",this.bosTokenId=this.tokens_to_ids.get(this.bosToken),this.eosToken=t.eos_token,this.eosTokenId=this.tokens_to_ids.get(this.eosToken),this.unkToken=this.vocab[this.unk_token_id],this.minScore=W(this.scores)[0],this.unkScore=this.minScore-10,this.scores[this.unk_token_id]=this.unkScore,this.trie=new ye,this.trie.extend(this.vocab),this.fuse_unk=!0}populateNodes(e){const t=e.sentence,s=t.length;let n=0;for(;n<s;){const s=1;let i=!1;for(let r of this.trie.commonPrefixSearch(t.slice(n))){const t=this.tokens_to_ids.get(r),o=this.scores[t],a=r.length;e.insert(n,a,o,t),i||a!==s||(i=!0)}i||e.insert(n,s,this.unkScore,this.unk_token_id),n+=s}}tokenize(e){const t=new ke(e,this.bosTokenId,this.eosTokenId);return this.populateNodes(t),t.tokens()}encode(e){const t=[];for(const s of e){const e=this.tokenize(s);t.push(...e)}return t}}const Be=(()=>{const e=[...Array.from({length:"~".charCodeAt(0)-"!".charCodeAt(0)+1},(e,t)=>t+"!".charCodeAt(0)),...Array.from({length:"¬".charCodeAt(0)-"¡".charCodeAt(0)+1},(e,t)=>t+"¡".charCodeAt(0)),...Array.from({length:"ÿ".charCodeAt(0)-"®".charCodeAt(0)+1},(e,t)=>t+"®".charCodeAt(0))],t=e.slice();let s=0;for(let i=0;i<256;++i)e.includes(i)||(e.push(i),t.push(256+s),s+=1);const n=t.map(e=>String.fromCharCode(e));return Object.fromEntries(e.map((e,t)=>[e,n[t]]))})(),Oe=(Ne=Be,Object.fromEntries(Object.entries(Ne).map(([e,t])=>[t,e])));var Ne;class je extends Pe{constructor(e){super(e),this.BPE_SPLIT_TOKEN=" ",this.tokens_to_ids=Ae(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.vocab=new Array(this.tokens_to_ids.size);for(const[t,s]of this.tokens_to_ids)this.vocab[s]=t;this.bpe_ranks=new Map(e.merges.map((e,t)=>[e,t])),this.merges=e.merges.map(e=>e.split(this.BPE_SPLIT_TOKEN)),this.end_of_word_suffix=e.end_of_word_suffix,this.continuing_subword_suffix=e.continuing_subword_suffix??null,this.byte_fallback=this.config.byte_fallback??!1,this.byte_fallback&&(this.text_encoder=new TextEncoder),this.ignore_merges=this.config.ignore_merges??!1,this.cache=new Map}bpe(e){if(0===e.length)return[];const t=this.cache.get(e);if(void 0!==t)return t;const s=Array.from(e);this.end_of_word_suffix&&(s[s.length-1]+=this.end_of_word_suffix);let n=[];if(s.length>1){const e=new we((e,t)=>e.score<t.score);let t={token:s[0],bias:0,prev:null,next:null},i=t;for(let n=1;n<s.length;++n){const t={bias:n/s.length,token:s[n],prev:i,next:null};i.next=t,this._add_node(e,i),i=t}for(;!e.isEmpty();){const s=e.pop();if(s.deleted||!s.next||s.next.deleted)continue;if(s.deleted=!0,s.next.deleted=!0,s.prev){const e={...s.prev};s.prev.deleted=!0,s.prev=e,e.prev?e.prev.next=e:t=e}const n={token:s.token+s.next.token,bias:s.bias,prev:s.prev,next:s.next.next};n.prev?(n.prev.next=n,this._add_node(e,n.prev)):t=n,n.next&&(n.next.prev=n,this._add_node(e,n))}for(let s=t;null!==s;s=s.next)n.push(s.token)}else n=s;if(this.continuing_subword_suffix)for(let i=0;i<n.length-1;++i)n[i]+=this.continuing_subword_suffix;return this.cache.set(e,n),n}_add_node(e,t){const s=this.bpe_ranks.get(t.token+this.BPE_SPLIT_TOKEN+t.next.token);void 0!==s&&(t.score=s+t.bias,e.push(t))}encode(e){const t=[];for(const s of e){if(this.ignore_merges&&this.tokens_to_ids.has(s)){t.push(s);continue}const e=this.bpe(s);for(const s of e)this.tokens_to_ids.has(s)?t.push(s):this.byte_fallback?t.push(...Array.from(this.text_encoder.encode(s)).map(e=>`<0x${e.toString(16).toUpperCase().padStart(2,"0")}>`)):t.push(this.unk_token)}return t}}class $e extends Pe{constructor(e,t){super(e),this.tokens_to_ids=Ae(t.target_lang?e.vocab[t.target_lang]:e.vocab),this.bos_token=t.bos_token,this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.pad_token=t.pad_token,this.pad_token_id=this.tokens_to_ids.get(this.pad_token),this.unk_token=t.unk_token,this.unk_token_id=this.tokens_to_ids.get(this.unk_token),this.vocab=new Array(this.tokens_to_ids.size);for(const[s,n]of this.tokens_to_ids)this.vocab[n]=s}encode(e){return e}}class De extends r{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"BertNormalizer":return new Qe(e);case"Precompiled":return new bt(e);case"Sequence":return new He(e);case"Replace":return new qe(e);case"NFC":return new Re(e);case"NFKC":return new Ue(e);case"NFKD":return new Ge(e);case"Strip":return new We(e);case"StripAccents":return new Ve(e);case"Lowercase":return new Xe(e);case"Prepend":return new Ke(e);default:throw new Error(`Unknown Normalizer type: ${e.type}`)}}normalize(e){throw Error("normalize should be implemented in subclass.")}_call(e){return this.normalize(e)}}class qe extends De{normalize(e){const t=Me(this.config.pattern);return null===t?e:e.replaceAll(t,this.config.content)}}class Re extends De{normalize(e){return e.normalize("NFC")}}class Ue extends De{normalize(e){return e.normalize("NFKC")}}class Ge extends De{normalize(e){return e.normalize("NFKD")}}class We extends De{normalize(e){return this.config.strip_left&&this.config.strip_right?e=e.trim():(this.config.strip_left&&(e=e.trimStart()),this.config.strip_right&&(e=e.trimEnd())),e}}class Ve extends De{normalize(e){return Ce(e)}}class Xe extends De{normalize(e){return e.toLowerCase()}}class Ke extends De{normalize(e){return this.config.prepend+e}}class He extends De{constructor(e){super(e),this.normalizers=e.normalizers.map(e=>De.fromConfig(e))}normalize(e){return this.normalizers.reduce((e,t)=>t.normalize(e),e)}}class Qe extends De{_tokenize_chinese_chars(e){const t=[];for(let s=0;s<e.length;++s){const n=e[s],i=n.charCodeAt(0);this._is_chinese_char(i)?(t.push(" "),t.push(n),t.push(" ")):t.push(n)}return t.join("")}_is_chinese_char(e){return e>=19968&&e<=40959||e>=13312&&e<=19903||e>=131072&&e<=173791||e>=173824&&e<=177983||e>=177984&&e<=178207||e>=178208&&e<=183983||e>=63744&&e<=64255||e>=194560&&e<=195103}stripAccents(e){return e.normalize("NFD").replace(/[\u0300-\u036f]/g,"")}_is_control(e){switch(e){case"\t":case"\n":case"\r":return!1;default:return/^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(e)}}_clean_text(e){const t=[];for(const s of e){const e=s.charCodeAt(0);0===e||65533===e||this._is_control(s)||(/^\s$/.test(s)?t.push(" "):t.push(s))}return t.join("")}normalize(e){return this.config.clean_text&&(e=this._clean_text(e)),this.config.handle_chinese_chars&&(e=this._tokenize_chinese_chars(e)),this.config.lowercase?(e=e.toLowerCase(),!1!==this.config.strip_accents&&(e=this.stripAccents(e))):this.config.strip_accents&&(e=this.stripAccents(e)),e}}class Ye extends r{static fromConfig(e){if(null===e)return null;switch(e.type){case"BertPreTokenizer":return new Je(e);case"Sequence":return new vt(e);case"Whitespace":return new Mt(e);case"WhitespaceSplit":return new At(e);case"Metaspace":return new xt(e);case"ByteLevel":return new Ze(e);case"Split":return new et(e);case"Punctuation":return new tt(e);case"Digits":return new st(e);case"Replace":return new zt(e);default:throw new Error(`Unknown PreTokenizer type: ${e.type}`)}}pre_tokenize_text(e,t){throw Error("pre_tokenize_text should be implemented in subclass.")}pre_tokenize(e,t){return(Array.isArray(e)?e.map(e=>this.pre_tokenize_text(e,t)):this.pre_tokenize_text(e,t)).flat()}_call(e,t){return this.pre_tokenize(e,t)}}class Je extends Ye{constructor(e){super(),this.pattern=new RegExp(`[^\\s${Ee}]+|[${Ee}]`,"gu")}pre_tokenize_text(e,t){return e.trim().match(this.pattern)||[]}}class Ze extends Ye{constructor(e){super(),this.config=e,this.add_prefix_space=this.config.add_prefix_space,this.trim_offsets=this.config.trim_offsets,this.use_regex=this.config.use_regex??!0,this.pattern=/'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu,this.byte_encoder=Be,this.text_encoder=new TextEncoder}pre_tokenize_text(e,t){return this.add_prefix_space&&!e.startsWith(" ")&&(e=" "+e),(this.use_regex?e.match(this.pattern)||[]:[e]).map(e=>Array.from(this.text_encoder.encode(e),e=>this.byte_encoder[e]).join(""))}}class et extends Ye{constructor(e){super(),this.config=e,this.pattern=Me(this.config.pattern,this.config.invert)}pre_tokenize_text(e,t){return null===this.pattern?[]:this.config.invert?e.match(this.pattern)||[]:function(e,t){const s=[];let n=0;for(const i of e.matchAll(t)){const t=i[0];n<i.index&&s.push(e.slice(n,i.index)),t.length>0&&s.push(t),n=i.index+t.length}return n<e.length&&s.push(e.slice(n)),s}(e,this.pattern)}}class tt extends Ye{constructor(e){super(),this.config=e,this.pattern=new RegExp(`[^${Ee}]+|[${Ee}]+`,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class st extends Ye{constructor(e){super(),this.config=e;const t="[^\\d]+|\\d"+(this.config.individual_digits?"":"+");this.pattern=new RegExp(t,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class nt extends r{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"TemplateProcessing":return new ot(e);case"ByteLevel":return new at(e);case"RobertaProcessing":return new rt(e);case"BertProcessing":return new it(e);case"Sequence":return new lt(e);default:throw new Error(`Unknown PostProcessor type: ${e.type}`)}}post_process(e,...t){throw Error("post_process should be implemented in subclass.")}_call(e,...t){return this.post_process(e,...t)}}class it extends nt{constructor(e){super(e),this.cls=e.cls[0],this.sep=e.sep[0]}post_process(e,t=null,{add_special_tokens:s=!0}={}){s&&(e=c([this.cls],e,[this.sep]));let n=new Array(e.length).fill(0);if(null!==t){const i=s&&this instanceof rt?[this.sep]:[],r=s?[this.sep]:[];e=c(e,i,t,r),n=c(n,new Array(t.length+i.length+r.length).fill(1))}return{tokens:e,token_type_ids:n}}}class rt extends it{}class ot extends nt{constructor(e){super(e),this.single=e.single,this.pair=e.pair}post_process(e,t=null,{add_special_tokens:s=!0}={}){const n=null===t?this.single:this.pair;let i=[],r=[];for(const o of n)"SpecialToken"in o?s&&(i.push(o.SpecialToken.id),r.push(o.SpecialToken.type_id)):"Sequence"in o&&("A"===o.Sequence.id?(i=c(i,e),r=c(r,new Array(e.length).fill(o.Sequence.type_id))):"B"===o.Sequence.id&&(i=c(i,t),r=c(r,new Array(t.length).fill(o.Sequence.type_id))));return{tokens:i,token_type_ids:r}}}class at extends nt{post_process(e,t=null){return t&&(e=c(e,t)),{tokens:e}}}class lt extends nt{constructor(e){super(e),this.processors=e.processors.map(e=>nt.fromConfig(e))}post_process(e,t=null,s={}){let n;for(const i of this.processors)if(i instanceof at)e=i.post_process(e).tokens,t&&(t=i.post_process(t).tokens);else{const r=i.post_process(e,t,s);e=r.tokens,n=r.token_type_ids}return{tokens:e,token_type_ids:n}}}class ct extends r{constructor(e){super(),this.config=e,this.added_tokens=[],this.end_of_word_suffix=null,this.trim_offsets=e.trim_offsets}static fromConfig(e){if(null===e)return null;switch(e.type){case"WordPiece":return new pt(e);case"Metaspace":return new kt(e);case"ByteLevel":return new ft(e);case"Replace":return new dt(e);case"ByteFallback":return new ht(e);case"Fuse":return new _t(e);case"Strip":return new ut(e);case"Sequence":return new gt(e);case"CTC":return new mt(e);case"BPEDecoder":return new wt(e);default:throw new Error(`Unknown Decoder type: ${e.type}`)}}_call(e){return this.decode(e)}decode(e){return this.decode_chain(e).join("")}decode_chain(e){throw Error("`decode_chain` should be implemented in subclass.")}}class dt extends ct{decode_chain(e){const t=Me(this.config.pattern);return null===t?e:e.map(e=>e.replaceAll(t,this.config.content))}}class ht extends ct{constructor(e){super(e),this.text_decoder=new TextDecoder}decode_chain(e){const t=[];let s=[];for(const n of e){let e=null;if(6===n.length&&n.startsWith("<0x")&&n.endsWith(">")){const t=parseInt(n.slice(3,5),16);isNaN(t)||(e=t)}if(null!==e)s.push(e);else{if(s.length>0){const e=this.text_decoder.decode(Uint8Array.from(s));t.push(e),s=[]}t.push(n)}}if(s.length>0){const e=this.text_decoder.decode(Uint8Array.from(s));t.push(e),s=[]}return t}}class _t extends ct{decode_chain(e){return[e.join("")]}}class ut extends ct{constructor(e){super(e),this.content=this.config.content,this.start=this.config.start,this.stop=this.config.stop}decode_chain(e){return e.map(e=>{let t=0;for(let n=0;n<this.start&&e[n]===this.content;++n)t=n+1;let s=e.length;for(let n=0;n<this.stop;++n){const t=e.length-n-1;if(e[t]!==this.content)break;s=t}return e.slice(t,s)})}}class pt extends ct{constructor(e){super(e),this.cleanup=e.cleanup}decode_chain(e){return e.map((e,t)=>(0!==t&&(e=e.startsWith(this.config.prefix)?e.replace(this.config.prefix,""):" "+e),this.cleanup&&(e=Se(e)),e))}}class ft extends ct{constructor(e){super(e),this.byte_decoder=Oe,this.text_decoder=new TextDecoder("utf-8",{fatal:!1,ignoreBOM:!0}),this.end_of_word_suffix=null}convert_tokens_to_string(e){const t=e.join(""),s=new Uint8Array([...t].map(e=>this.byte_decoder[e]));return this.text_decoder.decode(s)}decode_chain(e){const t=[];let s=[];for(const n of e)void 0!==this.added_tokens.find(e=>e.content===n)?(s.length>0&&(t.push(this.convert_tokens_to_string(s)),s=[]),t.push(n)):s.push(n);return s.length>0&&t.push(this.convert_tokens_to_string(s)),t}}class mt extends ct{constructor(e){super(e),this.pad_token=this.config.pad_token,this.word_delimiter_token=this.config.word_delimiter_token,this.cleanup=this.config.cleanup}convert_tokens_to_string(e){if(0===e.length)return"";const t=[e[0]];for(let n=1;n<e.length;++n)e[n]!==t.at(-1)&&t.push(e[n]);let s=t.filter(e=>e!==this.pad_token).join("");return this.cleanup&&(s=Se(s).replaceAll(this.word_delimiter_token," ").trim()),s}decode_chain(e){return[this.convert_tokens_to_string(e)]}}class gt extends ct{constructor(e){super(e),this.decoders=e.decoders.map(e=>ct.fromConfig(e))}decode_chain(e){return this.decoders.reduce((e,t)=>t.decode_chain(e),e)}}class wt extends ct{constructor(e){super(e),this.suffix=this.config.suffix}decode_chain(e){return e.map((t,s)=>t.replaceAll(this.suffix,s===e.length-1?"":" "))}}class yt extends ct{decode_chain(e){let t="";for(let s=1;s<e.length;s+=2)t+=e[s];return[t]}}class xt extends Ye{constructor(e){super(),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement,this.strRep=e.str_rep||this.replacement,this.prepend_scheme=e.prepend_scheme??"always"}pre_tokenize_text(e,{section_index:t}={}){let s=e.replaceAll(" ",this.strRep);return this.addPrefixSpace&&!s.startsWith(this.replacement)&&("always"===this.prepend_scheme||"first"===this.prepend_scheme&&0===t)&&(s=this.strRep+s),[s]}}class kt extends ct{constructor(e){super(e),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement}decode_chain(e){const t=[];for(let s=0;s<e.length;++s){let n=e[s].replaceAll(this.replacement," ");this.addPrefixSpace&&0==s&&n.startsWith(" ")&&(n=n.substring(1)),t.push(n)}return t}}class bt extends De{constructor(e){super(e),this.charsmap=e.precompiled_charsmap}normalize(e){if((e=(e=e.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm,"")).replace(/[\u0009\u000A\u000C\u000D\u1680\u200B\u200C\u200E\u200F\u2028\u2029\u2581\uFEFF\uFFFD]/gm," ")).includes("～")){const t=e.split("～");e=t.map(e=>e.normalize("NFKC")).join("～")}else e=e.normalize("NFKC");return e}}class vt extends Ye{constructor(e){super(),this.tokenizers=e.pretokenizers.map(e=>Ye.fromConfig(e))}pre_tokenize_text(e,t){return this.tokenizers.reduce((e,s)=>s.pre_tokenize(e,t),[e])}}class Mt extends Ye{constructor(e){super()}pre_tokenize_text(e,t){return e.match(/\w+|[^\w\s]+/g)||[]}}class At extends Ye{constructor(e){super()}pre_tokenize_text(e,t){return function(e){return e.match(/\S+/g)||[]}(e)}}class zt extends Ye{constructor(e){super(),this.config=e,this.pattern=Me(this.config.pattern),this.content=this.config.content}pre_tokenize_text(e,t){return null===this.pattern?[e]:[e.replaceAll(this.pattern,this.config.content)]}}const St=["bos_token","eos_token","unk_token","sep_token","pad_token","cls_token","mask_token"];function Ct(e,t,s,n){for(const i of Object.keys(e)){const r=t-e[i].length,o=s(i),a=new Array(r).fill(o);e[i]="right"===n?c(e[i],a):c(a,e[i])}}function Et(e,t){for(const s of Object.keys(e))e[s].length=t}class Tt extends r{return_token_type_ids=!1;_default_chat_template="{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}";constructor(e,t){super(),this._tokenizer_config=t,this.normalizer=De.fromConfig(e.normalizer),this.pre_tokenizer=Ye.fromConfig(e.pre_tokenizer),this.model=Pe.fromConfig(e.model,t),this.post_processor=nt.fromConfig(e.post_processor),this.decoder=ct.fromConfig(e.decoder),this.special_tokens=[],this.all_special_ids=[],this.added_tokens=[];for(const s of e.added_tokens){const e=new Fe(s);this.added_tokens.push(e),this.model.tokens_to_ids.set(e.content,e.id),this.model.vocab[e.id]=e.content,e.special&&(this.special_tokens.push(e.content),this.all_special_ids.push(e.id))}if(this.additional_special_tokens=t.additional_special_tokens??[],this.special_tokens.push(...this.additional_special_tokens),this.special_tokens=[...new Set(this.special_tokens)],this.decoder&&(this.decoder.added_tokens=this.added_tokens,this.decoder.end_of_word_suffix=this.model.end_of_word_suffix),this.added_tokens_regex=this.added_tokens.length>0?new RegExp(this.added_tokens.map(e=>`${e.lstrip?"\\s*":""}(${i(e.content)})${e.rstrip?"\\s*":""}`).join("|")):null,this.mask_token=this.getToken("mask_token"),this.mask_token_id=this.model.tokens_to_ids.get(this.mask_token),this.pad_token=this.getToken("pad_token","eos_token"),this.pad_token_id=this.model.tokens_to_ids.get(this.pad_token),this.sep_token=this.getToken("sep_token"),this.sep_token_id=this.model.tokens_to_ids.get(this.sep_token),this.unk_token=this.getToken("unk_token"),this.unk_token_id=this.model.tokens_to_ids.get(this.unk_token),this.model_max_length=t.model_max_length,this.remove_space=t.remove_space,this.clean_up_tokenization_spaces=t.clean_up_tokenization_spaces??!0,this.do_lowercase_and_remove_accent=t.do_lowercase_and_remove_accent??!1,this.padding_side="right",this.legacy=!1,this.chat_template=t.chat_template??null,Array.isArray(this.chat_template)){const e=Object.create(null);for(const{name:t,template:s}of this.chat_template){if("string"!=typeof t||"string"!=typeof s)throw new Error('Chat template must be a list of objects with "name" and "template" properties');e[t]=s}this.chat_template=e}this._compiled_template_cache=new Map}getToken(...e){for(const t of e){const e=this._tokenizer_config[t];if(e){if("object"==typeof e){if("AddedToken"===e.__type)return e.content;throw Error(`Unknown token: ${e}`)}return e}}return null}static async from_pretrained(e,{progress_callback:t=null,config:s=null,cache_dir:n=null,local_files_only:i=!1,revision:r="main",legacy:o=null}={}){return new this(...await ve(e,{progress_callback:t,cache_dir:n,local_files_only:i,revision:r,legacy:o}))}_call(e,{text_pair:t=null,add_special_tokens:s=!0,padding:n=!1,truncation:i=null,max_length:r=null,return_tensor:o=!0,return_token_type_ids:a=null}={}){const l=Array.isArray(e);let c;if(l){if(0===e.length)throw Error("text array must be non-empty");if(null!==t){if(!Array.isArray(t))throw Error("text_pair must also be an array");if(e.length!==t.length)throw Error("text and text_pair must have the same length");c=e.map((e,n)=>this._encode_plus(e,t[n],{add_special_tokens:s,return_token_type_ids:a}))}else c=e.map(e=>this._encode_plus(e,null,{add_special_tokens:s,return_token_type_ids:a}))}else{if(null==e)throw Error("text may not be null or undefined");if(Array.isArray(t))throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");c=[this._encode_plus(e,t,{add_special_tokens:s,return_token_type_ids:a})]}if(null===r&&(r="max_length"===n?this.model_max_length:V(c.map(e=>e.input_ids.length))[0]),r=Math.min(r,this.model_max_length),n||i)for(let h=0;h<c.length;++h)c[h].input_ids.length!==r&&(c[h].input_ids.length>r?i&&Et(c[h],r):n&&Ct(c[h],r,e=>"input_ids"===e?this.pad_token_id:0,this.padding_side));const d={};if(o){if((!n||!i)&&c.some(e=>{for(const t of Object.keys(e))if(e[t].length!==c[0][t]?.length)return!0;return!1}))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");const e=[c.length,c[0].input_ids.length];for(const t of Object.keys(c[0]))d[t]=new se("int64",BigInt64Array.from(c.flatMap(e=>e[t]).map(BigInt)),e)}else{for(const e of Object.keys(c[0]))d[e]=c.map(t=>t[e]);if(!l)for(const e of Object.keys(d))d[e]=d[e][0]}return d}_encode_text(e){if(null===e)return null;const t=(this.added_tokens_regex?e.split(this.added_tokens_regex).filter(e=>e):[e]).map((e,t)=>{if(void 0!==this.added_tokens.find(t=>t.content===e))return e;{if(!0===this.remove_space&&(e=e.trim().split(/\s+/).join(" ")),this.do_lowercase_and_remove_accent&&(e=function(e){return Ce(e.toLowerCase())}(e)),null!==this.normalizer&&(e=this.normalizer(e)),0===e.length)return[];const s=null!==this.pre_tokenizer?this.pre_tokenizer(e,{section_index:t}):[e];return this.model(s)}}).flat();return t}_encode_plus(e,t=null,{add_special_tokens:s=!0,return_token_type_ids:n=null}={}){const i=this._encode_text(e),r=this._encode_text(t),o=this.post_processor?this.post_processor(i,r,{add_special_tokens:s}):{tokens:c(i??[],r??[])},a=this.model.convert_tokens_to_ids(o.tokens),l={input_ids:a,attention_mask:new Array(a.length).fill(1)};return(n??this.return_token_type_ids)&&o.token_type_ids&&(l.token_type_ids=o.token_type_ids),l}encode(e,t=null,{add_special_tokens:s=!0,return_token_type_ids:n=null}={}){const{input_ids:i}=this._encode_plus(e,t,{add_special_tokens:s,return_token_type_ids:n});return i}batch_decode(e,t={}){return e instanceof se&&(e=e.tolist()),e.map(e=>this.decode(e,t))}decode(e,t={}){if(e instanceof se&&(e=ze(e)),!Array.isArray(e)||0===e.length||!o(e[0]))throw Error("token_ids must be a non-empty array of integers.");return this.decode_single(e,t)}decode_single(e,{skip_special_tokens:t=!1,clean_up_tokenization_spaces:s=null}){let n=this.model.convert_ids_to_tokens(e);t&&(n=n.filter(e=>!this.special_tokens.includes(e)));let i=this.decoder?this.decoder(n):n.join(" ");return this.decoder&&this.decoder.end_of_word_suffix&&(i=i.replaceAll(this.decoder.end_of_word_suffix," "),t&&(i=i.trim())),(s??this.clean_up_tokenization_spaces)&&(i=Se(i)),i}get default_chat_template(){return this._warned_about_chat_template||(this._warned_about_chat_template=!0),this._default_chat_template}apply_chat_template(e,{chat_template:t=null,add_generation_prompt:n=!1,tokenize:i=!0,padding:r=!1,truncation:o=!1,max_length:a=null,return_tensor:l=!0,tokenizer_kwargs:c={},...d}={}){if(this.chat_template&&"object"==typeof this.chat_template||null===this.chat_template&&this.default_chat_template&&"object"==typeof this.default_chat_template){const e=this.chat_template??this.default_chat_template;if(null!==t&&Object.hasOwn(e,t))t=e[t];else if(null===t&&"default"in e)t=e.default;else if(null===t)throw Error(`This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(e).sort()}.`)}else t??=this.chat_template??this.default_chat_template;if("string"!=typeof t)throw Error("chat_template must be a string, but got "+typeof t);let h=this._compiled_template_cache.get(t);void 0===h&&(h=new s(t),this._compiled_template_cache.set(t,h));const _=Object.create(null);for(const s of St){const e=this.getToken(s);e&&(_[s]=e)}const u=h.render({messages:e,add_generation_prompt:n,..._,...d});return i?this._call(u,{add_special_tokens:!1,padding:r,truncation:o,max_length:a,return_tensor:l,...c}).input_ids:u}}class Ft extends Tt{return_token_type_ids=!0}class Pt extends Tt{return_token_type_ids=!0}class Lt extends Tt{return_token_type_ids=!0}class It extends Tt{return_token_type_ids=!0}class Bt extends Tt{return_token_type_ids=!0}class Ot extends Tt{return_token_type_ids=!0}class Nt extends Tt{return_token_type_ids=!0}class jt extends Tt{return_token_type_ids=!0}class $t extends Tt{return_token_type_ids=!0}class Dt extends Tt{}class qt extends Tt{}class Rt extends Tt{return_token_type_ids=!0;constructor(e,t){super(e,t)}}class Ut extends Tt{return_token_type_ids=!0}class Gt extends Tt{}class Wt extends Tt{_default_chat_template='{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}'}class Vt extends Tt{}class Xt extends Tt{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{2}_[A-Z]{2}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}_build_translation_inputs(e,t,s){return ls(this,e,t,s)}}class Kt extends Xt{}class Ht extends Tt{}class Qt extends Wt{constructor(e,t){const s=".,!?…。，、।۔،",n=e.pre_tokenizer?.pretokenizers[0]?.pattern;n&&n.Regex===` ?[^(\\s|[${s}])]+`&&(n.Regex=` ?[^\\s${s}]+`),super(e,t)}}const Yt="▁";class Jt extends Tt{_default_chat_template="{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\n' + content.strip() + '\n<</SYS>>\n\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}";DEFAULT_SYSTEM_PROMPT="You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.";constructor(e,t){super(e,t),this.use_default_system_prompt=t.use_default_system_prompt??!1,this.legacy=t.legacy??!0,this.legacy||(this.normalizer=null,this.pre_tokenizer=new xt({replacement:Yt,add_prefix_space:!0,prepend_scheme:"first"}))}_encode_text(e){if(null===e)return null;if(this.legacy||0===e.length)return super._encode_text(e);let t=super._encode_text(Yt+e.replaceAll(Yt," "));return t.length>1&&t[0]===Yt&&this.special_tokens.includes(t[1])&&(t=t.slice(1)),t}get default_chat_template(){return super.default_chat_template.replaceAll("USE_DEFAULT_PROMPT",this.use_default_system_prompt?"true":"false").replaceAll("DEFAULT_SYSTEM_MESSAGE",this.DEFAULT_SYSTEM_PROMPT.replaceAll("\n","\\n").replaceAll("'","\\'"))}}class Zt extends Jt{}class es extends Tt{}class ts extends Tt{}class ss extends Tt{}class ns extends Tt{}class is extends Tt{}class rs extends Tt{}class os extends Tt{_default_chat_template="{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"}class as extends Tt{}function ls(e,t,s,n){if(!("language_codes"in e)||!Array.isArray(e.language_codes))throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");if(!("languageRegex"in e&&e.languageRegex instanceof RegExp))throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");if(!("lang_to_token"in e)||"function"!=typeof e.lang_to_token)throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");const i=n.src_lang,r=n.tgt_lang;if(!e.language_codes.includes(r))throw new Error(`Target language code "${r}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);if(void 0!==i){if(!e.language_codes.includes(i))throw new Error(`Source language code "${i}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);for(const t of e.post_processor.config.single)if("SpecialToken"in t&&e.languageRegex.test(t.SpecialToken.id)){t.SpecialToken.id=e.lang_to_token(i);break}}return n.forced_bos_token_id=e.model.convert_tokens_to_ids([e.lang_to_token(r)])[0],e._call(t,s)}class cs extends Tt{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{3}_[A-Z][a-z]{3}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}_build_translation_inputs(e,t,s){return ls(this,e,t,s)}}class ds extends Tt{constructor(e,t){super(e,t),this.languageRegex=/^__[a-z]{2,3}__$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)).map(e=>e.slice(2,-2)),this.lang_to_token=e=>`__${e}__`}_build_translation_inputs(e,t,s){return ls(this,e,t,s)}}const hs=[["en","english"],["zh","chinese"],["de","german"],["es","spanish"],["ru","russian"],["ko","korean"],["fr","french"],["ja","japanese"],["pt","portuguese"],["tr","turkish"],["pl","polish"],["ca","catalan"],["nl","dutch"],["ar","arabic"],["sv","swedish"],["it","italian"],["id","indonesian"],["hi","hindi"],["fi","finnish"],["vi","vietnamese"],["he","hebrew"],["uk","ukrainian"],["el","greek"],["ms","malay"],["cs","czech"],["ro","romanian"],["da","danish"],["hu","hungarian"],["ta","tamil"],["no","norwegian"],["th","thai"],["ur","urdu"],["hr","croatian"],["bg","bulgarian"],["lt","lithuanian"],["la","latin"],["mi","maori"],["ml","malayalam"],["cy","welsh"],["sk","slovak"],["te","telugu"],["fa","persian"],["lv","latvian"],["bn","bengali"],["sr","serbian"],["az","azerbaijani"],["sl","slovenian"],["kn","kannada"],["et","estonian"],["mk","macedonian"],["br","breton"],["eu","basque"],["is","icelandic"],["hy","armenian"],["ne","nepali"],["mn","mongolian"],["bs","bosnian"],["kk","kazakh"],["sq","albanian"],["sw","swahili"],["gl","galician"],["mr","marathi"],["pa","punjabi"],["si","sinhala"],["km","khmer"],["sn","shona"],["yo","yoruba"],["so","somali"],["af","afrikaans"],["oc","occitan"],["ka","georgian"],["be","belarusian"],["tg","tajik"],["sd","sindhi"],["gu","gujarati"],["am","amharic"],["yi","yiddish"],["lo","lao"],["uz","uzbek"],["fo","faroese"],["ht","haitian creole"],["ps","pashto"],["tk","turkmen"],["nn","nynorsk"],["mt","maltese"],["sa","sanskrit"],["lb","luxembourgish"],["my","myanmar"],["bo","tibetan"],["tl","tagalog"],["mg","malagasy"],["as","assamese"],["tt","tatar"],["haw","hawaiian"],["ln","lingala"],["ha","hausa"],["ba","bashkir"],["jw","javanese"],["su","sundanese"]],_s=new Map(hs),us=new Map([...hs.map(([e,t])=>[t,e]),["burmese","my"],["valencian","ca"],["flemish","nl"],["haitian","ht"],["letzeburgesch","lb"],["pushto","ps"],["panjabi","pa"],["moldavian","ro"],["moldovan","ro"],["sinhalese","si"],["castilian","es"]]);class ps extends Tt{_default_chat_template='{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}';_decode_asr(e,{return_timestamps:t=!1,return_language:s=!1,time_precision:n=null,force_full_sequences:i=!0}={}){if(null===n)throw Error("Must specify time_precision");let r=null;const o="word"===t;function a(){return{language:r,timestamp:[null,null],text:""}}const l=[];let c=a(),d=0;const h=this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0]+1;let _=[],u=[],p=!1,f=null;const m=new Set(this.all_special_ids);for(const y of e){const e=y.tokens,s=o?y.token_timestamps:null;let i=null,g=h;if("stride"in y){const[t,s,r]=y.stride;if(d-=s,f=t-r,s&&(g=s/n+h),r)for(let o=e.length-1;o>=0;--o){const t=e[o];if(t>=h){if(null!==i&&(t-h)*n<f)break;i=t}}}let w=[],x=[];for(let f=0;f<e.length;++f){const y=e[f];if(m.has(y)){const e=this.decode([y]),s=_s.get(e.slice(2,-2));if(void 0!==s){if(null!==r&&s!==r&&!t){_.push(w);const e=this.findLongestCommonSequence(_)[0],t=this.decode(e);c.text=t,l.push(c),_=[],w=[],c=a()}r=c.language=s}}else if(y>=h){const e=J((y-h)*n+d,2);if(null!==i&&y>=i)p=!0;else if(p||_.length>0&&y<g)p=!1;else if(null===c.timestamp[0])c.timestamp[0]=e;else if(e===c.timestamp[0]);else{c.timestamp[1]=e,_.push(w),o&&u.push(x);const[t,s]=this.findLongestCommonSequence(_,u),n=this.decode(t);c.text=n,o&&(c.words=this.collateWordTimestamps(t,s,r)),l.push(c),_=[],w=[],u=[],x=[],c=a()}}else if(w.push(y),o){let e,t=J(s[f]+d,2);e=f+1<s.length?J(s[f+1]+d,2):null,x.push([t,e])}}if("stride"in y){const[e,t,s]=y.stride;d+=e-s}w.length>0?(_.push(w),o&&u.push(x)):_.every(e=>0===e.length)&&(c=a(),_=[],w=[],u=[],x=[])}if(_.length>0){if(i&&t)throw new Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");const[e,s]=this.findLongestCommonSequence(_,u),n=this.decode(e);c.text=n,o&&(c.words=this.collateWordTimestamps(e,s,r)),l.push(c)}let g=Object.create(null);const w=l.map(e=>e.text).join("");if(t||s){for(let e=0;e<l.length;++e){const n=l[e];t||delete n.timestamp,s||delete n.language}if(o){const e=[];for(const t of l)for(const s of t.words)e.push(s);g={chunks:e}}else g={chunks:l}}return[w,g]}findLongestCommonSequence(e,t=null){let s=e[0],n=s.length,i=[];const r=Array.isArray(t)&&t.length>0;let o=r?[]:null,a=r?t[0]:null;for(let l=1;l<e.length;++l){const c=e[l];let d=0,h=[n,n,0,0];const _=c.length;for(let e=1;e<n+_;++e){const t=e/1e4,i=Math.max(0,n-e),r=Math.min(n,n+_-e),o=s.slice(i,r),a=Math.max(0,e-n),l=Math.min(_,e),u=c.slice(a,l);if(o.length!==u.length)throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");const p=o.filter((e,t)=>e===u[t]).length,f=p/e+t;p>1&&f>d&&(d=f,h=[i,r,a,l])}const[u,p,f,m]=h,g=Math.floor((p+u)/2),w=Math.floor((m+f)/2);i.push(...s.slice(0,g)),s=c.slice(w),n=s.length,r&&(o.push(...a.slice(0,g)),a=t[l].slice(w))}return i.push(...s),r?(o.push(...a),[i,o]):[i,[]]}collateWordTimestamps(e,t,s){const[n,i,r]=this.combineTokensIntoWords(e,s),o=[];for(let a=0;a<n.length;++a){const e=r[a];o.push({text:n[a],timestamp:[t[e.at(0)][0],t[e.at(-1)][1]]})}return o}combineTokensIntoWords(e,t,s="\"'“¡¿([{-",n="\"'.。,，!！?？:：”)]}、"){let i,r,o;return["chinese","japanese","thai","lao","myanmar"].includes(t=t??"english")?[i,r,o]=this.splitTokensOnUnicode(e):[i,r,o]=this.splitTokensOnSpaces(e),this.mergePunctuations(i,r,o,s,n)}decode(e,t){let s;return t&&t.decode_with_timestamps?(e instanceof se&&(e=ze(e)),s=this.decodeWithTimestamps(e,t)):s=super.decode(e,t),s}decodeWithTimestamps(e,t){const s=t?.time_precision??.02,n=Array.from(this.all_special_ids).at(-1)+1;let i=[[]];for(const r of e)if(r>=n){const e=J((r-n)*s,2);i.push(`<|${e}|>`),i.push([])}else i[i.length-1].push(r);return i=i.map(e=>"string"==typeof e?e:super.decode(e,t)),i.join("")}splitTokensOnUnicode(e){const t=this.decode(e,{decode_with_timestamps:!0}),s=[],n=[],i=[];let r=[],o=[],a=0;for(let l=0;l<e.length;++l){const c=e[l];r.push(c),o.push(l);const d=this.decode(r,{decode_with_timestamps:!0});d.includes("�")&&"�"!==t[a+d.indexOf("�")]||(s.push(d),n.push(r),i.push(o),r=[],o=[],a+=d.length)}return[s,n,i]}splitTokensOnSpaces(e){const[t,s,n]=this.splitTokensOnUnicode(e),i=[],r=[],o=[],a=new RegExp(`^[${Ee}]$`,"gu");for(let l=0;l<t.length;++l){const e=t[l],c=s[l],d=n[l],h=c[0]>=this.model.tokens_to_ids.get("<|endoftext|>"),_=e.startsWith(" "),u=e.trim(),p=a.test(u);if(h||_||p||0===i.length)i.push(e),r.push(c),o.push(d);else{const t=i.length-1;i[t]+=e,r[t].push(...c),o[t].push(...d)}}return[i,r,o]}mergePunctuations(e,t,s,n,i){const r=structuredClone(e),o=structuredClone(t),a=structuredClone(s);let l=r.length-2,d=r.length-1;for(;l>=0;)r[l].startsWith(" ")&&n.includes(r[l].trim())?(r[d]=r[l]+r[d],o[d]=c(o[l],o[d]),a[d]=c(a[l],a[d]),r[l]="",o[l]=[],a[l]=[]):d=l,--l;for(l=0,d=1;d<r.length;)!r[l].endsWith(" ")&&i.includes(r[d])?(r[l]+=r[d],o[l]=c(o[l],o[d]),a[l]=c(a[l],a[d]),r[d]="",o[d]=[],a[d]=[]):l=d,++d;return[r.filter(e=>e),o.filter(e=>e.length>0),a.filter(e=>e.length>0)]}get_decoder_prompt_ids({language:e=null,task:t=null,no_timestamps:s=!0}={}){const n=[];if(e){e=e.toLowerCase();let t=us.get(e);if(void 0===t){if(!_s.has(e)){const t=2===e.length?_s.keys():_s.values();throw new Error(`Language "${e}" is not supported. Must be one of: ${JSON.stringify(t)}`)}t=e}const s=this.model.tokens_to_ids.get(`<|${t}|>`);if(void 0===s)throw new Error(`Unable to find language "${t}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);n.push(s)}else n.push(null);if(t){if("transcribe"!==(t=t.toLowerCase())&&"translate"!==t)throw new Error(`Task "${t}" is not supported. Must be one of: ["transcribe", "translate"]`);const e=this.model.tokens_to_ids.get(`<|${t}|>`);if(void 0===e)throw new Error(`Unable to find task "${t}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);n.push(e)}else n.push(null);if(s){const e=this.model.tokens_to_ids.get("<|notimestamps|>");if(void 0===e)throw new Error('Unable to find "<|notimestamps|>" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.');n.push(e)}return n.map((e,t)=>[t+1,e]).filter(e=>null!==e[1])}}class fs extends Tt{}class ms extends Tt{}class gs extends Tt{}class ws extends Tt{constructor(e,t){super(e,t),this.languageRegex=/^(>>\w+<<)\s*/g,this.supported_language_codes=this.model.vocab.filter(e=>this.languageRegex.test(e))}_encode_text(e){if(null===e)return null;const[t,...s]=e.trim().split(this.languageRegex);if(0===s.length)return super._encode_text(t);if(2===s.length){const[e,t]=s;return this.supported_language_codes.includes(e),c([e],super._encode_text(t))}}}class ys extends Tt{}class xs extends Tt{_default_chat_template="{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}"}class ks extends xs{}class bs extends Tt{}class vs extends Tt{}class Ms extends Tt{constructor(e,t){super(e,t),this.decoder=new yt({})}}class As extends Tt{}class zs{static TOKENIZER_CLASS_MAPPING={T5Tokenizer:Gt,DistilBertTokenizer:Dt,CamembertTokenizer:qt,DebertaTokenizer:Bt,DebertaV2Tokenizer:Ot,BertTokenizer:Ft,HerbertTokenizer:Nt,ConvBertTokenizer:jt,RoFormerTokenizer:$t,XLMTokenizer:Rt,ElectraTokenizer:Ut,MobileBertTokenizer:Lt,SqueezeBertTokenizer:It,AlbertTokenizer:Pt,GPT2Tokenizer:Wt,BartTokenizer:Vt,MBartTokenizer:Xt,MBart50Tokenizer:Kt,RobertaTokenizer:Ht,WhisperTokenizer:ps,CodeGenTokenizer:fs,CLIPTokenizer:ms,SiglipTokenizer:gs,MarianTokenizer:ws,BloomTokenizer:Qt,NllbTokenizer:cs,M2M100Tokenizer:ds,LlamaTokenizer:Jt,CodeLlamaTokenizer:Zt,XLMRobertaTokenizer:es,MPNetTokenizer:ts,FalconTokenizer:ss,GPTNeoXTokenizer:ns,EsmTokenizer:is,Wav2Vec2CTCTokenizer:ys,BlenderbotTokenizer:xs,BlenderbotSmallTokenizer:ks,SpeechT5Tokenizer:bs,NougatTokenizer:vs,VitsTokenizer:Ms,Qwen2Tokenizer:rs,GemmaTokenizer:os,Grok1Tokenizer:as,CohereTokenizer:As,PreTrainedTokenizer:Tt};static async from_pretrained(e,{quantized:t=!0,progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:o="main",legacy:a=null}={}){const[l,c]=await ve(e,{progress_callback:s,cache_dir:i,local_files_only:r,revision:o,legacy:a}),d=c.tokenizer_class?.replace(/Fast$/,"")??"PreTrainedTokenizer";let h=this.TOKENIZER_CLASS_MAPPING[d];return h||(h=Tt),new h(l,c)}}class Ss{constructor(e){this.model_type=null,this.is_encoder_decoder=!1,Object.assign(this,e)}static async from_pretrained(e,{progress_callback:t=null,config:s=null,cache_dir:n=null,local_files_only:i=!1,revision:r="main"}={}){let o=s??await async function(e,t){return await B(e,"config.json",!0,t)}(e,{progress_callback:t,cache_dir:n,local_files_only:i,revision:r});return new this(o)}}class Cs{static async from_pretrained(...e){return Ss.from_pretrained(...e)}}class Es extends r{constructor(){super(),this.processors=[]}push(e){this.processors.push(e)}extend(e){this.processors.push(...e)}_call(e,t){for(let s of t)this.processors.forEach(t=>t(e,s))}[Symbol.iterator](){return this.processors.values()}}class Ts extends r{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class Fs extends Ts{constructor(e){super(),this.force_token_map=Object.fromEntries(e??[])}_call(e,t){let s=this.force_token_map[e.length];return null!=s&&(t.data.fill(-1/0),t.data[s]=0),t}}class Ps extends Ts{constructor(e){super(),this.bos_token_id=e}_call(e,t){return 1===e.length&&(t.data.fill(-1/0),t.data[this.bos_token_id]=0),t}}class Ls extends Ts{constructor(e,t){super(),this.max_length=e,this.forced_eos_token_id=t}_call(e,t){}}class Is extends Ts{constructor(e,t){super(),this.begin_suppress_tokens=e,this.begin_index=t}_call(e,t){if(e.length===this.begin_index)for(let s of this.begin_suppress_tokens)t.data[s]=-1/0;return t}}class Bs extends Ts{constructor(e){super(),this.eos_token_id=e.eos_token_id,this.no_timestamps_token_id=e.no_timestamps_token_id,this.timestamp_begin=this.no_timestamps_token_id+1,this.begin_index=(e.forced_decoder_ids||[]).length+2,e.forced_decoder_ids.slice(-1)[0][1]===this.no_timestamps_token_id&&(this.begin_index-=1),this.max_initial_timestamp_index=e.max_initial_timestamp_index}_call(e,t){const s=t.data;if(s[this.no_timestamps_token_id]=-1/0,e.length===this.begin_index-1)return s.fill(-1/0),s[this.timestamp_begin]=0,t;const n=e.slice(this.begin_index),i=n.length>=1&&n[n.length-1]>=this.timestamp_begin,r=n.length<2||n[n.length-2]>=this.timestamp_begin;if(i&&(r?s.subarray(this.timestamp_begin).fill(-1/0):s.subarray(0,this.eos_token_id).fill(-1/0)),e.length===this.begin_index&&null!==this.max_initial_timestamp_index){const e=this.timestamp_begin+this.max_initial_timestamp_index;s.subarray(e+1).fill(-1/0)}const o=D(s);return Math.log(o.subarray(this.timestamp_begin).map(Math.exp).reduce((e,t)=>e+t))>V(o.subarray(0,this.timestamp_begin))[0]&&s.subarray(0,this.timestamp_begin).fill(-1/0),t}}class Os extends Ts{constructor(e){super(),this.no_repeat_ngram_size=e}getNgrams(e){const t=e.length,s=[];for(let i=0;i<t+1-this.no_repeat_ngram_size;++i){const t=[];for(let s=0;s<this.no_repeat_ngram_size;++s)t.push(e[i+s]);s.push(t)}const n=new Map;for(const i of s){const e=i.slice(0,i.length-1),t=JSON.stringify(e),s=n.get(t)??[];s.push(i[i.length-1]),n.set(t,s)}return n}getGeneratedNgrams(e,t){const s=t.slice(t.length+1-this.no_repeat_ngram_size,t.length);return e.get(JSON.stringify(s))??[]}calcBannedNgramTokens(e){if(e.length+1<this.no_repeat_ngram_size)return[];{const t=this.getNgrams(e);return this.getGeneratedNgrams(t,e)}}_call(e,t){const s=this.calcBannedNgramTokens(e);for(const n of s)t.data[n]=-1/0;return t}}class Ns extends Ts{constructor(e){super(),this.penalty=e}_call(e,t){for(const s of e)t.data[s]<0?t.data[s]*=this.penalty:t.data[s]/=this.penalty;return t}}class js extends Ts{constructor(e,t){super(),this.min_length=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){if(e.length<this.min_length)for(const s of this.eos_token_id)t.data[s]=-1/0;return t}}class $s extends Ts{constructor(e,t,s){super(),this.prompt_length_to_skip=e,this.min_new_tokens=t,this.eos_token_id=Array.isArray(s)?s:[s]}_call(e,t){if(e.length-this.prompt_length_to_skip<this.min_new_tokens)for(const s of this.eos_token_id)t.data[s]=-1/0;return t}}class Ds extends Ts{constructor(e,t){super(),this.bad_words_ids=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(const s of this.bad_words_ids){let n=!0;for(let t=1;t<=s.length-1&&s.length<e.length;++t)if(s.at(-t-1)!==e.at(-t)){n=!1;break}n&&(t.data[s.at(-1)]=-1/0)}return t}}const qs=class{constructor(e={}){this.max_length=e.max_length??20,this.max_new_tokens=e.max_new_tokens??null,this.min_length=e.min_length??0,this.min_new_tokens=e.min_new_tokens??null,this.early_stopping=e.early_stopping??!1,this.max_time=e.max_time??null,this.do_sample=e.do_sample??!1,this.num_beams=e.num_beams??1,this.num_beam_groups=e.num_beam_groups??1,this.penalty_alpha=e.penalty_alpha??null,this.use_cache=e.use_cache??!0,this.temperature=e.temperature??1,this.top_k=e.top_k??50,this.top_p=e.top_p??1,this.typical_p=e.typical_p??1,this.epsilon_cutoff=e.epsilon_cutoff??0,this.eta_cutoff=e.eta_cutoff??0,this.diversity_penalty=e.diversity_penalty??0,this.repetition_penalty=e.repetition_penalty??1,this.encoder_repetition_penalty=e.encoder_repetition_penalty??1,this.length_penalty=e.length_penalty??1,this.no_repeat_ngram_size=e.no_repeat_ngram_size??0,this.bad_words_ids=e.bad_words_ids??null,this.force_words_ids=e.force_words_ids??null,this.renormalize_logits=e.renormalize_logits??!1,this.constraints=e.constraints??null,this.forced_bos_token_id=e.forced_bos_token_id??null,this.forced_eos_token_id=e.forced_eos_token_id??null,this.remove_invalid_values=e.remove_invalid_values??!1,this.exponential_decay_length_penalty=e.exponential_decay_length_penalty??null,this.suppress_tokens=e.suppress_tokens??null,this.begin_suppress_tokens=e.begin_suppress_tokens??null,this.forced_decoder_ids=e.forced_decoder_ids??null,this.num_return_sequences=e.num_return_sequences??1,this.output_attentions=e.output_attentions??!1,this.output_hidden_states=e.output_hidden_states??!1,this.output_scores=e.output_scores??!1,this.return_dict_in_generate=e.return_dict_in_generate??!1,this.pad_token_id=e.pad_token_id??null,this.bos_token_id=e.bos_token_id??null,this.eos_token_id=e.eos_token_id??null,this.encoder_no_repeat_ngram_size=e.encoder_no_repeat_ngram_size??0,this.decoder_start_token_id=e.decoder_start_token_id??null,this.generation_kwargs=e.generation_kwargs??{}}};class Rs extends r{constructor(e){super(),this.generation_config=e}_call(e,t=-1){return this.sample(e,t)}sample(e,t){throw Error("sample should be implemented in subclasses.")}getLogits(e,t){let s=e.dims.at(-1),n=e.data;if(-1===t)n=n.slice(-s);else{let e=t*s;n=n.slice(e,e+s)}return this.generation_config.temperature>0&&(n=n.map(e=>e/this.generation_config.temperature)),n}randomSelect(e){let t=e.reduce((e,t)=>e+t,0),s=Math.random()*t;for(let n=0;n<e.length;++n)if(s-=e[n],s<=0)return n;return 0}static getSampler(e){if(e.do_sample)return new Gs(e);if(e.num_beams>1)return new Ws(e);if(e.num_return_sequences>1)throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${e.num_return_sequences}.`);return new Us(e)}}class Us extends Rs{sample(e,t=-1){return[[V(this.getLogits(e,t))[1],0]]}}class Gs extends Rs{sample(e,t=-1){let s=e.dims.at(-1);this.generation_config.top_k>0&&(s=Math.min(this.generation_config.top_k,s));const n=R(this.getLogits(e,t),s),i=$(n.map(e=>e[1]));return Array.from({length:this.generation_config.num_beams},()=>{const e=this.randomSelect(i);return[n[e][0],Math.log(i[e])]})}}class Ws extends Rs{sample(e,t=-1){let s=e.dims.at(-1);this.generation_config.top_k>0&&(s=Math.min(this.generation_config.top_k,s));const n=R(this.getLogits(e,t),s),i=$(n.map(e=>e[1]));return Array.from({length:this.generation_config.num_beams},(e,t)=>[n[t][0],Math.log(i[t])])}}const{InferenceSession:Vs,Tensor:Xs,env:Ks}=p,Hs=new Map,Qs=new Map,Ys=new Map;async function Js(e,t,s){let n=`onnx/${t}${s.quantized?"_quantized":""}.onnx`,i=await I(e,n,!0,s);try{return await Vs.create(i,{executionProviders:f})}catch(r){if(1===f.length&&"wasm"===f[0])throw r;return await Vs.create(i,{executionProviders:["wasm"]})}}async function Zs(e,t){const s=function(e,t){const s=Object.create(null),n=[];for(const i of e.inputNames){const e=t[i];e instanceof se?s[i]=Ks.wasm.proxy?e.clone():e:n.push(i)}if(n.length>0)throw new Error(`An error occurred during model execution: "Missing the following inputs: ${n.join(", ")}.`);return Object.keys(t).length>e.inputNames.length&&Object.keys(t).filter(t=>!e.inputNames.includes(t)),s}(e,t);try{let t=await e.run(s);return t=en(t),t}catch(n){throw n}}function en(e){for(let t in e)e[t]instanceof Xs?e[t]=new se(e[t]):"object"==typeof e[t]&&en(e[t]);return e}function tn(e){if(e instanceof se)return e;if(0===e.length)throw Error("items must be non-empty");if(Array.isArray(e[0])){if(e.some(t=>t.length!==e[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new se("int64",BigInt64Array.from(e.flat().map(e=>BigInt(e))),[e.length,e[0].length])}return new se("int64",BigInt64Array.from(e.map(e=>BigInt(e))),[1,e.length])}function sn(e,t){let s=e.config.pad_token_id??null,n=e.config.eos_token_id??null;o(n)&&(n=[n]);let i=-1!==t.indexOf(s),r=null===n||!n.includes(s);if(i&&r){let e=BigInt64Array.from(t.data.map(e=>e!=s));return new se("int64",e,t.dims)}return me(t)}function nn(e,t,s){if(!e.inputNames.includes("position_ids"))return;const n=new BigInt64Array(t.attention_mask.data.length);for(let i=0;i<t.attention_mask.dims[0];++i){let e=i*t.attention_mask.dims[1],s=BigInt(0);for(let i=0;i<t.attention_mask.dims[1];++i){const r=e+i;0n===t.attention_mask.data[r]?n[r]=BigInt(1):(n[r]=s,s+=t.attention_mask.data[r])}}t.position_ids=new se("int64",n,t.attention_mask.dims),s&&(t.position_ids=t.position_ids.slice(null,-1).unsqueeze_(-1))}function rn(e){return new se("bool",[e],[1])}async function on(e,t){let{encoder_outputs:s,past_key_values:n}=t;s||(s=(await dn(e,t)).last_hidden_state);let i={input_ids:t.decoder_input_ids,encoder_hidden_states:s};const r=!!n;e.decoder_merged_session.inputNames.includes("use_cache_branch")&&(i.use_cache_branch=rn(r)),e.decoder_merged_session.inputNames.includes("encoder_attention_mask")&&(i.encoder_attention_mask=t.attention_mask),nn(e.decoder_merged_session,i,r),e.addPastKeyValues(i,n);const o=await Zs(e.decoder_merged_session,i);let a=o.logits;n=e.getPastKeyValues(o,n);const l=e.getAttentions(o);return new cd({logits:a,past_key_values:n,encoder_outputs:s,...l})}function an(e,t,s,n){let i=[],r=0;const o=e.requires_attention_mask??!0;let a=s.decoder_input_ids??s.decoder_start_token_id??s.bos_token_id??s.eos_token_id;a instanceof se?a=a.tolist().flat():Array.isArray(a)||(a=[a]);for(let l of t){l.dims=[1,...l.dims];let t={inputs:l,encoder_outputs:null,prev_model_outputs:null,output_token_ids:a,done:!1,score:0,id:r++};o&&(t.attention_mask=sn(e,l)),i.push(t)}return i}async function ln(e,t){const s=e.main_input_name;let n=t.output_token_ids;t.prev_model_outputs&&(n=n.slice(-1));let i={[s]:t.inputs,decoder_input_ids:tn(n),encoder_outputs:t.encoder_outputs,past_key_values:t.prev_model_outputs?.past_key_values};t.attention_mask&&(i.attention_mask=t.attention_mask);let r=await e.forward(i);return t.prev_model_outputs=r,t.encoder_outputs=r.encoder_outputs,r}function cn(e,t){e.output_token_ids=[...e.output_token_ids,t]}async function dn(e,t){const s=Object.create(null);for(const n of e.session.inputNames)s[n]=t[n];return e.session.inputNames.includes("token_type_ids")&&!s.token_type_ids&&(s.token_type_ids=new se("int64",new BigInt64Array(s.input_ids.data.length),s.input_ids.dims)),await Zs(e.session,s)}async function hn(e,t){let{input_ids:s,past_key_values:n,attention_mask:i}=t,r={input_ids:s,attention_mask:i??sn(e,s)};const o=!!n;e.session.inputNames.includes("use_cache_branch")&&(r.use_cache_branch=rn(o)),nn(e.session,r,o),e.addPastKeyValues(r,n);let a=await Zs(e.session,r),l=a.logits;return n=e.getPastKeyValues(a,n),{logits:l,past_key_values:n}}function _n(e,t,s,n,i){let r=[],o=0;for(let a of t){let t,s=a.tolist().map(Number);a.dims=[1,...a.dims],i?(t=i[o],t.dims=[1,...t.dims]):t=sn(e,a);let l={input:a,model_input_ids:a,attention_mask:t,prev_model_outputs:null,output_token_ids:s,num_output_tokens:n,done:!1,score:0,id:o++};r.push(l)}return r}async function un(e,t){let s=new BigInt64Array(t.output_token_ids.length).fill(1n),n={input_ids:t.model_input_ids,attention_mask:new se("int64",s,[1,s.length]),past_key_values:t.prev_model_outputs?.past_key_values},i=await e.forward(n);return t.prev_model_outputs=i,i}function pn(e,t){e.output_token_ids=[...e.output_token_ids,t],e.model_input_ids=new se("int64",[BigInt(t)],[1,1])}class fn extends r{main_input_name="input_ids";constructor(e,t){super(),this.config=e,this.session=t;const s=Ys.get(this.constructor),n=Hs.get(s);this.can_generate=!1,this._runBeam=null,this._getStartBeams=null,this._updateBeam=null,this._forward=null,4===n?(this.can_generate=!0,this._runBeam=un,this._getStartBeams=_n,this._updateBeam=pn,this._forward=hn):2===n||3===n?(this.can_generate=!0,this._runBeam=ln,this._getStartBeams=an,this._updateBeam=cn,this._forward=on):this._forward=dn}async dispose(){const e=[];for(let t of Object.keys(this)){const s=this[t];s instanceof Vs&&e.push(s.handler.dispose())}return await Promise.all(e)}static async from_pretrained(e,{quantized:t=!0,progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:o="main",model_file_name:a=null}={}){let l={quantized:t,progress_callback:s,config:n,cache_dir:i,local_files_only:r,revision:o,model_file_name:a};const c=Ys.get(this),d=Hs.get(c);let h;return h=4===d?await Promise.all([Cs.from_pretrained(e,l),Js(e,l.model_file_name??"decoder_model_merged",l),B(e,"generation_config.json",!1,l)]):2===d||3===d?await Promise.all([Cs.from_pretrained(e,l),Js(e,"encoder_model",l),Js(e,"decoder_model_merged",l),B(e,"generation_config.json",!1,l)]):5===d?await Promise.all([Cs.from_pretrained(e,l),Js(e,"vision_encoder",l),Js(e,"prompt_encoder_mask_decoder",l)]):1===d?await Promise.all([Cs.from_pretrained(e,l),Js(e,"encoder_model",l),Js(e,"decoder_model_merged",l)]):await Promise.all([Cs.from_pretrained(e,l),Js(e,l.model_file_name??"model",l)]),new this(...h)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}_get_logits_processor(e,t,s=null){const n=new Es;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&n.push(new Ns(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&n.push(new Os(e.no_repeat_ngram_size)),null!==e.bad_words_ids&&n.push(new Ds(e.bad_words_ids,e.eos_token_id)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&n.push(new js(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&n.push(new $s(t,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&n.push(new Ps(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&n.push(new Ls(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let s=t>1||null===e.forced_bos_token_id?t:t+1;null!==e.forced_decoder_ids&&(s+=e.forced_decoder_ids[e.forced_decoder_ids.length-1][0]),n.push(new Is(e.begin_suppress_tokens,s))}return null!==e.forced_decoder_ids&&n.push(new Fs(e.forced_decoder_ids)),null!==s&&n.extend(s),n}_get_generation_config(e){let t=new qs(this.config);return"generation_config"in this&&Object.assign(t,this.generation_config),null!==e&&Object.assign(t,e),t}async generate(e,t=null,s=null,{inputs_attention_mask:n=null}={}){if(!this.can_generate){let e=`The current model class (${Ys.get(this.constructor)}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;const t=this.config.model_type,s=mc.get(t)??fc.get(t)??dc.get(t)??yc.get(t);throw s&&(e+=` Please use the following class instead: '${s[0]}'`),Error(e)}if(!(e instanceof se||(i=e,"TypedArray"===i?.prototype?.__proto__?.constructor?.name)||Array.isArray(e)))throw Error(`\`inputs\` must be a Tensor, TypedArray, or Array, but is "${e.constructor.name}".`);var i;let r;if(this.config.is_encoder_decoder)r=0;else if(r=e instanceof se?e.dims.at(-1):e.length,0===r)throw Error("Must supply a non-empty array of input token ids.");t=this._get_generation_config(t),s=s??new Es,s=this._get_logits_processor(t,r,s);let o=t.eos_token_id;null===o||Array.isArray(o)||(o=[o]);let a=1;const l=a+(t.max_new_tokens??1/0),c=Number.isInteger(t.max_length)&&null===(t.max_new_tokens??null);let d=Rs.getSampler(t),h=this.getStartBeams(e,t,a,n);for(;h.some(e=>!e.done)&&a<l;){let e=[];for(let n of h){if(n.done){e.push(n);continue}if(c&&n.output_token_ids.length>=t.max_length){n.done=!0,e.push(n);continue}let i=await this.runBeam(n);t.output_attentions&&this.addAttentionsToBeam(n,i),t.output_scores;let r=i.logits.slice(null,-1,null);s(n.output_token_ids,r);let a=d(r);for(let[t,s]of a){let i={...n};this.updateBeam(i,t),i.score+=s,o&&o.includes(t)&&(i.done=!0),e.push(i)}}++a,e=this.groupBeams(e).map(e=>e.sort((e,t)=>t.score-e.score).slice(0,t.num_beams)),h=e.flat(),t.callback_function&&t.callback_function(h)}const _=this.groupBeams(h),u=e=>_.map(s=>t.num_return_sequences>1?s.slice(0,t.num_return_sequences).map(t=>t[e]):[s[0][e]]).flat(),p=u("output_token_ids");return t.return_dict_in_generate?{sequences:p,decoder_attentions:u("decoder_attentions"),cross_attentions:u("cross_attentions")}:p}addAttentionsToBeam(e,t){if(this.config.is_encoder_decoder){if(!t.cross_attentions||0===t.cross_attentions.length)throw Error("`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.cross_attentions||(e.cross_attentions=[]),e.cross_attentions.push(t.cross_attentions)}if(!t.decoder_attentions||0===t.decoder_attentions.length)throw Error("`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.decoder_attentions||(e.decoder_attentions=[]),e.decoder_attentions.push(t.decoder_attentions)}groupBeams(e){const t=Object.create(null);for(const s of e)void 0===t[s.id]?t[s.id]=[s]:t[s.id].push(s);return Object.values(t)}getPastKeyValues(e,t){const s=Object.create(null);for(const n in e)if(n.startsWith("present")){let i=n.replace("present","past_key_values");t&&n.includes("encoder")?s[i]=t[i]:s[i]=e[n]}return s}getAttentions(e){const t=Object.create(null);for(const s of["cross_attentions","decoder_attentions"]){const n=[];for(const t in e)t.startsWith(s)&&(n[t.split(".").pop()]=e[t]);t[s]=n}return t}addPastKeyValues(e,t){if(t)Object.assign(e,t);else{const t=1;if(this.config.is_encoder_decoder&&(this.add_encoder_pkv??1)){let s=[t,this.num_encoder_heads,0,this.encoder_dim_kv],n=[t,this.num_decoder_heads,0,this.decoder_dim_kv];for(let t=0;t<this.num_decoder_layers;++t)e[`past_key_values.${t}.encoder.key`]=new se("float32",[],s),e[`past_key_values.${t}.encoder.value`]=new se("float32",[],s),e[`past_key_values.${t}.decoder.key`]=new se("float32",[],n),e[`past_key_values.${t}.decoder.value`]=new se("float32",[],n)}else if("falcon"===this.config.model_type){let s=[t*this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new se("float32",[],s),e[`past_key_values.${t}.value`]=new se("float32",[],s)}else if(this.config.multi_query){let s=[t*this.num_heads,0,2*this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key_value`]=new se("float32",[],s)}else if("bloom"===this.config.model_type){let s=[t*this.num_heads,this.dim_kv,0],n=[t*this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new se("float32",[],s),e[`past_key_values.${t}.value`]=new se("float32",[],n)}else{let s=[t,this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new se("float32",[],s),e[`past_key_values.${t}.value`]=new se("float32",[],s)}}}getStartBeams(e,t,s,n){return this._getStartBeams(this,e,t,s,n)}async runBeam(e){return await this._runBeam(this,e)}updateBeam(e,t){return this._updateBeam(e,t)}}class mn{}class gn extends mn{constructor({last_hidden_state:e,hidden_states:t=null,attentions:s=null}){super(),this.last_hidden_state=e,this.hidden_states=t,this.attentions=s}}class wn extends fn{}class yn extends wn{}class xn extends wn{async _call(e){return new ud(await super._call(e))}}class kn extends wn{async _call(e){return new dd(await super._call(e))}}class bn extends wn{async _call(e){return new _d(await super._call(e))}}class vn extends wn{async _call(e){return new pd(await super._call(e))}}class Mn extends fn{}class An extends Mn{}class zn extends fn{}class Sn extends zn{}class Cn extends zn{async _call(e){return new ud(await super._call(e))}}class En extends zn{async _call(e){return new dd(await super._call(e))}}class Tn extends zn{async _call(e){return new _d(await super._call(e))}}class Fn extends zn{async _call(e){return new pd(await super._call(e))}}class Pn extends fn{}class Ln extends Pn{}class In extends Pn{async _call(e){return new ud(await super._call(e))}}class Bn extends Pn{async _call(e){return new dd(await super._call(e))}}class On extends Pn{async _call(e){return new _d(await super._call(e))}}class Nn extends Pn{async _call(e){return new pd(await super._call(e))}}class jn extends fn{}class $n extends jn{}class Dn extends jn{async _call(e){return new ud(await super._call(e))}}class qn extends jn{async _call(e){return new dd(await super._call(e))}}class Rn extends jn{async _call(e){return new _d(await super._call(e))}}class Un extends jn{async _call(e){return new pd(await super._call(e))}}class Gn extends fn{}class Wn extends Gn{}class Vn extends Gn{async _call(e){return new ud(await super._call(e))}}class Xn extends Gn{async _call(e){return new dd(await super._call(e))}}class Kn extends Gn{async _call(e){return new _d(await super._call(e))}}class Hn extends Gn{async _call(e){return new pd(await super._call(e))}}class Qn extends fn{}class Yn extends Qn{}class Jn extends Qn{async _call(e){return new ud(await super._call(e))}}class Zn extends Qn{async _call(e){return new dd(await super._call(e))}}class ei extends Qn{async _call(e){return new _d(await super._call(e))}}class ti extends Qn{async _call(e){return new pd(await super._call(e))}}class si extends fn{}class ni extends si{}class ii extends si{async _call(e){return new ud(await super._call(e))}}class ri extends si{async _call(e){return new dd(await super._call(e))}}class oi extends si{async _call(e){return new _d(await super._call(e))}}class ai extends si{async _call(e){return new pd(await super._call(e))}}class li extends fn{}class ci extends li{}class di extends li{async _call(e){return new dd(await super._call(e))}}class hi extends li{async _call(e){return new _d(await super._call(e))}}class _i extends li{async _call(e){return new pd(await super._call(e))}}class ui extends li{async _call(e){return new ud(await super._call(e))}}class pi extends fn{}class fi extends pi{}class mi extends pi{async _call(e){return new ud(await super._call(e))}}class gi extends pi{async _call(e){return new dd(await super._call(e))}}class wi extends pi{async _call(e){return new _d(await super._call(e))}}class yi extends fn{}class xi extends yi{}class ki extends yi{async _call(e){return new ud(await super._call(e))}}class bi extends yi{async _call(e){return new dd(await super._call(e))}}class vi extends yi{async _call(e){return new pd(await super._call(e))}}class Mi extends fn{}class Ai extends Mi{}class zi extends Mi{async _call(e){return new ud(await super._call(e))}}class Si extends Mi{async _call(e){return new dd(await super._call(e))}}class Ci extends Mi{async _call(e){return new _d(await super._call(e))}}class Ei extends Mi{async _call(e){return new pd(await super._call(e))}}class Ti extends fn{}class Fi extends Ti{}class Pi extends Ti{async _call(e){return new ud(await super._call(e))}}class Li extends Ti{async _call(e){return new dd(await super._call(e))}}class Ii extends Ti{async _call(e){return new pd(await super._call(e))}}class Bi extends fn{}class Oi extends Bi{}class Ni extends Bi{async _call(e){return new dd(await super._call(e))}}class ji extends Bi{async _call(e){return new pd(await super._call(e))}}class $i extends Bi{async _call(e){return new ud(await super._call(e))}}class Di extends fn{}class qi extends Di{}class Ri extends Di{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class Ui extends fn{}class Gi extends Ui{}class Wi extends Ui{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class Vi extends fn{}class Xi extends Vi{}class Ki extends Vi{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class Hi extends fn{}class Qi extends Hi{}class Yi extends Hi{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class Ji extends Hi{async _call(e){return new dd(await super._call(e))}}class Zi extends fn{}class er extends Zi{}class tr extends Zi{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class sr extends Zi{async _call(e){return new dd(await super._call(e))}}class nr extends Zi{constructor(e,t,s){super(e,t),this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class ir extends fn{}class rr extends ir{}class or extends ir{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class ar extends fn{}class lr extends ar{}class cr extends ar{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class dr extends fn{}class hr extends dr{}class _r extends dr{async _call(e){return new ud(await super._call(e))}}class ur extends dr{async _call(e){return new dd(await super._call(e))}}class pr extends dr{async _call(e){return new _d(await super._call(e))}}class fr extends dr{async _call(e){return new pd(await super._call(e))}}class mr extends fn{}class gr extends mr{}class wr extends mr{async _call(e){return new ud(await super._call(e))}}class yr extends mr{async _call(e){return new dd(await super._call(e))}}class xr extends mr{async _call(e){return new _d(await super._call(e))}}class kr extends mr{async _call(e){return new pd(await super._call(e))}}class br extends fn{}class vr extends br{}class Mr extends br{async _call(e){return new ud(await super._call(e))}}class Ar extends br{async _call(e){return new dd(await super._call(e))}}class zr extends br{async _call(e){return new _d(await super._call(e))}}class Sr extends br{async _call(e){return new pd(await super._call(e))}}class Cr extends fn{}class Er extends Cr{}class Tr extends Cr{}class Fr extends fn{}class Pr extends Fr{}class Lr extends Fr{requires_attention_mask=!1;main_input_name="input_features";constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}async generate(e,t=null,s=null){if(t=this._get_generation_config(t),t.return_timestamps??=!1,t.return_timestamps&&(s=[new Bs(t)]),t.return_token_timestamps&&(t.output_attentions=!0,t.return_dict_in_generate=!0,t.task,!t.alignment_heads))throw new Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");const n=await super.generate(e,t,s);return t.return_token_timestamps&&t.alignment_heads&&(n.token_timestamps=this._extract_token_timestamps(n,t.alignment_heads,t.num_frames)),n}_extract_token_timestamps(e,t,s=null,n=.02){if(!e.cross_attentions)throw new Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");let i=this.config.median_filter_width;void 0===i&&(i=7);const r=e.cross_attentions.map(e=>{let n=Array.from({length:this.config.decoder_layers},(t,s)=>de(e.map(e=>e[s]),2)),r=he(t.map(([e,t])=>s?n[e].slice(null,t,null,[0,s]):n[e].slice(null,t)));r=r.transpose(1,0,2,3);let[o,a]=_e(r,-2,0,!0),l=r.clone();for(let t=0;t<l.dims[0];++t){let e=l[t];for(let s=0;s<e.dims[0];++s){let n=e[s];const r=o[t][s][0],l=a[t][s][0];for(let e=0;e<n.dims[0];++e){let t=n[e];for(let e=0;e<t.data.length;++e)t.data[e]=(t.data[e]-l.data[e])/r.data[e];t.data.set(Y(t.data,i))}}}return ue(l,1)}),o=[e.sequences.length,e.sequences[0].length],a=new se("float32",new Float32Array(o[0]*o[1]),o);for(let l=0;l<o[0];++l){const e=r[l].neg().squeeze_(0);let[t,s]=pe(e),i=c([1],Array.from({length:t.length-1},(e,s)=>t[s+1]-t[s])).map(e=>!!e),o=[];for(let r=0;r<i.length;++r)i[r]&&o.push(s[r]*n);a[l].data.set(o,1)}return a}}class Ir extends fn{main_input_name="pixel_values";constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n;const i=this.config.encoder,r=this.config.decoder,o=i.model_type,a=(ac.get(o)??lc.get(o),mc.get(r.model_type));if(!a)throw new Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`);const l=new(0,a[1])(r,s,n);this.add_encoder_pkv="num_decoder_layers"in l,this.add_encoder_pkv?(this.num_decoder_layers=l.num_decoder_layers,this.num_decoder_heads=l.num_decoder_heads,this.decoder_dim_kv=l.decoder_dim_kv,this.num_encoder_layers=l.num_encoder_layers,this.num_encoder_heads=l.num_encoder_heads,this.encoder_dim_kv=l.encoder_dim_kv):(this.num_layers=l.num_layers,this.num_heads=l.num_heads,this.dim_kv=l.dim_kv)}}class Br extends fn{}class Or extends Br{}class Nr extends Br{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}}class jr extends Br{static async from_pretrained(e,t={}){return t.model_file_name??="vision_model",super.from_pretrained(e,t)}}class $r extends fn{}class Dr extends $r{}class qr extends $r{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}}class Rr extends Br{static async from_pretrained(e,t={}){return t.model_file_name??="vision_model",super.from_pretrained(e,t)}}class Ur extends fn{}class Gr extends Ur{}class Wr extends fn{}class Vr extends Wr{}class Xr extends Wr{}class Kr extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class Hr extends Kr{}class Qr extends Kr{}class Yr extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_heads,this.num_layers=this.config.num_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class Jr extends Yr{}class Zr extends Yr{}class eo extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class to extends eo{}class so extends eo{}class no extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class io extends no{}class ro extends no{}class oo extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class ao extends oo{}class lo extends oo{}class co extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class ho extends co{}class _o extends co{}class uo extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class po extends uo{}class fo extends uo{}class mo extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class go extends mo{}class wo extends mo{}class yo extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class xo extends yo{}class ko extends yo{}class bo extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.hidden_size/this.num_heads}}class vo extends bo{}class Mo extends bo{}class Ao extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_heads,this.num_layers=this.config.n_layers,this.dim_kv=this.config.d_model/this.num_heads}}class zo extends Ao{}class So extends Ao{}class Co extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class Eo extends Co{}class To extends Co{}class Fo extends fn{}class Po extends Fo{}class Lo extends Fo{async _call(e){return new dd(await super._call(e))}}class Io extends fn{}class Bo extends Io{}class Oo extends Io{async _call(e){return new dd(await super._call(e))}}class No extends fn{}class jo extends No{async _call(e){return new gd(await super._call(e))}}class $o extends fn{}class Do extends $o{}class qo extends $o{async _call(e){return new dd(await super._call(e))}}class Ro extends fn{}class Uo extends Ro{}class Go extends Ro{async _call(e){return new dd(await super._call(e))}}class Wo extends fn{}class Vo extends Wo{}class Xo extends Wo{}class Ko extends fn{}class Ho extends Ko{}class Qo extends Ko{}class Yo extends fn{}class Jo extends Yo{}class Zo extends Yo{async _call(e){return new dd(await super._call(e))}}class ea extends fn{}class ta extends ea{}class sa extends ea{async _call(e){return new ia(await super._call(e))}}class na extends ea{async _call(e){return new ra(await super._call(e))}}class ia extends mn{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class ra extends mn{constructor({logits:e,pred_boxes:t,pred_masks:s}){super(),this.logits=e,this.pred_boxes=t,this.pred_masks=s}}class oa extends fn{}class aa extends oa{}class la extends oa{async _call(e){return new ca(await super._call(e))}}class ca extends ia{}class da extends fn{}class ha extends da{}class _a extends da{async _call(e){return new dd(await super._call(e))}}class ua extends fn{}class pa extends ua{}class fa extends ua{async _call(e){return new dd(await super._call(e))}}class ma extends fn{}class ga extends ma{}class wa extends ma{async _call(e){return new dd(await super._call(e))}}class ya extends fn{}class xa extends ya{}class ka extends ya{}class ba extends fn{}class va extends ba{}class Ma extends ba{}class Aa extends fn{}class za extends Aa{}class Sa extends fn{}class Ca extends Sa{}class Ea extends Sa{}class Ta extends fn{}class Fa extends Ta{}class Pa extends fn{}class La extends Pa{}class Ia extends Pa{async _call(e){return new dd(await super._call(e))}}class Ba extends fn{}class Oa extends Ba{}class Na extends Ba{async _call(e){return new dd(await super._call(e))}}class ja extends fn{}class $a extends ja{}class Da extends ja{async _call(e){return new dd(await super._call(e))}}class qa extends fn{}class Ra extends qa{}class Ua extends qa{async _call(e){return new Ga(await super._call(e))}}class Ga extends mn{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class Wa extends fn{}class Va extends Wa{constructor(e,t,s){super(e,t),this.prompt_encoder_mask_decoder=s}async get_image_embeddings({pixel_values:e}){return await dn(this,{pixel_values:e})}async forward(e){if(e.image_embeddings&&e.image_positional_embeddings||(e={...e,...await this.get_image_embeddings(e)}),!e.input_labels){const t=e.input_points.dims.slice(0,-1),s=t.reduce((e,t)=>e*t,1);e.input_labels=new se("int64",new BigInt64Array(s).fill(1n),t)}return await Zs(this.prompt_encoder_mask_decoder,{input_points:e.input_points,input_labels:e.input_labels,image_embeddings:e.image_embeddings,image_positional_embeddings:e.image_positional_embeddings})}async _call(e){return new Xa(await super._call(e))}}class Xa extends mn{constructor({iou_scores:e,pred_masks:t}){super(),this.iou_scores=e,this.pred_masks=t}}class Ka extends fn{}class Ha extends Ka{}class Qa extends Ka{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class Ya extends fn{}class Ja extends Ya{}class Za extends Ya{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class el extends fn{}class tl extends el{}class sl extends el{async _call(e){return new fd(await super._call(e))}}class nl extends el{async _call(e){return new dd(await super._call(e))}}class il extends el{async _call(e){return new _d(await super._call(e))}}class rl extends fn{}class ol extends rl{}class al extends rl{async _call(e){return new fd(await super._call(e))}}class ll extends rl{async _call(e){return new dd(await super._call(e))}}class cl extends fn{}class dl extends cl{}class hl extends cl{async _call(e){return new fd(await super._call(e))}}class _l extends cl{async _call(e){return new dd(await super._call(e))}}class ul extends cl{async _call(e){return new _d(await super._call(e))}}class pl extends fn{}class fl extends pl{}class ml extends pl{async _call(e){return new fd(await super._call(e))}}class gl extends pl{async _call(e){return new dd(await super._call(e))}}class wl extends fn{}class yl extends el{}class xl extends el{async _call(e){return new fd(await super._call(e))}}class kl extends el{async _call(e){return new dd(await super._call(e))}}class bl extends fn{}class vl extends bl{}class Ml extends bl{async _call(e){return new fd(await super._call(e))}}class Al extends bl{async _call(e){return new dd(await super._call(e))}}class zl extends bl{async _call(e){return new hd(await super._call(e))}}class Sl extends bl{async _call(e){return new _d(await super._call(e))}}class Cl extends fn{}class El extends Cl{}class Tl extends Cl{}class Fl extends Cl{constructor(e,t,s,n){super(e,t),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.hidden_size/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.hidden_size/this.num_encoder_heads}async generate_speech(e,t,{threshold:s=.5,minlenratio:n=0,maxlenratio:i=20,vocoder:r=null}={}){const o={input_ids:e},{encoder_outputs:a,encoder_attention_mask:l}=await dn(this,o),c=a.dims[1]/this.config.reduction_factor,d=Math.floor(c*i),h=Math.floor(c*n),_=this.config.num_mel_bins;let u=[],p=null,f=null,m=0;for(;;){++m;const e=rn(!!f);let n;n=f?f.output_sequence_out:new se("float32",new Float32Array(_),[1,1,_]);let i={use_cache_branch:e,output_sequence:n,encoder_attention_mask:l,speaker_embeddings:t,encoder_hidden_states:a};this.addPastKeyValues(i,p),f=await Zs(this.decoder_merged_session,i),p=this.getPastKeyValues(f,p);const{prob:r,spectrum:o}=f;if(u.push(o),m>=h&&(Array.from(r.data).filter(e=>e>=s).length>0||m>=d))break}const g=de(u),{waveform:w}=await Zs(r.session,{spectrogram:g});return{spectrogram:g,waveform:w}}}class Pl extends fn{main_input_name="spectrogram"}class Ll extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_encoder_layers=this.num_decoder_layers=this.config.decoder_layers,this.num_encoder_heads=this.num_decoder_heads=this.config.decoder_attention_heads,this.encoder_dim_kv=this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads}}class Il extends Ll{}class Bl extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class Ol extends Bl{}class Nl extends Bl{}class jl extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class $l extends jl{}class Dl extends jl{}class ql extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class Rl extends ql{}class Ul extends ql{}class Gl extends fn{}class Wl extends Gl{}class Vl extends Gl{static async from_pretrained(e,t={}){return t.model_file_name??="text_model",super.from_pretrained(e,t)}}class Xl extends Gl{static async from_pretrained(e,t={}){return t.model_file_name??="audio_model",super.from_pretrained(e,t)}}class Kl extends fn{}class Hl extends Kl{async _call(e){return new wd(await super._call(e))}}class Ql extends fn{}class Yl extends Ql{}class Jl extends Ql{}class Zl extends Ql{}class ec extends fn{constructor(e,t,s){super(e,t),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class tc extends ec{}class sc extends ec{}class nc extends fn{}class ic extends nc{}class rc extends nc{async _call(e){return new dd(await super._call(e))}}class oc{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{quantized:t=!0,progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:o="main",model_file_name:a=null}={}){let l={quantized:t,progress_callback:s,config:n,cache_dir:i,local_files_only:r,revision:o,model_file_name:a};if(n=await Cs.from_pretrained(e,l),l.config||(l.config=n),!this.MODEL_CLASS_MAPPINGS)throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);for(let c of this.MODEL_CLASS_MAPPINGS){const t=c.get(n.model_type);if(t)return await t[1].from_pretrained(e,l)}if(this.BASE_IF_FAIL)return await fn.from_pretrained(e,l);throw Error(`Unsupported model type: ${n.model_type}`)}}const ac=new Map([["bert",["BertModel",yn]],["nomic_bert",["NomicBertModel",An]],["roformer",["RoFormerModel",Sn]],["electra",["ElectraModel",$n]],["esm",["EsmModel",fi]],["convbert",["ConvBertModel",Ln]],["camembert",["CamembertModel",Wn]],["deberta",["DebertaModel",Yn]],["deberta-v2",["DebertaV2Model",ni]],["mpnet",["MPNetModel",Ai]],["albert",["AlbertModel",Oi]],["distilbert",["DistilBertModel",ci]],["roberta",["RobertaModel",hr]],["xlm",["XLMModel",gr]],["xlm-roberta",["XLMRobertaModel",vr]],["clap",["ClapModel",Wl]],["clip",["CLIPModel",Or]],["clipseg",["CLIPSegModel",Vr]],["chinese_clip",["ChineseCLIPModel",Gr]],["siglip",["SiglipModel",Dr]],["mobilebert",["MobileBertModel",xi]],["squeezebert",["SqueezeBertModel",Fi]],["wav2vec2",["Wav2Vec2Model",tl]],["wav2vec2-bert",["Wav2Vec2BertModel",fl]],["unispeech",["UniSpeechModel",ol]],["unispeech-sat",["UniSpeechSatModel",dl]],["hubert",["HubertModel",yl]],["wavlm",["WavLMModel",vl]],["audio-spectrogram-transformer",["ASTModel",Er]],["vits",["VitsModel",Hl]],["detr",["DetrModel",ta]],["table-transformer",["TableTransformerModel",aa]],["vit",["ViTModel",Po]],["fastvit",["FastViTModel",Bo]],["mobilevit",["MobileViTModel",Do]],["mobilevitv2",["MobileViTV2Model",Uo]],["owlvit",["OwlViTModel",Vo]],["owlv2",["Owlv2Model",Ho]],["beit",["BeitModel",Jo]],["deit",["DeiTModel",ha]],["convnext",["ConvNextModel",La]],["convnextv2",["ConvNextV2Model",Oa]],["dinov2",["Dinov2Model",$a]],["resnet",["ResNetModel",pa]],["swin",["SwinModel",ga]],["swin2sr",["Swin2SRModel",xa]],["donut-swin",["DonutSwinModel",Fa]],["yolos",["YolosModel",Ra]],["dpt",["DPTModel",va]],["glpn",["GLPNModel",Ca]],["hifigan",["SpeechT5HifiGan",Pl]],["efficientnet",["EfficientNetModel",ic]]]),lc=new Map([["t5",["T5Model",qi]],["longt5",["LongT5Model",Gi]],["mt5",["MT5Model",Xi]],["bart",["BartModel",Qi]],["mbart",["MBartModel",er]],["marian",["MarianModel",Ha]],["whisper",["WhisperModel",Pr]],["m2m_100",["M2M100Model",Ja]],["blenderbot",["BlenderbotModel",rr]],["blenderbot-small",["BlenderbotSmallModel",lr]]]),cc=new Map([["bloom",["BloomModel",vo]],["gpt2",["GPT2Model",Hr]],["gptj",["GPTJModel",io]],["gpt_bigcode",["GPTBigCodeModel",ao]],["gpt_neo",["GPTNeoModel",Jr]],["gpt_neox",["GPTNeoXModel",to]],["codegen",["CodeGenModel",ho]],["llama",["LlamaModel",po]],["qwen2",["Qwen2Model",go]],["phi",["PhiModel",xo]],["mpt",["MptModel",zo]],["opt",["OPTModel",Eo]],["mistral",["MistralModel",Ol]],["starcoder2",["Starcoder2Model",$l]],["falcon",["FalconModel",Rl]]]),dc=new Map([["speecht5",["SpeechT5ForSpeechToText",Tl]],["whisper",["WhisperForConditionalGeneration",Lr]]]),hc=new Map([["speecht5",["SpeechT5ForTextToSpeech",Fl]]]),_c=new Map([["vits",["VitsModel",Hl]]]),uc=new Map([["bert",["BertForSequenceClassification",kn]],["roformer",["RoFormerForSequenceClassification",En]],["electra",["ElectraForSequenceClassification",qn]],["esm",["EsmForSequenceClassification",gi]],["convbert",["ConvBertForSequenceClassification",Bn]],["camembert",["CamembertForSequenceClassification",Xn]],["deberta",["DebertaForSequenceClassification",Zn]],["deberta-v2",["DebertaV2ForSequenceClassification",ri]],["mpnet",["MPNetForSequenceClassification",Si]],["albert",["AlbertForSequenceClassification",Ni]],["distilbert",["DistilBertForSequenceClassification",di]],["roberta",["RobertaForSequenceClassification",ur]],["xlm",["XLMForSequenceClassification",yr]],["xlm-roberta",["XLMRobertaForSequenceClassification",Ar]],["bart",["BartForSequenceClassification",Ji]],["mbart",["MBartForSequenceClassification",sr]],["mobilebert",["MobileBertForSequenceClassification",bi]],["squeezebert",["SqueezeBertForSequenceClassification",Li]]]),pc=new Map([["bert",["BertForTokenClassification",bn]],["roformer",["RoFormerForTokenClassification",Tn]],["electra",["ElectraForTokenClassification",Rn]],["esm",["EsmForTokenClassification",wi]],["convbert",["ConvBertForTokenClassification",On]],["camembert",["CamembertForTokenClassification",Kn]],["deberta",["DebertaForTokenClassification",ei]],["deberta-v2",["DebertaV2ForTokenClassification",oi]],["mpnet",["MPNetForTokenClassification",Ci]],["distilbert",["DistilBertForTokenClassification",hi]],["roberta",["RobertaForTokenClassification",pr]],["xlm",["XLMForTokenClassification",xr]],["xlm-roberta",["XLMRobertaForTokenClassification",zr]]]),fc=new Map([["t5",["T5ForConditionalGeneration",Ri]],["longt5",["LongT5ForConditionalGeneration",Wi]],["mt5",["MT5ForConditionalGeneration",Ki]],["bart",["BartForConditionalGeneration",Yi]],["mbart",["MBartForConditionalGeneration",tr]],["marian",["MarianMTModel",Qa]],["m2m_100",["M2M100ForConditionalGeneration",Za]],["blenderbot",["BlenderbotForConditionalGeneration",or]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",cr]]]),mc=new Map([["bloom",["BloomForCausalLM",Mo]],["gpt2",["GPT2LMHeadModel",Qr]],["gptj",["GPTJForCausalLM",ro]],["gpt_bigcode",["GPTBigCodeForCausalLM",lo]],["gpt_neo",["GPTNeoForCausalLM",Zr]],["gpt_neox",["GPTNeoXForCausalLM",so]],["codegen",["CodeGenForCausalLM",_o]],["llama",["LlamaForCausalLM",fo]],["qwen2",["Qwen2ForCausalLM",wo]],["phi",["PhiForCausalLM",ko]],["mpt",["MptForCausalLM",So]],["opt",["OPTForCausalLM",To]],["mbart",["MBartForCausalLM",nr]],["mistral",["MistralForCausalLM",Nl]],["starcoder2",["Starcoder2ForCausalLM",Dl]],["falcon",["FalconForCausalLM",Ul]],["trocr",["TrOCRForCausalLM",Il]],["stablelm",["StableLmForCausalLM",sc]]]),gc=new Map([["bert",["BertForMaskedLM",xn]],["roformer",["RoFormerForMaskedLM",Cn]],["electra",["ElectraForMaskedLM",Dn]],["esm",["EsmForMaskedLM",mi]],["convbert",["ConvBertForMaskedLM",In]],["camembert",["CamembertForMaskedLM",Vn]],["deberta",["DebertaForMaskedLM",Jn]],["deberta-v2",["DebertaV2ForMaskedLM",ii]],["mpnet",["MPNetForMaskedLM",zi]],["albert",["AlbertForMaskedLM",$i]],["distilbert",["DistilBertForMaskedLM",ui]],["roberta",["RobertaForMaskedLM",_r]],["xlm",["XLMWithLMHeadModel",wr]],["xlm-roberta",["XLMRobertaForMaskedLM",Mr]],["mobilebert",["MobileBertForMaskedLM",ki]],["squeezebert",["SqueezeBertForMaskedLM",Pi]]]),wc=new Map([["bert",["BertForQuestionAnswering",vn]],["roformer",["RoFormerForQuestionAnswering",Fn]],["electra",["ElectraForQuestionAnswering",Un]],["convbert",["ConvBertForQuestionAnswering",Nn]],["camembert",["CamembertForQuestionAnswering",Hn]],["deberta",["DebertaForQuestionAnswering",ti]],["deberta-v2",["DebertaV2ForQuestionAnswering",ai]],["mpnet",["MPNetForQuestionAnswering",Ei]],["albert",["AlbertForQuestionAnswering",ji]],["distilbert",["DistilBertForQuestionAnswering",_i]],["roberta",["RobertaForQuestionAnswering",fr]],["xlm",["XLMForQuestionAnswering",kr]],["xlm-roberta",["XLMRobertaForQuestionAnswering",Sr]],["mobilebert",["MobileBertForQuestionAnswering",vi]],["squeezebert",["SqueezeBertForQuestionAnswering",Ii]]]),yc=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",Ir]]]),xc=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",Ir]]]),kc=new Map([["vit",["ViTForImageClassification",Lo]],["fastvit",["FastViTForImageClassification",Oo]],["mobilevit",["MobileViTForImageClassification",qo]],["mobilevitv2",["MobileViTV2ForImageClassification",Go]],["beit",["BeitForImageClassification",Zo]],["deit",["DeiTForImageClassification",_a]],["convnext",["ConvNextForImageClassification",Ia]],["convnextv2",["ConvNextV2ForImageClassification",Na]],["dinov2",["Dinov2ForImageClassification",Da]],["resnet",["ResNetForImageClassification",fa]],["swin",["SwinForImageClassification",wa]],["segformer",["SegformerForImageClassification",Jl]],["efficientnet",["EfficientNetForImageClassification",rc]]]),bc=new Map([["detr",["DetrForObjectDetection",sa]],["table-transformer",["TableTransformerForObjectDetection",la]],["yolos",["YolosForObjectDetection",Ua]]]),vc=new Map([["owlvit",["OwlViTForObjectDetection",Xo]],["owlv2",["Owlv2ForObjectDetection",Qo]]]),Mc=new Map([["detr",["DetrForSegmentation",na]],["clipseg",["CLIPSegForImageSegmentation",Xr]]]),Ac=new Map([["segformer",["SegformerForSemanticSegmentation",Zl]]]),zc=new Map([["sam",["SamModel",Va]]]),Sc=new Map([["wav2vec2",["Wav2Vec2ForCTC",sl]],["wav2vec2-bert",["Wav2Vec2BertForCTC",ml]],["unispeech",["UniSpeechForCTC",al]],["unispeech-sat",["UniSpeechSatForCTC",hl]],["wavlm",["WavLMForCTC",Ml]],["hubert",["HubertForCTC",xl]]]),Cc=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",nl]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",gl]],["unispeech",["UniSpeechForSequenceClassification",ll]],["unispeech-sat",["UniSpeechSatForSequenceClassification",_l]],["wavlm",["WavLMForSequenceClassification",Al]],["hubert",["HubertForSequenceClassification",kl]],["audio-spectrogram-transformer",["ASTForAudioClassification",Tr]]]),Ec=new Map([["wavlm",["WavLMForXVector",zl]]]),Tc=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",ul]],["wavlm",["WavLMForAudioFrameClassification",Sl]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",il]]]),Fc=new Map([["vitmatte",["VitMatteForImageMatting",jo]]]),Pc=new Map([["swin2sr",["Swin2SRForImageSuperResolution",ka]]]),Lc=new Map([["dpt",["DPTForDepthEstimation",Ma]],["depth_anything",["DepthAnythingForDepthEstimation",za]],["glpn",["GLPNForDepthEstimation",Ea]]]),Ic=new Map([["clip",["CLIPVisionModelWithProjection",jr]],["siglip",["SiglipVisionModel",Rr]]]),Bc=[[ac,0],[lc,1],[cc,4],[uc,0],[pc,0],[fc,2],[dc,2],[mc,4],[gc,0],[wc,0],[yc,3],[kc,0],[Mc,0],[Ac,0],[Fc,0],[Pc,0],[Lc,0],[bc,0],[vc,0],[zc,5],[Sc,0],[Cc,0],[hc,2],[_c,0],[Ec,0],[Tc,0],[Ic,0]];for(const[a_,l_]of Bc)for(const[e,t]of a_.values())Hs.set(e,l_),Ys.set(t,e),Qs.set(e,t);const Oc=[["CLIPTextModelWithProjection",Nr,0],["SiglipTextModel",qr,0],["ClapTextModelWithProjection",Vl,0],["ClapAudioModelWithProjection",Xl,0]];for(const[a_,l_,c_]of Oc)Hs.set(a_,c_),Ys.set(l_,a_),Qs.set(a_,l_);class Nc extends oc{static MODEL_CLASS_MAPPINGS=Bc.map(e=>e[0]);static BASE_IF_FAIL=!0}class jc extends oc{static MODEL_CLASS_MAPPINGS=[uc]}class $c extends oc{static MODEL_CLASS_MAPPINGS=[pc]}class Dc extends oc{static MODEL_CLASS_MAPPINGS=[fc]}class qc extends oc{static MODEL_CLASS_MAPPINGS=[dc]}class Rc extends oc{static MODEL_CLASS_MAPPINGS=[hc]}class Uc extends oc{static MODEL_CLASS_MAPPINGS=[_c]}class Gc extends oc{static MODEL_CLASS_MAPPINGS=[mc]}class Wc extends oc{static MODEL_CLASS_MAPPINGS=[gc]}class Vc extends oc{static MODEL_CLASS_MAPPINGS=[wc]}class Xc extends oc{static MODEL_CLASS_MAPPINGS=[yc]}class Kc extends oc{static MODEL_CLASS_MAPPINGS=[kc]}class Hc extends oc{static MODEL_CLASS_MAPPINGS=[Mc]}class Qc extends oc{static MODEL_CLASS_MAPPINGS=[Ac]}class Yc extends oc{static MODEL_CLASS_MAPPINGS=[bc]}class Jc extends oc{static MODEL_CLASS_MAPPINGS=[vc]}class Zc extends oc{static MODEL_CLASS_MAPPINGS=[zc]}class ed extends oc{static MODEL_CLASS_MAPPINGS=[Sc]}class td extends oc{static MODEL_CLASS_MAPPINGS=[Cc]}class sd extends oc{static MODEL_CLASS_MAPPINGS=[Ec]}class nd extends oc{static MODEL_CLASS_MAPPINGS=[Tc]}class id extends oc{static MODEL_CLASS_MAPPINGS=[xc]}class rd extends oc{static MODEL_CLASS_MAPPINGS=[Fc]}class od extends oc{static MODEL_CLASS_MAPPINGS=[Pc]}class ad extends oc{static MODEL_CLASS_MAPPINGS=[Lc]}class ld extends oc{static MODEL_CLASS_MAPPINGS=[Ic]}class cd extends mn{constructor({logits:e,past_key_values:t,encoder_outputs:s,decoder_attentions:n=null,cross_attentions:i=null}){super(),this.logits=e,this.past_key_values=t,this.encoder_outputs=s,this.decoder_attentions=n,this.cross_attentions=i}}class dd extends mn{constructor({logits:e}){super(),this.logits=e}}class hd extends mn{constructor({logits:e,embeddings:t}){super(),this.logits=e,this.embeddings=t}}class _d extends mn{constructor({logits:e}){super(),this.logits=e}}class ud extends mn{constructor({logits:e}){super(),this.logits=e}}class pd extends mn{constructor({start_logits:e,end_logits:t}){super(),this.start_logits=e,this.end_logits=t}}class fd extends mn{constructor({logits:e}){super(),this.logits=e}}class md extends mn{constructor({logits:e,past_key_values:t}){super(),this.logits=e,this.past_key_values=t}}class gd extends mn{constructor({alphas:e}){super(),this.alphas=e}}class wd extends mn{constructor({waveform:e,spectrogram:t}){super(),this.waveform=e,this.spectrogram=t}}const yd="undefined"!=typeof self,xd=yd&&"DedicatedWorkerGlobalScope"===self.constructor.name;let kd,bd,vd;if(yd)kd=(e,t)=>{if(!self.OffscreenCanvas)throw new Error("OffscreenCanvas not supported by this browser.");return new self.OffscreenCanvas(e,t)},vd=self.createImageBitmap,bd=self.ImageData;else{if(!_)throw new Error("Unable to load image processing library.");vd=async e=>{const t=(await e.metadata()).channels;let{data:s,info:n}=await e.rotate().raw().toBuffer({resolveWithObject:!0});const i=new zd(new Uint8ClampedArray(s),n.width,n.height,n.channels);return void 0!==t&&t!==n.channels&&i.convert(t),i}}const Md={0:"nearest",1:"lanczos",2:"bilinear",3:"bicubic",4:"box",5:"hamming"},Ad=new Map([["png","image/png"],["jpg","image/jpeg"],["jpeg","image/jpeg"],["gif","image/gif"]]);class zd{constructor(e,t,s,n){this.data=e,this.width=t,this.height=s,this.channels=n}get size(){return[this.width,this.height]}static async read(e){if(e instanceof zd)return e;if("string"==typeof e||e instanceof URL)return await this.fromURL(e);throw new Error("Unsupported input type: "+typeof e)}static async fromURL(e){let t=await F(e);if(200!==t.status)throw new Error(`Unable to read image from "${e}" (${t.status} ${t.statusText})`);let s=await t.blob();return this.fromBlob(s)}static async fromBlob(e){if(yd){let t=await vd(e);const s=kd(t.width,t.height).getContext("2d");return s.drawImage(t,0,0),new this(s.getImageData(0,0,t.width,t.height).data,t.width,t.height,4)}{let t=_(await e.arrayBuffer());return await vd(t)}}static fromTensor(e,t="CHW"){if(3!==e.dims.length)throw new Error(`Tensor should have 3 dimensions, but has ${e.dims.length} dimensions.`);if("CHW"===t)e=e.transpose(1,2,0);else if("HWC"!==t)throw new Error(`Unsupported channel format: ${t}`);if(!(e.data instanceof Uint8ClampedArray||e.data instanceof Uint8Array))throw new Error(`Unsupported tensor type: ${e.type}`);switch(e.dims[2]){case 1:case 2:case 3:case 4:return new zd(e.data,e.dims[1],e.dims[0],e.dims[2]);default:throw new Error(`Unsupported number of channels: ${e.dims[2]}`)}}grayscale(){if(1===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*1);switch(this.channels){case 3:case 4:for(let t=0,s=0;t<this.data.length;t+=this.channels){const n=this.data[t],i=this.data[t+1],r=this.data[t+2];e[s++]=Math.round(.2989*n+.587*i+.114*r)}break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,1)}rgb(){if(3===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*3);switch(this.channels){case 1:for(let t=0,s=0;t<this.data.length;++t)e[s++]=this.data[t],e[s++]=this.data[t],e[s++]=this.data[t];break;case 4:for(let t=0,s=0;t<this.data.length;t+=4)e[s++]=this.data[t],e[s++]=this.data[t+1],e[s++]=this.data[t+2];break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,3)}rgba(){if(4===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*4);switch(this.channels){case 1:for(let t=0,s=0;t<this.data.length;++t)e[s++]=this.data[t],e[s++]=this.data[t],e[s++]=this.data[t],e[s++]=255;break;case 3:for(let t=0,s=0;t<this.data.length;t+=3)e[s++]=this.data[t],e[s++]=this.data[t+1],e[s++]=this.data[t+2],e[s++]=255;break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,4)}async resize(e,t,{resample:s=2}={}){let n=Md[s]??s;if(yd){let s=this.channels,n=this.toCanvas();const i=kd(e,t).getContext("2d");return i.drawImage(n,0,0,e,t),new zd(i.getImageData(0,0,e,t).data,e,t,4).convert(s)}{let s=this.toSharp();switch(n){case"box":case"hamming":"box"!==n&&"hamming"!==n||(n="bilinear");case"nearest":case"bilinear":case"bicubic":s=s.affine([e/this.width,0,0,t/this.height],{interpolator:n});break;case"lanczos":s=s.resize({width:e,height:t,fit:"fill",kernel:"lanczos3"});break;default:throw new Error(`Resampling method ${n} is not supported.`)}return await vd(s)}}async pad([e,t,s,n]){if(e=Math.max(e,0),t=Math.max(t,0),s=Math.max(s,0),n=Math.max(n,0),0===e&&0===t&&0===s&&0===n)return this;if(yd){let i=this.channels,r=this.toCanvas(),o=this.width+e+t,a=this.height+s+n;const l=kd(o,a).getContext("2d");return l.drawImage(r,0,0,this.width,this.height,e,s,o,a),new zd(l.getImageData(0,0,o,a).data,o,a,4).convert(i)}{let i=this.toSharp().extend({left:e,right:t,top:s,bottom:n});return await vd(i)}}async crop([e,t,s,n]){if(e=Math.max(e,0),t=Math.max(t,0),s=Math.min(s,this.width-1),n=Math.min(n,this.height-1),0===e&&0===t&&s===this.width-1&&n===this.height-1)return this;const i=s-e+1,r=n-t+1;if(yd){const s=this.channels,n=this.toCanvas(),o=kd(i,r).getContext("2d");return o.drawImage(n,e,t,i,r,0,0,i,r),new zd(o.getImageData(0,0,i,r).data,i,r,4).convert(s)}{const s=this.toSharp().extract({left:e,top:t,width:i,height:r});return await vd(s)}}async center_crop(e,t){if(this.width===e&&this.height===t)return this;let s=(this.width-e)/2,n=(this.height-t)/2;if(yd){let i=this.channels,r=this.toCanvas();const o=kd(e,t).getContext("2d");let a=0,l=0,c=0,d=0;return s>=0?a=s:c=-s,n>=0?l=n:d=-n,o.drawImage(r,a,l,e,t,c,d,e,t),new zd(o.getImageData(0,0,e,t).data,e,t,4).convert(i)}{let i=this.toSharp();if(s>=0&&n>=0)i=i.extract({left:Math.floor(s),top:Math.floor(n),width:e,height:t});else if(s<=0&&n<=0){let r=Math.floor(-n),o=Math.floor(-s);i=i.extend({top:r,left:o,right:e-this.width-o,bottom:t-this.height-r})}else{let r=[0,0],o=0;n<0?(r[0]=Math.floor(-n),r[1]=t-this.height-r[0]):o=Math.floor(n);let a=[0,0],l=0;s<0?(a[0]=Math.floor(-s),a[1]=e-this.width-a[0]):l=Math.floor(s),i=i.extend({top:r[0],bottom:r[1],left:a[0],right:a[1]}).extract({left:l,top:o,width:e,height:t})}return await vd(i)}}async toBlob(e="image/png",t=1){if(!yd)throw new Error("toBlob() is only supported in browser environments.");const s=this.toCanvas();return await s.convertToBlob({type:e,quality:t})}toTensor(e="CHW"){let t=new se("uint8",new Uint8Array(this.data),[this.height,this.width,this.channels]);if("HWC"===e);else{if("CHW"!==e)throw new Error(`Unsupported channel format: ${e}`);t=t.permute(2,0,1)}return t}toCanvas(){if(!yd)throw new Error("toCanvas() is only supported in browser environments.");let e=this.clone().rgba(),t=kd(e.width,e.height),s=new bd(e.data,e.width,e.height);return t.getContext("2d").putImageData(s,0,0),t}_update(e,t,s,n=null){return this.data=e,this.width=t,this.height=s,null!==n&&(this.channels=n),this}clone(){return new zd(this.data.slice(),this.width,this.height,this.channels)}convert(e){if(this.channels===e)return this;switch(e){case 1:this.grayscale();break;case 3:this.rgb();break;case 4:this.rgba();break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this}async save(e){if(!yd){if(z.useFS){const t=this.toSharp();return await t.toFile(e)}throw new Error("Unable to save the image because filesystem is disabled in this environment.")}{if(xd)throw new Error("Unable to save an image from a Web Worker.");const t=e.split(".").pop().toLowerCase(),s=Ad.get(t)??"image/png",n=await this.toBlob(s),i=URL.createObjectURL(n),r=document.createElement("a");r.href=i,r.download=e,r.click(),r.remove()}}toSharp(){if(yd)throw new Error("toSharp() is only supported in server-side environments.");return _(this.data,{raw:{width:this.width,height:this.height,channels:this.channels}})}}async function Sd(e,t){if("undefined"==typeof AudioContext)throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");const s=await(await F(e)).arrayBuffer(),n=new AudioContext({sampleRate:t}),i=await n.decodeAudioData(s);let r;if(2===i.numberOfChannels){const e=Math.sqrt(2),t=i.getChannelData(0),s=i.getChannelData(1);r=new Float32Array(t.length);for(let n=0;n<i.length;++n)r[n]=e*(t[n]+s[n])/2}else r=i.getChannelData(0);return r}function Cd(e){if(e<1)return new Float64Array;if(1===e)return new Float64Array([1]);const t=e-1,s=Math.PI/t,n=new Float64Array(e);for(let i=0;i<e;++i){const e=2*i-t;n[i]=.5+.5*Math.cos(s*e)}return n}const Ed={htk:e=>2595*Math.log10(1+e/700),kaldi:e=>1127*Math.log(1+e/700),slaney:(e,t=1e3,s=15,n=27/Math.log(6.4))=>e>=t?s+Math.log(e/t)*n:3*e/200};function Td(e,t="htk"){const s=Ed[t];if(!s)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?s(e):e.map(e=>s(e))}const Fd={htk:e=>700*(10**(e/2595)-1),kaldi:e=>700*(Math.exp(e/1127)-1),slaney:(e,t=1e3,s=15,n=Math.log(6.4)/27)=>e>=s?t*Math.exp(n*(e-s)):200*e/3};function Pd(e,t,s){const n=(t-e)/(s-1);return Float64Array.from({length:s},(t,s)=>e+n*s)}function Ld(e,t,s,n,i,r=null,o="htk",a=!1){if(null!==r&&"slaney"!==r)throw new Error('norm must be one of null or "slaney"');const l=Pd(Td(s,o),Td(n,o),t+2);let c,d=function(e,t="htk"){const s=Fd[t];if(!s)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?s(e):e.map(e=>s(e))}(l,o);if(a){const t=i/(2*e);c=Td(Float64Array.from({length:e},(e,s)=>s*t),o),d=l}else c=Pd(0,Math.floor(i/2),e);const h=function(e,t){const s=Float64Array.from({length:t.length-1},(e,s)=>t[s+1]-t[s]),n=Array.from({length:e.length},()=>new Array(t.length));for(let o=0;o<e.length;++o){const s=n[o];for(let n=0;n<t.length;++n)s[n]=t[n]-e[o]}const i=t.length-2,r=Array.from({length:i},()=>new Array(e.length));for(let o=0;o<e.length;++o){const e=n[o];for(let t=0;t<i;++t){const n=-e[t]/s[t],i=e[t+2]/s[t+1];r[t][o]=Math.max(0,Math.min(n,i))}}return r}(c,d);if(null!==r&&"slaney"===r)for(let _=0;_<t;++_){const t=h[_],s=2/(d[_+2]-d[_]);for(let n=0;n<e;++n)t[n]*=s}return h}function Id(e,t,s,n,i){if(s<=0)throw new Error("reference must be greater than zero");if(n<=0)throw new Error("min_value must be greater than zero");s=Math.max(n,s);const r=Math.log10(s);for(let o=0;o<e.length;++o)e[o]=t*Math.log10(Math.max(n,e[o])-r);if(null!==i){if(i<=0)throw new Error("db_range must be greater than zero");const t=V(e)[0]-i;for(let s=0;s<e.length;++s)e[s]=Math.max(e[s],t)}return e}function Bd(e,t,s,n,{fft_length:i=null,power:r=1,center:o=!0,pad_mode:a="reflect",onesided:l=!0,preemphasis:c=null,mel_filters:d=null,mel_floor:_=1e-10,log_mel:u=null,reference:p=1,min_value:f=1e-10,db_range:m=null,remove_dc_offset:g=null,max_num_frames:w=null,do_pad:y=!0,transpose:x=!1}={}){const k=t.length;if(null===i&&(i=s),s>i)throw Error(`frame_length (${s}) may not be larger than fft_length (${i})`);if(k!==s)throw new Error(`Length of the window (${k}) must equal frame_length (${s})`);if(n<=0)throw new Error("hop_length must be greater than zero");if(null===r&&null!==d)throw new Error("You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue.");if(o){if("reflect"!==a)throw new Error(`pad_mode="${a}" not implemented yet.`);const t=Math.floor((i-1)/2)+1;e=function(e,t,s){const n=new e.constructor(e.length+t+s),i=e.length-1;for(let r=0;r<e.length;++r)n[t+r]=e[r];for(let r=1;r<=t;++r)n[t-r]=e[h(r,i)];for(let r=1;r<=s;++r)n[i+t+r]=e[h(i-r,i)];return n}(e,t,t)}const b=Math.floor(1+Math.floor((e.length-s)/n)),v=l?Math.floor(i/2)+1:i;let M=b,A=b;null!==w&&(w>b?y&&(A=w):A=M=w);const z=new Q(i),S=new Float64Array(i),C=new Float64Array(z.outputBufferSize),E=new Array(M);for(let h=0;h<M;++h){const i=h*n;for(let t=0;t<s;++t)S[t]=e[i+t];if(g){let e=0;for(let n=0;n<s;++n)e+=S[n];const t=e/s;for(let n=0;n<s;++n)S[n]-=t}if(null!==c){for(let e=s-1;e>=1;--e)S[e]-=c*S[e-1];S[0]*=1-c}for(let e=0;e<t.length;++e)S[e]*=t[e];z.realTransform(C,S);const r=new Array(v);for(let e=0;e<r.length;++e){const t=e<<1;r[e]=C[t]**2+C[t+1]**2}E[h]=r}if(null!==r&&2!==r){const e=2/r;for(let t=0;t<E.length;++t){const s=E[t];for(let t=0;t<s.length;++t)s[t]**=e}}const T=d.length,F=new Float32Array(T*A),P=x?[A,T]:[T,A];for(let h=0;h<T;++h){const e=d[h];for(let t=0;t<M;++t){const s=E[t];let n=0;for(let t=0;t<v;++t)n+=e[t]*s[t];F[x?t*T+h:h*M+t]=Math.max(_,n)}}if(null!==r&&null!==u){const e=Math.min(F.length,M*T);switch(u){case"log":for(let t=0;t<e;++t)F[t]=Math.log(F[t]);break;case"log10":for(let t=0;t<e;++t)F[t]=Math.log10(F[t]);break;case"dB":if(1===r)!function(e,t=1,s=1e-5,n=null){Id(e,20,t,s,n)}(F,p,f,m);else{if(2!==r)throw new Error(`Cannot use log_mel option '${u}' with power ${r}`);!function(e,t=1,s=1e-10,n=null){Id(e,10,t,s,n)}(F,p,f,m)}break;default:throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${u}'`)}}return{data:F,dims:P}}function Od(e,t,{periodic:s=!0,frame_length:n=null,center:i=!0}={}){const r=s?e+1:e;let o;switch(t){case"boxcar":o=new Float64Array(r).fill(1);break;case"hann":case"hann_window":o=Cd(r);break;case"povey":o=Cd(r).map(e=>Math.pow(e,.85));break;default:throw new Error(`Unknown window type ${t}.`)}if(s&&(o=o.subarray(0,e)),null===n)return o;if(e>n)throw new Error(`Length of the window (${e}) may not be larger than frame_length (${n})`);return o}function Nd([e,t,s,n]){return[e-s/2,t-n/2,e+s/2,t+n/2]}function jd(e,t=.5,s=null,n=!1){const i=e.logits,r=e.pred_boxes,[o,a,l]=i.dims;if(null!==s&&s.length!==o)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let c=[];for(let d=0;d<o;++d){let e=null!==s?s[d]:null,o={boxes:[],classes:[],scores:[]},h=i[d],_=r[d];for(let s=0;s<a;++s){let i,r=h[s],a=[];if(n){i=r.sigmoid().data;for(let e=0;e<i.length;++e)i[e]>t&&a.push(e)}else{let e=V(r.data)[1];if(e===l-1)continue;a.push(e),i=$(r.data)}for(const t of a){let n=_[s].data;n=Nd(n),null!==e&&(n=n.map((t,s)=>t*e[(s+1)%2])),o.boxes.push(n),o.classes.push(t),o.scores.push(i[t])}}c.push(o)}return c}function $d(e,t){if(!(e instanceof Float32Array||e instanceof Float64Array))throw new Error(`${t} expects input to be a Float32Array or a Float64Array, but got ${e?.constructor?.name??typeof e} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}function Dd(e,t,s=0,n=null){const i=e/t;let r=Z(i)*t;return null!==n&&r>n&&(r=Math.floor(i)*t),r<s&&(r=Math.ceil(i)*t),r}function qd([e,t],s){return[Math.max(Math.floor(e/s),1)*s,Math.max(Math.floor(t/s),1)*s]}class Rd extends r{constructor(e){super(),this.config=e}}class Ud extends Rd{constructor(e){super(e),this.image_mean=this.config.image_mean??this.config.mean,this.image_std=this.config.image_std??this.config.std,this.resample=this.config.resample??2,this.do_rescale=this.config.do_rescale??!0,this.rescale_factor=this.config.rescale_factor??1/255,this.do_normalize=this.config.do_normalize,this.do_resize=this.config.do_resize,this.do_thumbnail=this.config.do_thumbnail,this.size=this.config.size,this.size_divisibility=this.config.size_divisibility??this.config.size_divisor,this.do_center_crop=this.config.do_center_crop,this.crop_size=this.config.crop_size,this.do_convert_rgb=this.config.do_convert_rgb??!0,this.do_crop_margin=this.config.do_crop_margin,this.pad_size=this.config.pad_size,this.do_pad=this.config.do_pad,this.do_pad&&!this.pad_size&&this.size&&void 0!==this.size.width&&void 0!==this.size.height&&(this.pad_size=this.size),this.do_flip_channel_order=this.config.do_flip_channel_order??!1}async thumbnail(e,t,s=2){const n=e.height,i=e.width,r=t.height,o=t.width;let a=Math.min(n,r),l=Math.min(i,o);return a===n&&l===i?e:(n>i?l=Math.floor(i*a/n):i>n&&(a=Math.floor(n*l/i)),await e.resize(l,a,{resample:s}))}async crop_margin(e,t=200){const s=e.clone().grayscale(),n=W(s.data)[0],i=V(s.data)[0]-n;if(0===i)return e;const r=t/255;let o=s.width,a=s.height,l=0,c=0;for(let d=0;d<s.height;++d){const e=d*s.width;for(let t=0;t<s.width;++t)(s.data[e+t]-n)/i<r&&(o=Math.min(o,t),a=Math.min(a,d),l=Math.max(l,t),c=Math.max(c,d))}return await e.crop([o,a,l,c])}pad_image(e,t,s,{mode:n="constant",center:i=!1,constant_values:r=0}={}){const[o,a,l]=t;let c,d;if("number"==typeof s?(c=s,d=s):(c=s.width,d=s.height),c!==a||d!==o){const s=new Float32Array(c*d*l);if(Array.isArray(r))for(let e=0;e<s.length;++e)s[e]=r[e%l];else 0!==r&&s.fill(r);const[_,u]=i?[Math.floor((c-a)/2),Math.floor((d-o)/2)]:[0,0];for(let t=0;t<o;++t){const n=(t+u)*c,i=t*a;for(let t=0;t<a;++t){const r=(n+t+_)*l,o=(i+t)*l;for(let t=0;t<l;++t)s[r+t]=e[o+t]}}if("symmetric"===n){if(i)throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");const t=o-1,n=a-1;for(let i=0;i<d;++i){const r=i*c,d=h(i,t)*a;for(let t=0;t<c;++t){if(i<o&&t<a)continue;const c=(r+t)*l,_=(d+h(t,n))*l;for(let t=0;t<l;++t)s[c+t]=e[_+t]}}}e=s,t=[d,c,l]}return[e,t]}rescale(e){for(let t=0;t<e.length;++t)e[t]=this.rescale_factor*e[t]}get_resize_output_image_size(e,t){const[s,n]=e.size;let i,r;if(this.do_thumbnail){const{height:e,width:s}=t;i=Math.min(e,s)}else Number.isInteger(t)?(i=t,r=this.config.max_size??i):void 0!==t&&(i=t.shortest_edge,r=t.longest_edge);if(void 0!==i||void 0!==r){const e=void 0===i?1:Math.max(i/s,i/n),t=s*e,o=n*e,a=void 0===r?1:Math.min(r/t,r/o);let l=Math.floor(Number((t*a).toFixed(2))),c=Math.floor(Number((o*a).toFixed(2)));return void 0!==this.size_divisibility&&([l,c]=qd([l,c],this.size_divisibility)),[l,c]}if(void 0!==t&&void 0!==t.width&&void 0!==t.height){let e=t.width,i=t.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let t=i/n,r=e/s;Math.abs(1-r)<Math.abs(1-t)?t=r:r=t,i=Dd(t*n,this.config.ensure_multiple_of),e=Dd(r*s,this.config.ensure_multiple_of)}return[e,i]}if(void 0!==this.size_divisibility)return qd([s,n],this.size_divisibility);throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`)}async resize(e){const[t,s]=this.get_resize_output_image_size(e,this.size);return await e.resize(t,s,{resample:this.resample})}async preprocess(e,{do_normalize:t=null,do_pad:s=null,do_convert_rgb:n=null,do_convert_grayscale:i=null,do_flip_channel_order:r=null}={}){this.do_crop_margin&&(e=await this.crop_margin(e));const[o,a]=e.size;if(n??this.do_convert_rgb?e=e.rgb():i&&(e=e.grayscale()),this.do_resize&&(e=await this.resize(e)),this.do_thumbnail&&(e=await this.thumbnail(e,this.size,this.resample)),this.do_center_crop){let t,s;Number.isInteger(this.crop_size)?(t=this.crop_size,s=this.crop_size):(t=this.crop_size.width,s=this.crop_size.height),e=await e.center_crop(t,s)}const l=[e.height,e.width];let c=Float32Array.from(e.data),d=[e.height,e.width,e.channels];if(this.do_rescale&&this.rescale(c),t??this.do_normalize){let t=this.image_mean;Array.isArray(this.image_mean)||(t=new Array(e.channels).fill(t));let s=this.image_std;if(Array.isArray(this.image_std)||(s=new Array(e.channels).fill(t)),t.length!==e.channels||s.length!==e.channels)throw new Error(`When set to arrays, the length of \`image_mean\` (${t.length}) and \`image_std\` (${s.length}) must match the number of channels in the image (${e.channels}).`);for(let n=0;n<c.length;n+=e.channels)for(let i=0;i<e.channels;++i)c[n+i]=(c[n+i]-t[i])/s[i]}if(s??this.do_pad)if(this.pad_size){const t=this.pad_image(c,[e.height,e.width,e.channels],this.pad_size);[c,d]=t}else if(this.size_divisibility){const[e,t]=qd([d[1],d[0]],this.size_divisibility);[c,d]=this.pad_image(c,d,{width:e,height:t})}if(r??this.do_flip_channel_order){if(3!==d[2])throw new Error("Flipping channel order is only supported for RGB images.");for(let e=0;e<c.length;e+=3){const t=c[e];c[e]=c[e+2],c[e+2]=t}}return{original_size:[a,o],reshaped_input_size:l,pixel_values:new se("float32",c,d).permute(2,0,1)}}async _call(e,...t){Array.isArray(e)||(e=[e]);const s=await Promise.all(e.map(e=>this.preprocess(e)));return{pixel_values:he(s.map(e=>e.pixel_values),0),original_sizes:s.map(e=>e.original_size),reshaped_input_sizes:s.map(e=>e.reshaped_input_size)}}}class Gd extends Ud{post_process_semantic_segmentation(e,t=null){const s=e.logits,n=s.dims[0];if(null!==t&&t.length!==n)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");const i=[];for(let r=0;r<n;++r){const e=null!==t?t[r]:null;let n=s[r];null!==e&&(n=ie(n,e,"bilinear",!1));const[o,a]=e??n.dims.slice(-2),l=new se("int32",new Int32Array(o*a),[o,a]),c=n[0].data;for(let t=1;t<n.dims[0];++t){const e=n[t].data;for(let s=0;s<e.length;++s)e[s]>c[s]&&(c[s]=e[s],l.data[s]=t)}const d=new Array(n.dims[0]),h=l.data;for(let t=0;t<h.length;++t){const e=h[t];d[e]=e}const _=d.filter(e=>void 0!==e);i.push({segmentation:l,labels:_})}return i}}class Wd extends Ud{}class Vd extends Wd{}class Xd extends Ud{}class Kd extends Ud{}class Hd extends Ud{}class Qd extends Ud{}class Yd extends Ud{}class Jd extends Ud{constructor(e){super(e),this.crop_pct=this.config.crop_pct??.875}async resize(e){const t=this.size?.shortest_edge;if(void 0===t)throw new Error("Size dictionary must contain 'shortest_edge' key.");if(t<384){const s=Math.floor(t/this.crop_pct),[n,i]=this.get_resize_output_image_size(e,{shortest_edge:s});e=await e.resize(n,i,{resample:this.resample}),e=await e.center_crop(t,t)}else e=await e.resize(t,t,{resample:this.resample});return e}}class Zd extends Jd{}class eh extends Ud{}class th extends Ud{}class sh extends Ud{constructor(e){super(e),this.include_top=this.config.include_top??!0,this.include_top&&(this.image_std=this.image_std.map(e=>e*e))}}class nh extends Ud{}class ih extends nh{}class rh extends Ud{post_process_object_detection(...e){return jd(...e)}}class oh extends rh{}class ah extends Ud{}class lh extends Ud{}class ch extends Ud{pad_image(e,t,s,n={}){const[i,r,o]=t;let a=this.image_mean;Array.isArray(this.image_mean)||(a=new Array(o).fill(a));let l=this.image_std;Array.isArray(l)||(l=new Array(o).fill(a));const c=a.map((e,t)=>-e/l[t]);return super.pad_image(e,t,s,{center:!0,constant_values:c,...n})}}class dh extends ch{}class hh extends Ud{async _call(e){const t=await super._call(e),s=[t.pixel_values.dims[0],64,64],n=new se("int64",new BigInt64Array(s.reduce((e,t)=>e*t)).fill(1n),s);return{...t,pixel_mask:n}}post_process_object_detection(...e){return jd(...e)}remove_low_and_no_objects(e,t,s,n){let i=[],r=[],o=[];for(let a=0;a<e.dims[0];++a){let l=e[a],c=t[a],d=V(l.data)[1];if(d===n)continue;let h=$(l.data)[d];h>s&&(i.push(c),r.push(h),o.push(d))}return[i,r,o]}check_segment_validity(e,t,s,n=.5,i=.8){let r=[],o=0,a=0;for(let c=0;c<e.length;++c)e[c]===s&&(r.push(c),++o),t[s].data[c]>=n&&++a;let l=o>0&&a>0;return l&&(l=o/a>i),[l,r]}compute_segments(e,t,s,n,i,r=null,o=null){let[a,l]=o??e[0].dims,c=new se("int32",new Int32Array(a*l),[a,l]),d=[];if(null!==o)for(let p=0;p<e.length;++p)e[p]=ie(e[p],o,"bilinear",!1);let h=new Int32Array(e[0].data.length),_=new Float32Array(e[0].data.length);for(let p=0;p<e.length;++p){let s=t[p];for(let t=0;t<e[p].data.length;++t)e[p].data[t]*=s,e[p].data[t]>_[t]&&(h[t]=p,_[t]=e[p].data[t])}let u=0;for(let p=0;p<s.length;++p){let r=s[p],[o,a]=this.check_segment_validity(h,e,p,n,i);if(o){++u;for(let e of a)c.data[e]=u;d.push({id:u,label_id:r,score:t[p]})}}return[c,d]}post_process_panoptic_segmentation(e,t=.5,s=.5,n=.8,i=null,r=null){null===i&&(i=new Set);const o=e.logits,a=e.pred_masks.sigmoid();let[l,c,d]=o.dims;if(d-=1,null!==r&&r.length!==l)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let h=[];for(let _=0;_<l;++_){let e=null!==r?r[_]:null,l=o[_],c=a[_],[u,p,f]=this.remove_low_and_no_objects(l,c,t,d);if(0===f.length){let[t,s]=e??c.dims.slice(-2),n=new se("int32",new Int32Array(t*s).fill(-1),[t,s]);h.push({segmentation:n,segments_info:[]});continue}let[m,g]=this.compute_segments(u,p,f,s,n,i,e);h.push({segmentation:m,segments_info:g})}return h}post_process_instance_segmentation(){throw Error("Not implemented yet")}}class _h extends Ud{post_process_object_detection(...e){return jd(...e)}}class uh extends Ud{reshape_input_points(e,t,s){let n=a(e=structuredClone(e));if(3===n.length)n=[1,...n],e=[e];else if(4!==n.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let i=0;i<e.length;++i){let n=t[i],r=s[i],o=[r[0]/n[0],r[1]/n[1]];for(let t=0;t<e[i].length;++t)for(let s=0;s<e[i][t].length;++s)for(let n=0;n<e[i][t][s].length;++n)e[i][t][s][n]*=o[n]}return new se("float32",Float32Array.from(e.flat(1/0)),n)}add_input_labels(e,t){let s=a(e);if(2===s.length)s=[1,...s],e=[e];else if(3!==s.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(s.some((e,s)=>e!==t.dims[s]))throw Error(`The first ${s.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new se("int64",e.flat(1/0).map(BigInt),s)}async _call(e,t=null,s=null){const n=await super._call(e);if(t&&(n.input_points=this.reshape_input_points(t,n.original_sizes,n.reshaped_input_sizes)),s){if(!n.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");n.input_labels=this.add_input_labels(s,n.input_points)}return n}post_process_masks(e,t,s,{mask_threshold:n=0,binarize:i=!0,pad_size:r=null}={}){const o=[],a=[(r=r??this.pad_size).height,r.width];for(let l=0;l<t.length;++l){const r=t[l],c=s[l],d=e[l],h=[];for(let e=0;e<d.dims[0];++e){let t=ie(d[e],a,"bilinear",!1);if(t=t.slice(null,[0,c[0]],[0,c[1]]),t=ie(t,r,"bilinear",!1),i){const e=new Uint8Array(t.data.length);for(let s=0;s<t.data.length;++s)t.data[s]>n&&(e[s]=1);t=new se("bool",e,t.dims)}h.push(t)}o.push(he(h))}return o}}class ph extends Ud{pad_image(e,t,s,n={}){const[i,r,o]=t;return super.pad_image(e,t,{width:r+(s-r%s)%s,height:i+(s-i%s)%s},{mode:"symmetric",center:!1,constant_values:-1,...n})}}class fh extends Ud{async _call(e,t){Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);const s=await Promise.all(e.map(e=>this.preprocess(e))),n=await Promise.all(t.map(e=>this.preprocess(e,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0})));return{pixel_values:he(s.map((e,t)=>de([e.pixel_values,n[t].pixel_values],0)),0),original_sizes:s.map(e=>e.original_size),reshaped_input_sizes:s.map(e=>e.reshaped_input_size)}}}class mh extends Rd{constructor(e){super(e),this.config.mel_filters??=Ld(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney"),this.window=Od(this.config.n_fft,"hann")}_extract_fbank_features(e){const{data:t,dims:s}=Bd(e,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:this.config.nb_max_frames}),n=V(t)[0];for(let i=0;i<t.length;++i)t[i]=(Math.max(t[i],n-8)+4)/4;return{data:t,dims:s}}async _call(e){let t;$d(e,"WhisperFeatureExtractor"),e.length>this.config.n_samples?t=e.slice(0,this.config.n_samples):(t=new Float32Array(this.config.n_samples),t.set(e));const{data:s,dims:n}=this._extract_fbank_features(t);return{input_features:new se("float32",s,[1,...n])}}}class gh extends Rd{_zero_mean_unit_var_norm(e){const t=e.reduce((e,t)=>e+t,0)/e.length,s=e.reduce((e,s)=>e+(s-t)**2,0)/e.length;return e.map(e=>(e-t)/Math.sqrt(s+1e-7))}async _call(e){$d(e,"Wav2Vec2FeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=e;this.config.do_normalize&&(t=this._zero_mean_unit_var_norm(t));const s=[1,t.length];return{input_values:new se("float32",t,s),attention_mask:new se("int64",new BigInt64Array(t.length).fill(1n),s)}}}class wh extends Rd{constructor(e){super(e);const t=this.config.sampling_rate,s=Ld(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let n=0;n<s.length;++n)s[n].push(0);this.mel_filters=s,this.window=Od(400,"povey",{periodic:!1})}_extract_fbank_features(e,t){return Bd(e=e.map(e=>32768*e),this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1.192092955078125e-7,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e,{padding:t=!0,pad_to_multiple_of:s=2,do_normalize_per_mel_bins:n=!0,return_attention_mask:i=!0}={}){$d(e,"SeamlessM4TFeatureExtractor");let r,o=this._extract_fbank_features(e,this.config.max_length);if(n){const[e,t]=o.dims;for(let s=0;s<t;++s){let n=0;for(let l=0;l<e;++l)n+=o.data[l*t+s];const i=n/e;let r=0;for(let l=0;l<e;++l)r+=(o.data[l*t+s]-i)**2;r/=e-1;const a=Math.sqrt(r+1e-7);for(let l=0;l<e;++l){const e=l*t+s;o.data[e]=(o.data[e]-i)/a}}}if(t){const[e,t]=o.dims,n=e%s;if(n>0){const s=new Float32Array(t*(e+n));s.set(o.data),s.fill(this.config.padding_value,o.data.length);const a=e+n;o={data:s,dims:[a,t]},i&&(r=new se("int64",new BigInt64Array(a),[1,a]),r.data.fill(1n,0,e))}}const[a,l]=o.dims,c=this.config.stride;if(0!==a%c)throw new Error(`The number of frames (${a}) must be a multiple of the stride (${c}).`);const d=new se("float32",o.data,o.dims).view(1,Math.floor(a/c),l*c),h={input_features:d};if(i){const e=d.dims[1],t=new se("int64",new BigInt64Array(e),[1,e]);if(r)for(let s=1,n=0;s<a;s+=c,++n)t.data[n]=r.data[s];else t.data.fill(1n);h.attention_mask=t}return h}}class yh extends Rd{constructor(e){super(e);const t=this.config.sampling_rate,s=Ld(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let n=0;n<s.length;++n)s[n].push(0);this.mel_filters=s,this.window=Od(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}_extract_fbank_features(e,t){return Bd(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1.192092955078125e-7,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e){$d(e,"ASTFeatureExtractor");const t=this._extract_fbank_features(e,this.config.max_length);if(this.config.do_normalize){const e=2*this.std;for(let s=0;s<t.data.length;++s)t.data[s]=(t.data[s]-this.mean)/e}return{input_values:new se("float32",t.data,[1,...t.dims])}}}class xh extends Rd{constructor(e){super(e),this.mel_filters=Ld(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=Ld(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=Od(this.config.fft_window_size,"hann")}_get_input_mel(e,t,s,n){let i,r=!1;const o=e.length-t;if(o>0){if("rand_trunc"!==s)throw new Error(`Truncation strategy "${s}" not implemented`);{r=!0;const s=Math.floor(Math.random()*(o+1));e=e.subarray(s,s+t),i=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),i.dims=[1,...i.dims]}}else{if(o<0){let s=new Float64Array(t);if(s.set(e),"repeat"===n)for(let n=e.length;n<t;n+=e.length)s.set(e.subarray(0,Math.min(e.length,t-n)),n);else if("repeatpad"===n)for(let t=e.length;t<-o;t+=e.length)s.set(e,t);e=s}if("fusion"===s)throw new Error(`Truncation strategy "${s}" not implemented`);i=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),i.dims=[1,...i.dims]}return{...i,longer:r}}_extract_fbank_features(e,t,s=null){return Bd(e,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:t,log_mel:"dB",max_num_frames:s,do_pad:!1,transpose:!0})}async _call(e,{max_length:t=null}={}){$d(e,"ClapFeatureExtractor");const s=this._get_input_mel(e,t??this.config.nb_max_samples,this.config.truncation,this.config.padding);return{input_features:new se("float32",s.data,[1,...s.dims])}}}class kh extends Rd{}class bh extends r{constructor(e){super(),this.feature_extractor=e}async _call(e,...t){return await this.feature_extractor(e,...t)}}class vh extends bh{async _call(...e){return await this.feature_extractor(...e)}post_process_masks(...e){return this.feature_extractor.post_process_masks(...e)}reshape_input_points(...e){return this.feature_extractor.reshape_input_points(...e)}}class Mh extends bh{async _call(e){return await this.feature_extractor(e)}}class Ah extends bh{async _call(e){return await this.feature_extractor(e)}}class zh extends bh{async _call(e){return await this.feature_extractor(e)}}class Sh extends bh{}class Ch{static FEATURE_EXTRACTOR_CLASS_MAPPING={ImageFeatureExtractor:Ud,WhisperFeatureExtractor:mh,ViTFeatureExtractor:eh,MobileViTFeatureExtractor:nh,MobileViTImageProcessor:ih,OwlViTFeatureExtractor:rh,Owlv2ImageProcessor:oh,CLIPFeatureExtractor:Hd,ChineseCLIPFeatureExtractor:Qd,SiglipImageProcessor:Yd,ConvNextFeatureExtractor:Jd,ConvNextImageProcessor:Zd,SegformerFeatureExtractor:Gd,BitImageProcessor:Xd,DPTImageProcessor:Vd,DPTFeatureExtractor:Wd,GLPNFeatureExtractor:Kd,BeitFeatureExtractor:lh,DeiTFeatureExtractor:ah,DetrFeatureExtractor:hh,YolosFeatureExtractor:_h,DonutFeatureExtractor:ch,NougatImageProcessor:dh,EfficientNetImageProcessor:sh,ViTImageProcessor:th,VitMatteImageProcessor:fh,SamImageProcessor:uh,Swin2SRImageProcessor:ph,Wav2Vec2FeatureExtractor:gh,SeamlessM4TFeatureExtractor:wh,SpeechT5FeatureExtractor:kh,ASTFeatureExtractor:yh,ClapFeatureExtractor:xh};static PROCESSOR_CLASS_MAPPING={WhisperProcessor:Mh,Wav2Vec2ProcessorWithLM:Ah,SamProcessor:vh,SpeechT5Processor:zh,OwlViTProcessor:Sh};static async from_pretrained(e,{progress_callback:t=null,config:s=null,cache_dir:n=null,local_files_only:i=!1,revision:r="main"}={}){let o=s??await B(e,"preprocessor_config.json",!0,{progress_callback:t,cache_dir:n,local_files_only:i,revision:r}),a=o.feature_extractor_type??o.image_processor_type,l=this.FEATURE_EXTRACTOR_CLASS_MAPPING[a];if(!l){if(void 0===o.size)throw new Error(`Unknown Feature Extractor type: ${a}`);l=Ud}return new(this.PROCESSOR_CLASS_MAPPING[o.processor_class]??bh)(new l(o))}}async function Eh(e){return Array.isArray(e)||(e=[e]),await Promise.all(e.map(e=>zd.read(e)))}async function Th(e,t){return Array.isArray(e)||(e=[e]),await Promise.all(e.map(e=>"string"==typeof e||e instanceof URL?Sd(e,t):e instanceof Float64Array?new Float32Array(e):e))}function Fh(e,t){t&&(e=e.map(e=>0|e));const[s,n,i,r]=e;return{xmin:s,ymin:n,xmax:i,ymax:r}}class Ph extends r{constructor({task:e,model:t,tokenizer:s=null,processor:n=null}){super(),this.task=e,this.model=t,this.tokenizer=s,this.processor=n}async dispose(){await this.model.dispose()}}class Lh extends Ph{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),n=await this.model(s),i="multi_label_classification"===this.model.config.problem_type?e=>e.sigmoid().data:e=>$(e.data),r=this.model.config.id2label,o=[];for(const a of n.logits){const e=R(i(a),t).map(e=>({label:r[e[0]],score:e[1]}));1===t?o.push(...e):o.push(e)}return Array.isArray(e)||1===t?o:o[0]}}class Ih extends Ph{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){const s=Array.isArray(e),n=this.tokenizer(s?e:[e],{padding:!0,truncation:!0}),i=(await this.model(n)).logits,r=this.model.config.id2label,o=[];for(let a=0;a<i.dims[0];++a){const e=n.input_ids[a],s=i[a],l=[];for(let n=0;n<s.dims[0];++n){const i=s[n],o=V(i.data)[1],a=r?r[o]:`LABEL_${o}`;if(t.includes(a))continue;const c=this.tokenizer.decode([e[n].item()],{skip_special_tokens:!0});if(""===c)continue;const d=$(i.data);l.push({entity:a,score:d[o],index:n,word:c,start:null,end:null})}o.push(l)}return s?o:o[0]}}class Bh extends Ph{constructor(e){super(e)}async _call(e,t,{topk:s=1}={}){const n=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),i=await this.model(n),r=[];for(let o=0;o<i.start_logits.dims[0];++o){const e=n.input_ids[o],t=e.indexOf(this.tokenizer.sep_token_id),a=d(Array.from($(i.start_logits[o].data)).map((e,t)=>[e,t]).filter(e=>e[1]>t),Array.from($(i.end_logits[o].data)).map((e,t)=>[e,t]).filter(e=>e[1]>t)).filter(e=>e[0][1]<=e[1][1]).map(e=>[e[0][1],e[1][1],e[0][0]*e[1][0]]).sort((e,t)=>t[2]-e[2]);for(let n=0;n<Math.min(a.length,s);++n){const[t,s,i]=a[n],o=[...e].slice(t,s+1),l=this.tokenizer.decode(o,{skip_special_tokens:!0});r.push({answer:l,score:i})}}return 1===s?r[0]:r}}class Oh extends Ph{constructor(e){super(e)}async _call(e,{topk:t=5}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),n=await this.model(s),i=[];for(let r=0;r<s.input_ids.dims[0];++r){const e=s.input_ids[r],o=e.indexOf(this.tokenizer.mask_token_id);if(-1===o)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const a=R($(n.logits[r][o].data),t);i.push(a.map(t=>{const s=[...e];return s[o]=t[0],{score:t[1],token:t[0],token_str:this.tokenizer.model.vocab[t[0]],sequence:this.tokenizer.decode(s,{skip_special_tokens:!0})}}))}return Array.isArray(e)?i:i[0]}}class Nh extends Ph{_key="generated_text";constructor(e){super(e)}async _call(e,t={}){Array.isArray(e)||(e=[e]),this.model.config.prefix&&(e=e.map(e=>this.model.config.prefix+e));const s=this.model.config.task_specific_params;s&&s[this.task]&&s[this.task].prefix&&(e=e.map(e=>s[this.task].prefix+e));const n=this.tokenizer,i={padding:!0,truncation:!0};let r;r=this instanceof $h&&"_build_translation_inputs"in n?n._build_translation_inputs(e,i,t).input_ids:n(e,i).input_ids;const o=await this.model.generate(r,t);return n.batch_decode(o,{skip_special_tokens:!0}).map(e=>({[this._key]:e}))}}class jh extends Nh{_key="summary_text";constructor(e){super(e)}}class $h extends Nh{_key="translation_text";constructor(e){super(e)}}function Dh(e){return Array.isArray(e)&&e.every(e=>"role"in e&&"content"in e)}class qh extends Ph{constructor(e){super(e)}async _call(e,t={}){let s,n=!1,i=!1;if("string"==typeof e)s=e=[e];else if(Array.isArray(e)&&e.every(e=>"string"==typeof e))n=!0,s=e;else{if(Dh(e))e=[e];else{if(!Array.isArray(e)||!e.every(Dh))throw new Error("Input must be a string, an array of strings, a Chat, or an array of Chats");n=!0}i=!0,s=e.map(e=>this.tokenizer.apply_chat_template(e,{tokenize:!1,add_generation_prompt:!0}))}const r=t.add_special_tokens??!1,o=!i&&(t.return_full_text??!0);this.tokenizer.padding_side="left";const{input_ids:a,attention_mask:l}=this.tokenizer(s,{add_special_tokens:r,padding:!0,truncation:!0}),c=await this.model.generate(a,t,null,{inputs_attention_mask:l});let d,h=this.tokenizer.batch_decode(c,{skip_special_tokens:!0});!o&&a.dims.at(-1)>0&&(d=this.tokenizer.batch_decode(a,{skip_special_tokens:!0}).map(e=>e.length));const _=Array.from({length:e.length},e=>[]);for(let u=0;u<h.length;++u){const t=Math.floor(u/c.length*e.length);d&&(h[u]=h[u].slice(d[t])),_[t].push({generated_text:i?[...e[t],{role:"assistant",content:h[u]}]:h[u]})}return n||1!==_.length?_:_[0]}}class Rh extends Ph{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([e,t])=>[e.toLowerCase(),t])),this.entailment_id=this.label2id.entailment,void 0===this.entailment_id&&(this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,void 0===this.contradiction_id&&(this.contradiction_id=0)}async _call(e,t,{hypothesis_template:s="This example is {}.",multi_label:n=!1}={}){const i=Array.isArray(e);i||(e=[e]),Array.isArray(t)||(t=[t]);const r=t.map(e=>s.replace("{}",e)),o=n||1===t.length,a=[];for(const l of e){const e=[];for(const t of r){const s=this.tokenizer(l,{text_pair:t,padding:!0,truncation:!0}),n=await this.model(s);o?e.push([n.logits.data[this.contradiction_id],n.logits.data[this.entailment_id]]):e.push(n.logits.data[this.entailment_id])}const s=(o?e.map(e=>$(e)[1]):$(e)).map((e,t)=>[e,t]).sort((e,t)=>t[0]-e[0]);a.push({sequence:l,labels:s.map(e=>t[e[1]]),scores:s.map(e=>e[0])})}return i?a:a[0]}}class Uh extends Ph{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:s=!1,quantize:n=!1,precision:i="binary"}={}){const r=this.tokenizer(e,{padding:!0,truncation:!0}),o=await this.model(r);let a=o.last_hidden_state??o.logits??o.token_embeddings;if("none"===t);else if("mean"===t)a=re(a,r.attention_mask);else{if("cls"!==t)throw Error(`Pooling method '${t}' not supported.`);a=a.slice(null,0)}return s&&(a=a.normalize(2,-1)),n&&(a=ge(a,i)),a}}class Gh extends Ph{constructor(e){super(e)}async _call(e,{pool:t=null}={}){const s=await Eh(e),{pixel_values:n}=await this.processor(s),i=await this.model({pixel_values:n});let r;if(t){if(!("pooler_output"in i))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");r=i.pooler_output}else r=i.last_hidden_state??i.logits??i.image_embeds;return r}}class Wh extends Ph{constructor(e){super(e)}async _call(e,{topk:t=null}={}){const s=!Array.isArray(e),n=this.processor.feature_extractor.config.sampling_rate,i=await Th(e,n),r=this.model.config.id2label,o=[];for(const a of i){const e=await this.processor(a),s=R($((await this.model(e)).logits[0].data),t).map(e=>({label:r[e[0]],score:e[1]}));1===t?o.push(...s):o.push(s)}return s&&1!==t?o[0]:o}}class Vh extends Ph{constructor(e){super(e)}async _call(e,t,{hypothesis_template:s="This is a sound of {}."}={}){const n=!Array.isArray(e);n&&(e=[e]);const i=t.map(e=>s.replace("{}",e)),r=this.tokenizer(i,{padding:!0,truncation:!0}),o=this.processor.feature_extractor.config.sampling_rate,a=await Th(e,o),l=[];for(const c of a){const e=await this.processor(c),s=$((await this.model({...r,...e})).logits_per_audio.data);l.push([...s].map((e,s)=>({score:e,label:t[s]})))}return n?l[0]:l}}class Xh extends Ph{constructor(e){super(e)}async _call(e,t={}){switch(this.model.config.model_type){case"whisper":return this._call_whisper(e,t);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":return this._call_wav2vec2(e,t);default:throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(e,t={}){t.language,t.task;const s=!Array.isArray(e);s&&(e=[e]);const n=this.processor.feature_extractor.config.sampling_rate,i=await Th(e,n),r=[];for(const o of i){const e=await this.processor(o),t=(await this.model(e)).logits[0],s=[];for(const i of t)s.push(V(i.data)[1]);const n=this.tokenizer.decode(s);r.push({text:n})}return s?r[0]:r}async _call_whisper(e,t={}){const s=t.return_timestamps??!1,n=t.chunk_length_s??0,i=t.chunk_callback??null,r=t.force_full_sequences??!1;let o=t.stride_length_s??null;"word"===s&&(t.return_token_timestamps=!0);const a=l(t,"language",null),c=l(t,"task",null);if(a||c||s){if(t.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const e=this.tokenizer.get_decoder_prompt_ids({language:a,task:c,no_timestamps:!s});e.length>0&&(t.forced_decoder_ids=e)}const d=!Array.isArray(e);d&&(e=[e]);const h=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,_=this.processor.feature_extractor.config.hop_length,u=this.processor.feature_extractor.config.sampling_rate,p=await Th(e,u),f=[];for(const l of p){let e=[];if(n>0){if(null===o)o=n/6;else if(n<=o)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const t=u*n,s=u*o,i=t-2*s;let r=0;for(;r<l.length;){const n=l.subarray(r,r+t),o=await this.processor(n),a=0===r,c=r+i>=l.length;e.push({stride:[n.length,a?0:s,c?0:s],input_features:o.input_features,is_last:c}),r+=i}}else e=[{stride:[l.length,0,0],input_features:(await this.processor(l)).input_features,is_last:!0}];for(const n of e){t.num_frames=Math.floor(n.stride[0]/_);const e=await this.model.generate(n.input_features,t);"word"===s?(n.tokens=e.sequences[0],n.token_timestamps=e.token_timestamps.tolist()[0].map(e=>J(e,2))):n.tokens=e[0],n.stride=n.stride.map(e=>e/u),null!==i&&i(n)}const[a,c]=this.tokenizer._decode_asr(e,{time_precision:h,return_timestamps:s,force_full_sequences:r});f.push({text:a,...c})}return d?f[0]:f}}class Kh extends Ph{constructor(e){super(e)}async _call(e,t={}){const s=Array.isArray(e),n=await Eh(e),{pixel_values:i}=await this.processor(n),r=[];for(const o of i){o.dims=[1,...o.dims];const e=await this.model.generate(o,t),s=this.tokenizer.batch_decode(e,{skip_special_tokens:!0}).map(e=>({generated_text:e.trim()}));r.push(s)}return s?r:r[0]}}class Hh extends Ph{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const s=Array.isArray(e),n=await Eh(e),{pixel_values:i}=await this.processor(n),r=await this.model({pixel_values:i}),o=this.model.config.id2label,a=[];for(const l of r.logits){const e=R($(l.data),t).map(e=>({label:o[e[0]],score:e[1]}));1===t?a.push(...e):a.push(e)}return s||1===t?a:a[0]}}class Qh extends Ph{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:s=.5,overlap_mask_area_threshold:n=.8,label_ids_to_fuse:i=null,target_sizes:r=null,subtask:o=null}={}){if(Array.isArray(e)&&1!==e.length)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const a=await Eh(e),l=a.map(e=>[e.height,e.width]),{pixel_values:c,pixel_mask:d}=await this.processor(a),h=await this.model({pixel_values:c,pixel_mask:d});let _=null;if(null!==o)_=this.subtasks_mapping[o];else for(let[f,m]of Object.entries(this.subtasks_mapping))if(m in this.processor.feature_extractor){_=this.processor.feature_extractor[m].bind(this.processor.feature_extractor),o=f;break}const u=this.model.config.id2label,p=[];if("panoptic"===o||"instance"===o){const e=_(h,t,s,n,i,r??l)[0],o=e.segmentation;for(const t of e.segments_info){const e=new Uint8ClampedArray(o.data.length);for(let n=0;n<o.data.length;++n)o.data[n]===t.id&&(e[n]=255);const s=new zd(e,o.dims[1],o.dims[0],1);p.push({score:t.score,label:u[t.label_id],mask:s})}}else{if("semantic"!==o)throw Error(`Subtask ${o} not supported.`);{const{segmentation:e,labels:t}=_(h,r??l)[0];for(const s of t){const t=new Uint8ClampedArray(e.data.length);for(let i=0;i<e.data.length;++i)e.data[i]===s&&(t[i]=255);const n=new zd(t,e.dims[1],e.dims[0],1);p.push({score:null,label:u[s],mask:n})}}}return p}}class Yh extends Ph{constructor(e){super(e)}async _call(e,t,{hypothesis_template:s="This is a photo of {}"}={}){const n=Array.isArray(e),i=await Eh(e),r=t.map(e=>s.replace("{}",e)),o=this.tokenizer(r,{padding:"siglip"!==this.model.config.model_type||"max_length",truncation:!0}),{pixel_values:a}=await this.processor(i),l=await this.model({...o,pixel_values:a}),c="siglip"===this.model.config.model_type?e=>e.sigmoid().data:e=>$(e.data),d=[];for(const h of l.logits_per_image){const e=[...c(h)].map((e,s)=>({score:e,label:t[s]}));e.sort((e,t)=>t.score-e.score),d.push(e)}return n?d:d[0]}}class Jh extends Ph{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:s=!1}={}){const n=Array.isArray(e);if(n&&1!==e.length)throw Error("Object detection pipeline currently only supports a batch size of 1.");const i=await Eh(e),r=s?null:i.map(e=>[e.height,e.width]),{pixel_values:o,pixel_mask:a}=await this.processor(i),l=await this.model({pixel_values:o,pixel_mask:a}),c=this.processor.feature_extractor.post_process_object_detection(l,t,r),d=this.model.config.id2label,h=c.map(e=>e.boxes.map((t,n)=>({score:e.scores[n],label:d[e.classes[n]],box:Fh(t,!s)})));return n?h:h[0]}}class Zh extends Ph{constructor(e){super(e)}async _call(e,t,{threshold:s=.1,topk:n=null,percentage:i=!1}={}){const r=Array.isArray(e),o=await Eh(e),a=this.tokenizer(t,{padding:!0,truncation:!0}),l=await this.processor(o),c=[];for(let d=0;d<o.length;++d){const e=o[d],r=i?null:[[e.height,e.width]],h=l.pixel_values[d].unsqueeze_(0),_=await this.model({...a,pixel_values:h}),u=this.processor.feature_extractor.post_process_object_detection(_,s,r,!0)[0];let p=u.boxes.map((e,s)=>({score:u.scores[s],label:t[u.classes[s]],box:Fh(e,!i)})).sort((e,t)=>t.score-e.score);null!==n&&(p=p.slice(0,n)),c.push(p)}return r?c:c[0]}}class e_ extends Ph{constructor(e){super(e)}async _call(e,t,s={}){const n=(await Eh(e))[0],{pixel_values:i}=await this.processor(n),r=`<s_docvqa><s_question>${t}</s_question><s_answer>`,o=this.tokenizer(r,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,a=await this.model.generate(i,{...s,decoder_input_ids:o,max_length:this.model.config.decoder.max_position_embeddings}),l=this.tokenizer.batch_decode(a)[0].match(/<s_answer>(.*?)<\/s_answer>/);let c=null;return l&&l.length>=2&&(c=l[1].trim()),[{answer:c}]}}class t_ extends Ph{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(e){super(e),this.vocoder=e.vocoder??null}async _call(e,{speaker_embeddings:t=null}={}){return this.processor?this._call_text_to_spectrogram(e,{speaker_embeddings:t}):this._call_text_to_waveform(e)}async _call_text_to_waveform(e){const t=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:s}=await this.model(t),n=this.model.config.sampling_rate;return{audio:s.data,sampling_rate:n}}async _call_text_to_spectrogram(e,{speaker_embeddings:t}){if(this.vocoder||(this.vocoder=await Nc.from_pretrained(this.DEFAULT_VOCODER_ID,{quantized:!1})),("string"==typeof t||t instanceof URL)&&(t=new Float32Array(await(await fetch(t)).arrayBuffer())),t instanceof Float32Array)t=new se("float32",t,[1,t.length]);else if(!(t instanceof se))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:s}=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:n}=await this.model.generate_speech(s,t,{vocoder:this.vocoder}),i=this.processor.feature_extractor.config.sampling_rate;return{audio:n.data,sampling_rate:i}}}class s_ extends Ph{constructor(e){super(e)}async _call(e){const t=await Eh(e),s=await this.processor(t),n=await this.model(s),i=[];for(const r of n.reconstruction){const e=r.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");i.push(zd.fromTensor(e))}return i.length>1?i:i[0]}}class n_ extends Ph{constructor(e){super(e)}async _call(e){const t=await Eh(e),s=await this.processor(t),{predicted_depth:n}=await this.model(s),i=[];for(let r=0;r<t.length;++r){const e=ie(n[r],t[r].size.reverse(),"bilinear",!1),s=e.mul_(255/V(e.data)[0]).to("uint8");i.push({predicted_depth:n[r],depth:zd.fromTensor(s)})}return i.length>1?i:i[0]}}const i_=Object.freeze({"text-classification":{tokenizer:zs,pipeline:Lh,model:jc,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:zs,pipeline:Ih,model:$c,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:zs,pipeline:Bh,model:Vc,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:zs,pipeline:Oh,model:Wc,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:zs,pipeline:jh,model:Dc,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:zs,pipeline:$h,model:Dc,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:zs,pipeline:Nh,model:Dc,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:zs,pipeline:qh,model:Gc,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:zs,pipeline:Rh,model:jc,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:Wh,model:td,processor:Ch,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:zs,pipeline:Vh,model:Nc,processor:Ch,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:zs,pipeline:Xh,model:[qc,ed],processor:Ch,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:zs,pipeline:t_,model:[Uc,Rc],processor:[Ch,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:zs,pipeline:Kh,model:Xc,processor:Ch,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:Hh,model:Kc,processor:Ch,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:Qh,model:[Hc,Qc],processor:Ch,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:zs,pipeline:Yh,model:Nc,processor:Ch,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:Jh,model:Yc,processor:Ch,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:zs,pipeline:Zh,model:Jc,processor:Ch,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:zs,pipeline:e_,model:id,processor:Ch,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:s_,model:od,processor:Ch,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:n_,model:ad,processor:Ch,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:zs,pipeline:Uh,model:Nc,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:Ch,pipeline:Gh,model:[ld,Nc],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),r_=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function o_(e,t=null,{quantized:s=!0,progress_callback:i=null,config:r=null,cache_dir:o=null,local_files_only:a=!1,revision:l="main",model_file_name:c=null}={}){e=r_[e]??e;const d=i_[e.split("_",1)[0]];if(!d)throw Error(`Unsupported pipeline: ${e}. Must be one of [${Object.keys(i_)}]`);t||(t=d.default.model);const h={quantized:s,progress_callback:i,config:r,cache_dir:o,local_files_only:a,revision:l,model_file_name:c},_=new Map([["tokenizer",d.tokenizer],["model",d.model],["processor",d.processor]]),u=await async function(e,t,s){const n=Object.create(null),i=[];for(let[r,o]of e.entries()){if(!o)continue;let e;e=Array.isArray(o)?new Promise(async(e,n)=>{let i;for(let a of o){if(null===a)return void e(null);try{return void e(await a.from_pretrained(t,s))}catch(r){i=r}}n(i)}):o.from_pretrained(t,s),n[r]=e,i.push(e)}await Promise.all(i);for(let[r,o]of Object.entries(n))n[r]=await o;return n}(_,t,h);return u.task=e,n(i,{status:"ready",task:e,model:t}),new(0,d.pipeline)(u)}export{yh as ASTFeatureExtractor,Tr as ASTForAudioClassification,Er as ASTModel,Cr as ASTPreTrainedModel,$i as AlbertForMaskedLM,ji as AlbertForQuestionAnswering,Ni as AlbertForSequenceClassification,Oi as AlbertModel,Bi as AlbertPreTrainedModel,Pt as AlbertTokenizer,Wh as AudioClassificationPipeline,Cs as AutoConfig,Nc as AutoModel,td as AutoModelForAudioClassification,nd as AutoModelForAudioFrameClassification,ed as AutoModelForCTC,Gc as AutoModelForCausalLM,ad as AutoModelForDepthEstimation,id as AutoModelForDocumentQuestionAnswering,Kc as AutoModelForImageClassification,ld as AutoModelForImageFeatureExtraction,rd as AutoModelForImageMatting,Hc as AutoModelForImageSegmentation,od as AutoModelForImageToImage,Zc as AutoModelForMaskGeneration,Wc as AutoModelForMaskedLM,Yc as AutoModelForObjectDetection,Vc as AutoModelForQuestionAnswering,Qc as AutoModelForSemanticSegmentation,Dc as AutoModelForSeq2SeqLM,jc as AutoModelForSequenceClassification,qc as AutoModelForSpeechSeq2Seq,Rc as AutoModelForTextToSpectrogram,Uc as AutoModelForTextToWaveform,$c as AutoModelForTokenClassification,Xc as AutoModelForVision2Seq,sd as AutoModelForXVector,Jc as AutoModelForZeroShotObjectDetection,Ch as AutoProcessor,zs as AutoTokenizer,Xh as AutomaticSpeechRecognitionPipeline,Yi as BartForConditionalGeneration,Ji as BartForSequenceClassification,Qi as BartModel,Hi as BartPretrainedModel,Vt as BartTokenizer,gn as BaseModelOutput,lh as BeitFeatureExtractor,Zo as BeitForImageClassification,Jo as BeitModel,Yo as BeitPreTrainedModel,xn as BertForMaskedLM,vn as BertForQuestionAnswering,kn as BertForSequenceClassification,bn as BertForTokenClassification,yn as BertModel,wn as BertPreTrainedModel,Ft as BertTokenizer,Xd as BitImageProcessor,or as BlenderbotForConditionalGeneration,rr as BlenderbotModel,ir as BlenderbotPreTrainedModel,cr as BlenderbotSmallForConditionalGeneration,lr as BlenderbotSmallModel,ar as BlenderbotSmallPreTrainedModel,ks as BlenderbotSmallTokenizer,xs as BlenderbotTokenizer,Mo as BloomForCausalLM,vo as BloomModel,bo as BloomPreTrainedModel,Qt as BloomTokenizer,Hd as CLIPFeatureExtractor,Or as CLIPModel,Br as CLIPPreTrainedModel,Xr as CLIPSegForImageSegmentation,Vr as CLIPSegModel,Wr as CLIPSegPreTrainedModel,Nr as CLIPTextModelWithProjection,ms as CLIPTokenizer,jr as CLIPVisionModelWithProjection,Vn as CamembertForMaskedLM,Hn as CamembertForQuestionAnswering,Xn as CamembertForSequenceClassification,Kn as CamembertForTokenClassification,Wn as CamembertModel,Gn as CamembertPreTrainedModel,qt as CamembertTokenizer,fd as CausalLMOutput,md as CausalLMOutputWithPast,Qd as ChineseCLIPFeatureExtractor,Gr as ChineseCLIPModel,Ur as ChineseCLIPPreTrainedModel,Xl as ClapAudioModelWithProjection,xh as ClapFeatureExtractor,Wl as ClapModel,Gl as ClapPreTrainedModel,Vl as ClapTextModelWithProjection,_o as CodeGenForCausalLM,ho as CodeGenModel,co as CodeGenPreTrainedModel,fs as CodeGenTokenizer,Zt as CodeLlamaTokenizer,As as CohereTokenizer,In as ConvBertForMaskedLM,Nn as ConvBertForQuestionAnswering,Bn as ConvBertForSequenceClassification,On as ConvBertForTokenClassification,Ln as ConvBertModel,Pn as ConvBertPreTrainedModel,jt as ConvBertTokenizer,Jd as ConvNextFeatureExtractor,Ia as ConvNextForImageClassification,Zd as ConvNextImageProcessor,La as ConvNextModel,Pa as ConvNextPreTrainedModel,Na as ConvNextV2ForImageClassification,Oa as ConvNextV2Model,Ba as ConvNextV2PreTrainedModel,Wd as DPTFeatureExtractor,Ma as DPTForDepthEstimation,Vd as DPTImageProcessor,va as DPTModel,ba as DPTPreTrainedModel,Jn as DebertaForMaskedLM,ti as DebertaForQuestionAnswering,Zn as DebertaForSequenceClassification,ei as DebertaForTokenClassification,Yn as DebertaModel,Qn as DebertaPreTrainedModel,Bt as DebertaTokenizer,ii as DebertaV2ForMaskedLM,ai as DebertaV2ForQuestionAnswering,ri as DebertaV2ForSequenceClassification,oi as DebertaV2ForTokenClassification,ni as DebertaV2Model,si as DebertaV2PreTrainedModel,Ot as DebertaV2Tokenizer,ah as DeiTFeatureExtractor,_a as DeiTForImageClassification,ha as DeiTModel,da as DeiTPreTrainedModel,za as DepthAnythingForDepthEstimation,Aa as DepthAnythingPreTrainedModel,n_ as DepthEstimationPipeline,hh as DetrFeatureExtractor,sa as DetrForObjectDetection,na as DetrForSegmentation,ta as DetrModel,ia as DetrObjectDetectionOutput,ea as DetrPreTrainedModel,ra as DetrSegmentationOutput,Da as Dinov2ForImageClassification,$a as Dinov2Model,ja as Dinov2PreTrainedModel,ui as DistilBertForMaskedLM,_i as DistilBertForQuestionAnswering,di as DistilBertForSequenceClassification,hi as DistilBertForTokenClassification,ci as DistilBertModel,li as DistilBertPreTrainedModel,Dt as DistilBertTokenizer,e_ as DocumentQuestionAnsweringPipeline,ch as DonutFeatureExtractor,Fa as DonutSwinModel,Ta as DonutSwinPreTrainedModel,rc as EfficientNetForImageClassification,sh as EfficientNetImageProcessor,ic as EfficientNetModel,nc as EfficientNetPreTrainedModel,Dn as ElectraForMaskedLM,Un as ElectraForQuestionAnswering,qn as ElectraForSequenceClassification,Rn as ElectraForTokenClassification,$n as ElectraModel,jn as ElectraPreTrainedModel,Ut as ElectraTokenizer,mi as EsmForMaskedLM,gi as EsmForSequenceClassification,wi as EsmForTokenClassification,fi as EsmModel,pi as EsmPreTrainedModel,is as EsmTokenizer,Q as FFT,Ul as FalconForCausalLM,Rl as FalconModel,ql as FalconPreTrainedModel,ss as FalconTokenizer,Oo as FastViTForImageClassification,Bo as FastViTModel,Io as FastViTPreTrainedModel,Uh as FeatureExtractionPipeline,Rd as FeatureExtractor,Oh as FillMaskPipeline,Kd as GLPNFeatureExtractor,Ea as GLPNForDepthEstimation,Ca as GLPNModel,Sa as GLPNPreTrainedModel,Qr as GPT2LMHeadModel,Hr as GPT2Model,Kr as GPT2PreTrainedModel,Wt as GPT2Tokenizer,lo as GPTBigCodeForCausalLM,ao as GPTBigCodeModel,oo as GPTBigCodePreTrainedModel,ro as GPTJForCausalLM,io as GPTJModel,no as GPTJPreTrainedModel,Zr as GPTNeoForCausalLM,Jr as GPTNeoModel,Yr as GPTNeoPreTrainedModel,so as GPTNeoXForCausalLM,to as GPTNeoXModel,eo as GPTNeoXPreTrainedModel,ns as GPTNeoXTokenizer,os as GemmaTokenizer,as as Grok1Tokenizer,Nt as HerbertTokenizer,xl as HubertForCTC,kl as HubertForSequenceClassification,yl as HubertModel,wl as HubertPreTrainedModel,Hh as ImageClassificationPipeline,Gh as ImageFeatureExtractionPipeline,Ud as ImageFeatureExtractor,gd as ImageMattingOutput,Qh as ImageSegmentationPipeline,s_ as ImageToImagePipeline,Kh as ImageToTextPipeline,fo as LlamaForCausalLM,po as LlamaModel,uo as LlamaPreTrainedModel,Jt as LlamaTokenizer,Wi as LongT5ForConditionalGeneration,Gi as LongT5Model,Ui as LongT5PreTrainedModel,Za as M2M100ForConditionalGeneration,Ja as M2M100Model,Ya as M2M100PreTrainedModel,ds as M2M100Tokenizer,Kt as MBart50Tokenizer,nr as MBartForCausalLM,tr as MBartForConditionalGeneration,sr as MBartForSequenceClassification,er as MBartModel,Zi as MBartPreTrainedModel,Xt as MBartTokenizer,zi as MPNetForMaskedLM,Ei as MPNetForQuestionAnswering,Si as MPNetForSequenceClassification,Ci as MPNetForTokenClassification,Ai as MPNetModel,Mi as MPNetPreTrainedModel,ts as MPNetTokenizer,Ki as MT5ForConditionalGeneration,Xi as MT5Model,Vi as MT5PreTrainedModel,Qa as MarianMTModel,Ha as MarianModel,Ka as MarianPreTrainedModel,ws as MarianTokenizer,ud as MaskedLMOutput,Nl as MistralForCausalLM,Ol as MistralModel,Bl as MistralPreTrainedModel,ki as MobileBertForMaskedLM,vi as MobileBertForQuestionAnswering,bi as MobileBertForSequenceClassification,xi as MobileBertModel,yi as MobileBertPreTrainedModel,Lt as MobileBertTokenizer,nh as MobileViTFeatureExtractor,qo as MobileViTForImageClassification,ih as MobileViTImageProcessor,Do as MobileViTModel,$o as MobileViTPreTrainedModel,Go as MobileViTV2ForImageClassification,Uo as MobileViTV2Model,Ro as MobileViTV2PreTrainedModel,mn as ModelOutput,So as MptForCausalLM,zo as MptModel,Ao as MptPreTrainedModel,cs as NllbTokenizer,An as NomicBertModel,Mn as NomicBertPreTrainedModel,dh as NougatImageProcessor,vs as NougatTokenizer,To as OPTForCausalLM,Eo as OPTModel,Co as OPTPreTrainedModel,Jh as ObjectDetectionPipeline,rh as OwlViTFeatureExtractor,Xo as OwlViTForObjectDetection,Vo as OwlViTModel,Wo as OwlViTPreTrainedModel,Sh as OwlViTProcessor,Qo as Owlv2ForObjectDetection,oh as Owlv2ImageProcessor,Ho as Owlv2Model,Ko as Owlv2PreTrainedModel,ko as PhiForCausalLM,xo as PhiModel,yo as PhiPreTrainedModel,Ph as Pipeline,fn as PreTrainedModel,Tt as PreTrainedTokenizer,Ss as PretrainedConfig,oc as PretrainedMixin,bh as Processor,pd as QuestionAnsweringModelOutput,Bh as QuestionAnsweringPipeline,wo as Qwen2ForCausalLM,go as Qwen2Model,mo as Qwen2PreTrainedModel,rs as Qwen2Tokenizer,zd as RawImage,fa as ResNetForImageClassification,pa as ResNetModel,ua as ResNetPreTrainedModel,Cn as RoFormerForMaskedLM,Fn as RoFormerForQuestionAnswering,En as RoFormerForSequenceClassification,Tn as RoFormerForTokenClassification,Sn as RoFormerModel,zn as RoFormerPreTrainedModel,$t as RoFormerTokenizer,_r as RobertaForMaskedLM,fr as RobertaForQuestionAnswering,ur as RobertaForSequenceClassification,pr as RobertaForTokenClassification,hr as RobertaModel,dr as RobertaPreTrainedModel,Ht as RobertaTokenizer,uh as SamImageProcessor,Xa as SamImageSegmentationOutput,Va as SamModel,Wa as SamPreTrainedModel,vh as SamProcessor,wh as SeamlessM4TFeatureExtractor,Gd as SegformerFeatureExtractor,Jl as SegformerForImageClassification,Zl as SegformerForSemanticSegmentation,Yl as SegformerModel,Ql as SegformerPreTrainedModel,cd as Seq2SeqLMOutput,dd as SequenceClassifierOutput,Yd as SiglipImageProcessor,Dr as SiglipModel,$r as SiglipPreTrainedModel,qr as SiglipTextModel,gs as SiglipTokenizer,Rr as SiglipVisionModel,kh as SpeechT5FeatureExtractor,Tl as SpeechT5ForSpeechToText,Fl as SpeechT5ForTextToSpeech,Pl as SpeechT5HifiGan,El as SpeechT5Model,Cl as SpeechT5PreTrainedModel,zh as SpeechT5Processor,bs as SpeechT5Tokenizer,Pi as SqueezeBertForMaskedLM,Ii as SqueezeBertForQuestionAnswering,Li as SqueezeBertForSequenceClassification,Fi as SqueezeBertModel,Ti as SqueezeBertPreTrainedModel,It as SqueezeBertTokenizer,sc as StableLmForCausalLM,tc as StableLmModel,ec as StableLmPreTrainedModel,Dl as Starcoder2ForCausalLM,$l as Starcoder2Model,jl as Starcoder2PreTrainedModel,jh as SummarizationPipeline,ka as Swin2SRForImageSuperResolution,ph as Swin2SRImageProcessor,xa as Swin2SRModel,ya as Swin2SRPreTrainedModel,wa as SwinForImageClassification,ga as SwinModel,ma as SwinPreTrainedModel,Ri as T5ForConditionalGeneration,qi as T5Model,Di as T5PreTrainedModel,Gt as T5Tokenizer,la as TableTransformerForObjectDetection,aa as TableTransformerModel,ca as TableTransformerObjectDetectionOutput,oa as TableTransformerPreTrainedModel,se as Tensor,Nh as Text2TextGenerationPipeline,Lh as TextClassificationPipeline,qh as TextGenerationPipeline,t_ as TextToAudioPipeline,Ih as TokenClassificationPipeline,_d as TokenClassifierOutput,Pe as TokenizerModel,Il as TrOCRForCausalLM,Ll as TrOCRPreTrainedModel,$h as TranslationPipeline,al as UniSpeechForCTC,ll as UniSpeechForSequenceClassification,ol as UniSpeechModel,rl as UniSpeechPreTrainedModel,ul as UniSpeechSatForAudioFrameClassification,hl as UniSpeechSatForCTC,_l as UniSpeechSatForSequenceClassification,dl as UniSpeechSatModel,cl as UniSpeechSatPreTrainedModel,eh as ViTFeatureExtractor,Lo as ViTForImageClassification,th as ViTImageProcessor,Po as ViTModel,Fo as ViTPreTrainedModel,Ir as VisionEncoderDecoderModel,jo as VitMatteForImageMatting,fh as VitMatteImageProcessor,No as VitMattePreTrainedModel,Hl as VitsModel,wd as VitsModelOutput,Kl as VitsPreTrainedModel,Ms as VitsTokenizer,ml as Wav2Vec2BertForCTC,gl as Wav2Vec2BertForSequenceClassification,fl as Wav2Vec2BertModel,pl as Wav2Vec2BertPreTrainedModel,ys as Wav2Vec2CTCTokenizer,gh as Wav2Vec2FeatureExtractor,il as Wav2Vec2ForAudioFrameClassification,sl as Wav2Vec2ForCTC,nl as Wav2Vec2ForSequenceClassification,tl as Wav2Vec2Model,el as Wav2Vec2PreTrainedModel,Ah as Wav2Vec2ProcessorWithLM,Sl as WavLMForAudioFrameClassification,Ml as WavLMForCTC,Al as WavLMForSequenceClassification,zl as WavLMForXVector,vl as WavLMModel,bl as WavLMPreTrainedModel,mh as WhisperFeatureExtractor,Lr as WhisperForConditionalGeneration,Pr as WhisperModel,Fr as WhisperPreTrainedModel,Mh as WhisperProcessor,ps as WhisperTokenizer,kr as XLMForQuestionAnswering,yr as XLMForSequenceClassification,xr as XLMForTokenClassification,gr as XLMModel,mr as XLMPreTrainedModel,Mr as XLMRobertaForMaskedLM,Sr as XLMRobertaForQuestionAnswering,Ar as XLMRobertaForSequenceClassification,zr as XLMRobertaForTokenClassification,vr as XLMRobertaModel,br as XLMRobertaPreTrainedModel,es as XLMRobertaTokenizer,Rt as XLMTokenizer,wr as XLMWithLMHeadModel,hd as XVectorOutput,_h as YolosFeatureExtractor,Ua as YolosForObjectDetection,Ra as YolosModel,Ga as YolosObjectDetectionOutput,qa as YolosPreTrainedModel,Vh as ZeroShotAudioClassificationPipeline,Rh as ZeroShotClassificationPipeline,Yh as ZeroShotImageClassificationPipeline,Zh as ZeroShotObjectDetectionPipeline,Z as bankers_round,de as cat,U as cos_sim,q as dot,pe as dynamicTimeWarping,z as env,R as getTopItems,Cd as hanning,ie as interpolate,N as interpolate_data,oe as layer_norm,D as log_softmax,G as magnitude,V as max,ue as mean,re as mean_pooling,Y as medianFilter,Ld as mel_filter_bank,W as min,fe as ones,me as ones_like,ne as permute,j as permute_data,o_ as pipeline,ge as quantize_embeddings,Sd as read_audio,J as round,$ as softmax,Bd as spectrogram,he as stack,_e as std_mean,Od as window_function};
//# sourceMappingURL=transformers-CDIsii5h.js.map
