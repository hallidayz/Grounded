{"version":3,"mappings":";ikCAoRO,SAASA,IAUd,OAnHF,SACEC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,GAEA,MAAMC,EAAmB,GACnBC,EAA4B,GAClC,IAAIC,GAAW,EACXC,EAA8D,WAuElE,OApEKX,IACHQ,EAAOI,KAAK,sCACZH,EAAgBG,KAAK,kEACrBF,GAAW,EACXC,EAAoB,mBAIjBV,IACHO,EAAOI,KAAK,yCACPZ,GACHS,EAAgBG,KAAK,uGAKpBT,IACHK,EAAOI,KAAK,gCACZH,EAAgBG,KAAK,kDACrBF,GAAW,EACXC,EAAoB,eAIP,OAAXP,IACEA,EAAS,MACXI,EAAOI,KAAK,+BAA+BC,KAAKC,MAAMV,SACtDK,EAAgBG,KAAK,kDACrBD,EAAoB,cACXP,EAAS,OAClBI,EAAOI,KAAK,0BAA0BC,KAAKC,MAAMV,SACjDK,EAAgBG,KAAK,wDACK,aAAtBD,IACFA,EAAoB,gBAMrBT,IACHM,EAAOI,KAAK,2BACZH,EAAgBG,KAAK,oDACK,aAAtBD,IACFA,EAAoB,aAKL,WAAfN,GAAsC,OAAXD,GAAmBA,EAAS,OACzDI,EAAOI,KAAK,qCACZH,EAAgBG,KAAK,uDACK,aAAtBD,IACFA,EAAoB,eAKnBR,EAGOH,GAAsBC,IAEhCS,GAAW,EACXC,EAAoB,oBALpBD,GAAW,EACXC,EAAoB,eASf,CACLX,oBACAC,sBACAC,SACAC,OACAY,gBAAiBX,EACjBC,aACAC,UACAC,KACAS,aAXmBb,IAASH,GAAqBC,GAYjDO,SACAC,kBACAC,WACAC,oBAEJ,CAgBSM,CA9PT,WACE,IAEE,MAAoC,oBAAtBC,iBAChB,OACE,OAAO,CACT,CACF,CA8O4BC,GAxO5B,WACE,IAEE,OAA6C,IAArCC,KAAanB,mBACvB,OACE,OAAO,CACT,CACF,CAkO8BoB,GA7N9B,WACE,IACE,MAAO,QAASC,gBAA+B,IAAlBA,UAAUC,GACzC,OACE,OAAO,CACT,CACF,CAwNiBC,GAnNjB,WACE,IACE,MAA8B,oBAAhBC,aAC4B,mBAA5BA,YAAYC,WAC5B,OACE,OAAO,CACT,CACF,CA6MeC,GAvMf,WACE,IAEE,GAAI,iBAAkBL,WAAaA,UAAUM,aAE3C,OAAgC,KAAzBN,UAAUM,aAInB,MAAMC,EAAKP,UAAUQ,UAAUC,cAG/B,MAFiB,kEAAkEC,KAAKH,GAI/E,KAIF,IACT,OACE,OAAO,IACT,CACF,CAkLiBI,GA7KjB,WACE,IACE,MAAMJ,EAAKP,UAAUQ,UAAUC,cAE/B,MAAI,6BAA6BC,KAAKH,GAC7B,SAGL,6DAA6DG,KAAKH,GAC7D,SAGL,2BAA2BG,KAAKH,GAC3B,UAGF,SACT,OACE,MAAO,SACT,CACF,CA0JqBK,GArJrB,WACE,IACE,MAAML,EAAKP,UAAUQ,UAErB,OAAID,EAAGM,SAAS,YAAcN,EAAGM,SAAS,OAAe,SACrDN,EAAGM,SAAS,WAAmB,UAC/BN,EAAGM,SAAS,YAAcN,EAAGM,SAAS,UAAkB,SACxDN,EAAGM,SAAS,OAAe,OAC3BN,EAAGM,SAAS,UAAYN,EAAGM,SAAS,OAAe,QAEhD,SACT,OACE,MAAO,SACT,CACF,CAwIkBC,GAnIlB,WACE,IACE,MAAMP,EAAKP,UAAUQ,UAErB,OAAID,EAAGM,SAAS,WAAmB,UAC/BN,EAAGM,SAAS,UAAkB,QAC9BN,EAAGM,SAAS,SAAiB,QAC7BN,EAAGM,SAAS,WAAmB,UAC/BN,EAAGM,SAAS,QAAUN,EAAGM,SAAS,WAAaN,EAAGM,SAAS,QAAgB,MAExE,SACT,OACE,MAAO,SACT,CACF,CAsHaE,GAYb,CAKO,SAASC,EAAwBC,GACtC,OAAKA,EAAO7B,SAIqB,gBAA7B6B,EAAO5B,kBACF,oDAGwB,oBAA7B4B,EAAO5B,kBACF,+FAGwB,eAA7B4B,EAAO5B,kBACF,wDAGwB,aAA7B4B,EAAO5B,kBACF,qEAGF,+CAnBE,qDAoBX,CCnTA,IAAI6B,EAAiC,CACnCC,SAAU,EACVC,OAAQ,OACRC,MAAO,IAGT,MAAMC,MAAuCC,IAKtC,SAASC,EAAoBC,GAYlC,OAVAC,MAAM,oEAAoE,CAACC,OAAO,OAAOC,QAAQ,CAAC,eAAe,oBAAoBC,KAAKC,KAAKC,UAAU,CAACC,SAAS,wBAAwBC,QAAQ,6BAA6BC,KAAK,CAACC,cAAcjB,EAAgBE,OAAOgB,aAAalB,EAAgBG,MAAMH,gBAAgBA,EAAgBC,UAAUkB,UAAUC,KAAKC,MAAMC,UAAU,gBAAgBC,MAAM,OAAOC,aAAa,QAAQC,MAAM,QAE/arB,EAAUsB,IAAInB,GAGdC,MAAM,oEAAoE,CAACC,OAAO,OAAOC,QAAQ,CAAC,eAAe,oBAAoBC,KAAKC,KAAKC,UAAU,CAACC,SAAS,wBAAwBC,QAAQ,mDAAmDC,KAAK,CAACd,OAAOF,EAAgBE,OAAOC,MAAMH,EAAgBG,MAAMF,SAASD,EAAgBC,UAAUkB,UAAUC,KAAKC,MAAMC,UAAU,gBAAgBC,MAAM,OAAOC,aAAa,QAAQC,MAAM,QAEhblB,EAASP,GAGF,KACLI,EAAUuB,OAAOpB,GAErB,CAKA,SAASqB,EAAeC,GACtB7B,EAAkB6B,EAClBzB,EAAU0B,QAAQvB,IAChB,IACEA,EAASsB,EACX,OAASE,GAET,GAEJ,CAKO,SAASC,EAAwB/B,EAAkBE,EAAe8B,GACvEL,EAAe,CACb3B,SAAU5B,KAAK6D,IAAI,EAAG7D,KAAK8D,IAAI,IAAKlC,IACpCC,OAAQ,UACRC,QACA8B,WAEJ,CAiBO,SAASG,EAAiBjC,EAAgB,QAAS8B,GACxDL,EAAe,CACb3B,SAAUD,EAAgBC,SAC1BC,OAAQ,QACRC,QACA8B,WAEJ,CC3EO,MAAMI,EAMR,CACHC,WAAY,CACVC,KAAM,aACNC,KAAM,yDACNC,KAAM,sBACNC,YAAa,kDACbC,KAAM,SAERC,UAAW,CACTL,KAAM,YACNC,KAAM,kCACNC,KAAM,kBACNC,YAAa,oEACbC,KAAM,UAERE,QAAS,CACPN,KAAM,UACNC,KAAM,2BACNC,KAAM,kBACNC,YAAa,2DACbC,KAAM,WAQV,IAAIG,EAAwB,KACxBC,EAA4B,KAC5BC,MAA4CC,IAC5CC,EAN+B,YAO/BC,GAAiB,EACjBC,EAA4C,KAC5CC,EAAkD,KAClDC,EAA+F,KAK5F,SAASC,IACd,OAAOT,CACT,CAEO,SAASU,IACd,OAAOT,CACT,CAEO,SAASU,IACd,OAAON,CACT,CAqCO,SAASO,EAAiBC,GAC/BT,EAAgBS,CAClB,CAYO,SAASC,IACd,OAAOvB,CACT,CAKAwB,eAAsBC,IAQpB,GAPAhB,EAAmB,KACnBC,EAAuB,KACvBC,EAAee,QACfZ,GAAiB,EACjBC,EAAmB,KAGf,WAAYY,OAAQ,CACtB,MAAMC,QAAkBC,OAAOC,OAC/B,UAAWC,KAAOH,GACZG,EAAIzE,SAAS,iBAAmByE,EAAIzE,SAAS,UAAYyE,EAAIzE,SAAS,gBAClEuE,OAAOvC,OAAOyC,EAG1B,CACF,CAUAP,eAAsBQ,EAAiBC,GAAuB,EAAOX,GAE/DA,GAAaA,IAAcT,IAC7BA,EAAgBS,GAEZb,GAAoBC,KACtBuB,GAAc,IAIlB,MAAMC,EAAcZ,GAAaT,EAOjC,GALIoB,SACIR,IAIJhB,GAAoBC,GAAwBG,IAAkBqB,IAAgBD,EAChF,OAAO,EAGT,GAAInB,GAAkBC,IAAqBkB,EAEzC,IAEE,aADMlB,EACsB,OAArBN,GAAsD,OAAzBC,CACtC,OACE,OAAO,CACT,CAIEY,GAAaA,IAAcT,IAC7BA,EAAgBS,GAGlBR,GAAiB,EAGjB,IAAIqB,EAAwC,KA+Y5C,OA9YAA,EAAiBC,WAAW,KACtBtB,IAEFA,GAAiB,EACjBf,EAAiB,wBAAyB,+DAE3C,KAEHgB,EAAA,WACE,IAUE,GARAC,EAAsB9F,IACtB+F,EAAoB,KAGJxD,EAAwBuD,IAInCA,EAAoBnF,SAUvB,OARKmF,EAAoB1F,KAEb0F,EAAoB7F,oBAC9B8F,EAAoB,aAFpBA,EAAoB,OAKtBH,GAAiB,EACjBf,EAAiB,wBAAyB,mFACnC,EAWT,IAAIsC,EAPkB,oBAAXV,SACRA,OAAeW,qBAAwBX,OAAeW,sBAAwB,IAQjF,IAKE,GAHAD,QAAqBE,EAAA,IAAMC,OAAO,8BAAsBC,2BAGnDJ,IAAuBA,EAAmBK,SAE7C,OAAO,CAEX,OAASC,GAEP,MAAMC,EAAWD,GAAajE,SAAWmE,OAAOF,GAC1CG,EAAaH,GAAaI,OAAS,GAsBzC,OAnBIH,EAAStF,SAAS,oBAAsBsF,EAAStF,SAAS,YAAcwF,EAAWxF,SAAS,YAC9F2D,EAAoB,YAEhBD,GAAwBA,EAAoB7F,mBAKhD8F,EADS2B,EAAStF,SAAS,WAAasF,EAAStF,SAAS,QAAUsF,EAAStF,SAAS,iBAClE,SAGXsF,EAAStF,SAAS,YAAcsF,EAAStF,SAAS,UAAYsF,EAAStF,SAAS,mBACrE,UAIA,WAGf,CACT,CAEA,MAAMoF,SAAEA,EAAAM,IAAUA,GAAQX,EAG1B,IAAKK,IAAaM,EAChB,MAAM,IAAIC,MAAM,8CAIlB,GAAwB,mBAAbP,EACT,MAAM,IAAIO,MAAM,0DAKlB,IAsBE,GArBAD,EAAIE,kBAAmB,EACvBF,EAAIG,mBAAoB,EACxBH,EAAII,iBAAkB,EACtBJ,EAAIK,gBAAiB,EAWrBL,EAAIM,SAAW,iBACfN,EAAII,iBAAkB,EACtBJ,EAAIG,mBAAoB,EAKpBnC,EAAqB,CAEvB,IAAKA,EAAoB3F,OACvB,IACE2H,EAAIO,SAAWP,EAAIO,UAAY,EAGjC,OAASC,GAET,CAIGxC,EAAoB7F,iBAI3B,CACF,OAASsI,GAGT,OAGM,IAAIC,QAAQC,GAAWvB,WAAWuB,EAAS,MAajD,IAAIC,EAAgB,EAChBC,EAAe,EACnB,MAAMC,EAAc,EAEdC,EAAoBnG,IACxB,GAAwB,aAApBA,EAASC,OAAuB,CAClC,MAAMmG,EAAUpG,EAASA,SAAW5B,KAAKC,MAA0B,IAApB2B,EAASA,UAAkB,EACpEqG,EAAgBjI,KAAKC,MAAO4H,EAAeC,EAAe,IAAOE,EAAUF,GACjFF,EAAgB5H,KAAK8D,IAAI,IAAKmE,GAE9B,MAAMC,EAAYtG,EAASsC,MAAQ,QACnCP,EACEiE,EACA,uBACA,GAAGM,MAAcF,KAGrB,SAA+B,SAApBpG,EAASC,OAAmB,CACrCgG,IACA,MAAMI,EAAgBjI,KAAKC,MAAO4H,EAAeC,EAAe,KAChEF,EAAgB5H,KAAK8D,IAAI,IAAKmE,GAE9B,MAAMC,EAAYtG,EAASsC,MAAQ,QACnCP,EACEiE,EACA,uBACA,GAAGM,WAGP,GAIIC,EAAcnE,EAAckC,GAKA,gBADjBlB,GAAqBlF,mBAAqB,aACiC,OAAzCkF,GAAqB9E,iBAA4B8E,EAAoB9E,gBAQxH,IAEEuE,QAAyBiC,EACvByB,EAAY/D,KACZ+D,EAAYhE,KACZ,CACEiE,WAAW,EACXC,kBAAmBN,IAMvBpD,EAAe2D,IAAIpC,EAAazB,EAClC,OAAS8D,GACP,MAAM3B,EAAW2B,GAAY7F,SAAWmE,OAAO0B,GACzCzB,EAAayB,GAAYxB,OAAS,GAGjBH,EAAStF,SAAS,oBAClBsF,EAAStF,SAAS,YAClBwF,EAAWxF,SAAS,YACpBsF,EAAStF,SAAS,2BAGvC2D,EAAoB,YAEhBD,GAAwBA,EAAoB7F,kBAIhDsF,EAAmB,MACVmC,EAAStF,SAAS,WAAasF,EAAStF,SAAS,QAC1D2D,EAAoB,SAEpBR,EAAmB,OAEnBQ,EAAoB,UAEpBR,EAAmB,KAEvB,CAMA,IAAI+D,GAAgB,EACpB,GAAI/D,EACF,IAEoB,oBADCA,EAAyBL,OAE1CoE,GAAgB,EAGpB,OACEA,GAAgB,CAClB,CAGF,GAAKA,EAiDH9D,EAAuBD,MAjDL,CAGlB,MAAMgE,EAAsC,eAAhBvC,EAA+B,YAAcA,EACnEwC,EAAmB1E,EAAcyE,GAGvC,GAAI9D,EAAegE,IAAIF,GACrB/D,EAAuBC,EAAeiE,IAAIH,QAG1C,IAEE/D,QAA6BgC,EAC3B,kBACAgC,EAAiBvE,KACjB,CACEiE,WAAW,EACXC,kBAAmBN,IAMvBpD,EAAe2D,IAAIG,EAAqB/D,EAC1C,OAASmE,GACP,MAAMC,EAAgBD,GAAiBnG,SAAWmE,OAAOgC,GACnDE,EAAkBF,GAAiB9B,OAAS,GACjB+B,EAAcxH,SAAS,oBACxBwH,EAAcxH,SAAS,YACvByH,EAAgBzH,SAAS,YAGvD2D,EAAoB,YAEpBP,EAAuB,MACdoE,EAAcxH,SAAS,WAAawH,EAAcxH,SAAS,QACpE2D,EAAoB,SAEpBP,EAAuB,OAEvBO,EAAoB,UAEpBP,EAAuB,KAE3B,CAEJ,CAYA,MAAMsE,EAAmC,OAArBvE,GAAsD,OAAzBC,EAwBjD,OAvBIyB,gBAA6BA,GACjCrB,GAAiB,EAEbkE,ED7bH,SAA4BlH,EAAgB,YACjDyB,EAAe,CACb3B,SAAU,IACVC,OAAQ,UACRC,QACA8B,QCybyD,+BDvb7D,CCubQqF,CAAmB,kCAKnBlF,EAAiB,wBAAyB,qCAcrCiF,CACT,OAAStF,GACHyC,gBAA6BA,GAEjCrB,GAAiB,EACjBL,EAAmB,KACnBC,EAAuB,KACvBX,EAAiB,uBAAwB,qCAGzC,MAAMmF,EAAexF,aAAiBuD,MAAQvD,EAAMhB,QAAUmE,OAAOnD,GA2CrE,OAzCKuB,IAGDA,EADEiE,EAAa5H,SAAS,oBAAsB4H,EAAa5H,SAAS,YAAc4H,EAAa5H,SAAS,WACpF,YACX4H,EAAa5H,SAAS,WAAa4H,EAAa5H,SAAS,QAAU4H,EAAa5H,SAAS,iBAC9E,SACX4H,EAAa5H,SAAS,YAAc4H,EAAa5H,SAAS,UAAY4H,EAAa5H,SAAS,mBACjF,UACX4H,EAAa5H,SAAS,gBAAkB4H,EAAa5H,SAAS,QACnD,OAEA,WAMjB,cADC2D,GAGAD,GAAwBA,EAAoB7F,mBAsB7C,CACT,CACF,EApYA,GAsYO4F,CACT,CAMAS,eAAsB2D,IAGpB,IAEE,GAAIC,IAEF,OAAO,EAIT,IAAIC,EAAW,EACf,MAAMC,EAAc,EACpB,IAAIC,EAAiB,KAErB,KAAOF,EAAWC,GAAa,CAC7BD,IAOA,IAEE,SADqBrD,IAGnB,OAAO,EAISd,IACMC,GAM1B,OAASzB,GACP6F,EAAY7F,EACKA,aAAiBuD,MAAQvD,EAAMhB,QAAUmE,OAAOnD,EAInE,CAEA,GAAI2F,EAAWC,EAAa,CAE1B,MAAME,EAAQxJ,KAAK8D,IAAI,IAAO9D,KAAKyJ,IAAI,EAAGJ,EAAW,GAAI,WACnD,IAAI3B,QAAQC,GAAWvB,WAAWuB,EAAS6B,GACnD,CACF,CAGA,MAAME,EAAiBxE,IACjByE,EAAuBxE,IAE7B,GAAIuE,GAAkBC,QAOpB,GAAIJ,EAAW,CACb,MAAM3C,EAAW2C,aAAqBtC,MAAQsC,EAAU7G,QAAUmE,OAAO0C,GACrE3C,EAAStF,SAAS,oBAAsBsF,EAAStF,SAAS,UAIhE,CAGF,OAAO,CACT,OAASoC,GAEP,OAAO,CACT,CACF,CAMO,SAAS0F,EAAgBQ,GAAuB,GACrD,OAAIA,EAC0B,OAArBnF,GAAsD,OAAzBC,EAEV,OAArBD,GAAsD,OAAzBC,CACtC,CAKO,SAASmF,IAQd,MAAO,CACLC,OAAQV,IACRW,QAASjF,EACTkF,YAAkC,OAArBvF,EACbwF,gBAA0C,OAAzBvF,EACjBwF,cAAelF,EACfmF,cAAelF,EAEnB,CAKO,SAASmF,IACd,OAAOpF,CACT,CClrBA,MAwMaqF,EAAqC,CAvMhD,CAAEC,OAAQ,gBAAiBC,SAAU,kCAAmCC,SAAU,YAClF,CAAEF,OAAQ,wBAAyBC,SAAU,kCAAmCC,SAAU,YAC1F,CAAEF,OAAQ,4BAA6BC,SAAU,kCAAmCC,SAAU,YAC9F,CAAEF,OAAQ,eAAiBC,SAAU,kCAAmCC,SAAU,YAClF,CAAEF,OAAQ,2BAA4BC,SAAU,kCAAmCC,SAAU,YAC7F,CAAEF,OAAQ,mCAAqCC,SAAU,kCAAmCC,SAAU,YACtG,CAAEF,OAAQ,+BAAgCC,SAAU,kCAAmCC,SAAU,YACjG,CAAEF,OAAQ,0BAA4BC,SAAU,kCAAmCC,SAAU,YAC7F,CAAEF,OAAQ,2BAA6BC,SAAU,kCAAmCC,SAAU,YAC9F,CAAEF,OAAQ,mBAAoBC,SAAU,kCAAmCC,SAAU,YACrF,CAAEF,OAAQ,qBAAuBC,SAAU,kCAAmCC,SAAU,YACxF,CAAEF,OAAQ,+BAAiCC,SAAU,kCAAmCC,SAAU,YAClG,CAAEF,OAAQ,2BAA4BC,SAAU,kCAAmCC,SAAU,YAC7F,CAAEF,OAAQ,sBAAwBC,SAAU,kCAAmCC,SAAU,YACzF,CAAEF,OAAQ,0CAA2CC,SAAU,kCAAmCC,SAAU,YAC5G,CAAEF,OAAQ,4BAA8BC,SAAU,kCAAmCC,SAAU,YAC/F,CAAEF,OAAQ,qBAAsBC,SAAU,kCAAmCC,SAAU,YACvF,CAAEF,OAAQ,wBAA0BC,SAAU,kCAAmCC,SAAU,YAC3F,CAAEF,OAAQ,uCAAyCC,SAAU,kCAAmCC,SAAU,YAC1G,CAAEF,OAAQ,yCAA0CC,SAAU,kCAAmCC,SAAU,YAC3G,CAAEF,OAAQ,iCAAmCC,SAAU,kCAAmCC,SAAU,YACpG,CAAEF,OAAQ,2BAA4BC,SAAU,kCAAmCC,SAAU,YAQ7F,CAAEF,OAAQ,gBAAkBC,SAAU,oCAAqCC,SAAU,QACrF,CAAEF,OAAQ,0BAA4BC,SAAU,oCAAqCC,SAAU,QAC/F,CAAEF,OAAQ,4BAA8BC,SAAU,oCAAqCC,SAAU,QACjG,CAAEF,OAAQ,iBAAkBC,SAAU,oCAAqCC,SAAU,QACrF,CAAEF,OAAQ,qBAAuBC,SAAU,oCAAqCC,SAAU,QAC1F,CAAEF,OAAQ,WAAaC,SAAU,oCAAqCC,SAAU,QAChF,CAAEF,OAAQ,eAAiBC,SAAU,oCAAqCC,SAAU,QACpF,CAAEF,OAAQ,4BAA8BC,SAAU,oCAAqCC,SAAU,QACjG,CAAEF,OAAQ,2BAA4BC,SAAU,oCAAqCC,SAAU,QAC/F,CAAEF,OAAQ,6CAA8CC,SAAU,oCAAqCC,SAAU,QACjH,CAAEF,OAAQ,kCAAoCC,SAAU,oCAAqCC,SAAU,QACvG,CAAEF,OAAQ,kCAAoCC,SAAU,oCAAqCC,SAAU,QACvG,CAAEF,OAAQ,+BAAgCC,SAAU,oCAAqCC,SAAU,QACnG,CAAEF,OAAQ,qCAAuCC,SAAU,oCAAqCC,SAAU,QAC1G,CAAEF,OAAQ,6BAA8BC,SAAU,oCAAqCC,SAAU,QACjG,CAAEF,OAAQ,oBAAsBC,SAAU,oCAAqCC,SAAU,QACzF,CAAEF,OAAQ,wCAAyCC,SAAU,oCAAqCC,SAAU,QAC5G,CAAEF,OAAQ,2CAA4CC,SAAU,oCAAqCC,SAAU,QAC/G,CAAEF,OAAQ,6BAA8BC,SAAU,oCAAqCC,SAAU,QACjG,CAAEF,OAAQ,qBAAsBC,SAAU,oCAAqCC,SAAU,QACzF,CAAEF,OAAQ,gCAAkCC,SAAU,oCAAqCC,SAAU,QACrG,CAAEF,OAAQ,wCAA0CC,SAAU,oCAAqCC,SAAU,QAQ7G,CAAEF,OAAQ,oBAAsBC,SAAU,4BAA6BC,SAAU,YACjF,CAAEF,OAAQ,oBAAqBC,SAAU,4BAA6BC,SAAU,YAChF,CAAEF,OAAQ,2BAA4BC,SAAU,4BAA6BC,SAAU,YACvF,CAAEF,OAAQ,iCAAmCC,SAAU,4BAA6BC,SAAU,YAC9F,CAAEF,OAAQ,wBAA0BC,SAAU,4BAA6BC,SAAU,YACrF,CAAEF,OAAQ,oBAAqBC,SAAU,4BAA6BC,SAAU,YAChF,CAAEF,OAAQ,sBAAuBC,SAAU,4BAA6BC,SAAU,YAClF,CAAEF,OAAQ,sBAAuBC,SAAU,4BAA6BC,SAAU,YAClF,CAAEF,OAAQ,2BAA6BC,SAAU,4BAA6BC,SAAU,YACxF,CAAEF,OAAQ,4BAA8BC,SAAU,4BAA6BC,SAAU,YACzF,CAAEF,OAAQ,mCAAoCC,SAAU,4BAA6BC,SAAU,YAC/F,CAAEF,OAAQ,gCAAiCC,SAAU,4BAA6BC,SAAU,YAC5F,CAAEF,OAAQ,sCAAuCC,SAAU,4BAA6BC,SAAU,YAClG,CAAEF,OAAQ,iCAAkCC,SAAU,4BAA6BC,SAAU,YAC7F,CAAEF,OAAQ,0BAA2BC,SAAU,4BAA6BC,SAAU,YACtF,CAAEF,OAAQ,gBAAiBC,SAAU,4BAA6BC,SAAU,YAC5E,CAAEF,OAAQ,oCAAsCC,SAAU,4BAA6BC,SAAU,YACjG,CAAEF,OAAQ,wBAAyBC,SAAU,4BAA6BC,SAAU,YACpF,CAAEF,OAAQ,oCAAsCC,SAAU,4BAA6BC,SAAU,YACjG,CAAEF,OAAQ,8CAAgDC,SAAU,4BAA6BC,SAAU,YAC3G,CAAEF,OAAQ,oCAAqCC,SAAU,4BAA6BC,SAAU,YAChG,CAAEF,OAAQ,2BAA4BC,SAAU,4BAA6BC,SAAU,YACvF,CAAEF,OAAQ,sBAAuBC,SAAU,4BAA6BC,SAAU,YAClF,CAAEF,OAAQ,uBAAwBC,SAAU,4BAA6BC,SAAU,YACnF,CAAEF,OAAQ,8BAA+BC,SAAU,4BAA6BC,SAAU,YAC1F,CAAEF,OAAQ,mCAAoCC,SAAU,4BAA6BC,SAAU,YAQ/F,CAAEF,OAAQ,2BAA6BC,SAAU,mBAAoBC,SAAU,QAC/E,CAAEF,OAAQ,uBAAwBC,SAAU,mBAAoBC,SAAU,QAC1E,CAAEF,OAAQ,2BAA4BC,SAAU,mBAAoBC,SAAU,QAC9E,CAAEF,OAAQ,kCAAmCC,SAAU,mBAAoBC,SAAU,QACrF,CAAEF,OAAQ,2BAA6BC,SAAU,mBAAoBC,SAAU,QAC/E,CAAEF,OAAQ,iBAAkBC,SAAU,mBAAoBC,SAAU,QACpE,CAAEF,OAAQ,gBAAiBC,SAAU,mBAAoBC,SAAU,QACnE,CAAEF,OAAQ,oCAAsCC,SAAU,mBAAoBC,SAAU,QACxF,CAAEF,OAAQ,6BAA8BC,SAAU,mBAAoBC,SAAU,QAChF,CAAEF,OAAQ,wCAAyCC,SAAU,mBAAoBC,SAAU,QAC3F,CAAEF,OAAQ,wBAAyBC,SAAU,mBAAoBC,SAAU,QAC3E,CAAEF,OAAQ,iCAAmCC,SAAU,mBAAoBC,SAAU,QACrF,CAAEF,OAAQ,8BAAgCC,SAAU,mBAAoBC,SAAU,QAClF,CAAEF,OAAQ,6BAA8BC,SAAU,mBAAoBC,SAAU,QAChF,CAAEF,OAAQ,uBAAwBC,SAAU,mBAAoBC,SAAU,QAC1E,CAAEF,OAAQ,mCAAqCC,SAAU,mBAAoBC,SAAU,QACvF,CAAEF,OAAQ,yBAA0BC,SAAU,mBAAoBC,SAAU,QAC5E,CAAEF,OAAQ,yBAA0BC,SAAU,mBAAoBC,SAAU,QAC5E,CAAEF,OAAQ,yBAA0BC,SAAU,mBAAoBC,SAAU,QAQ5E,CAAEF,OAAQ,kBAAmBC,SAAU,2BAA4BC,SAAU,YAC7E,CAAEF,OAAQ,2BAA4BC,SAAU,2BAA4BC,SAAU,YACtF,CAAEF,OAAQ,0BAA2BC,SAAU,2BAA4BC,SAAU,YACrF,CAAEF,OAAQ,4BAA6BC,SAAU,2BAA4BC,SAAU,YACvF,CAAEF,OAAQ,cAAgBC,SAAU,2BAA4BC,SAAU,YAC1E,CAAEF,OAAQ,gBAAkBC,SAAU,2BAA4BC,SAAU,YAC5E,CAAEF,OAAQ,8BAAgCC,SAAU,2BAA4BC,SAAU,YAC1F,CAAEF,OAAQ,gBAAiBC,SAAU,2BAA4BC,SAAU,YAC3E,CAAEF,OAAQ,iBAAmBC,SAAU,2BAA4BC,SAAU,YAC7E,CAAEF,OAAQ,2BAA6BC,SAAU,2BAA4BC,SAAU,YACvF,CAAEF,OAAQ,oBAAqBC,SAAU,2BAA4BC,SAAU,YAC/E,CAAEF,OAAQ,gCAAiCC,SAAU,2BAA4BC,SAAU,YAC3F,CAAEF,OAAQ,uBAAwBC,SAAU,2BAA4BC,SAAU,YAClF,CAAEF,OAAQ,iBAAmBC,SAAU,2BAA4BC,SAAU,YAC7E,CAAEF,OAAQ,oBAAqBC,SAAU,2BAA4BC,SAAU,YAC/E,CAAEF,OAAQ,2BAA6BC,SAAU,2BAA4BC,SAAU,YAQvF,CAAEF,OAAQ,iCAAmCC,SAAU,4BAA6BC,SAAU,YAC9F,CAAEF,OAAQ,+BAAiCC,SAAU,4BAA6BC,SAAU,YAC5F,CAAEF,OAAQ,wCAA0CC,SAAU,4BAA6BC,SAAU,YACrG,CAAEF,OAAQ,uDAAyDC,SAAU,4BAA6BC,SAAU,YACpH,CAAEF,OAAQ,4CAA8CC,SAAU,4BAA6BC,SAAU,YACzG,CAAEF,OAAQ,oCAAsCC,SAAU,4BAA6BC,SAAU,YACjG,CAAEF,OAAQ,+CAAiDC,SAAU,4BAA6BC,SAAU,YAC5G,CAAEF,OAAQ,4BAA6BC,SAAU,4BAA6BC,SAAU,YACxF,CAAEF,OAAQ,gCAAiCC,SAAU,4BAA6BC,SAAU,YAC5F,CAAEF,OAAQ,4BAA8BC,SAAU,4BAA6BC,SAAU,YACzF,CAAEF,OAAQ,0CAA4CC,SAAU,4BAA6BC,SAAU,YACvG,CAAEF,OAAQ,qCAAuCC,SAAU,4BAA6BC,SAAU,YAQlG,CAAEF,OAAQ,qCAAsCC,SAAU,kCAAmCC,SAAU,QACvG,CAAEF,OAAQ,qCAAsCC,SAAU,kCAAmCC,SAAU,QACvG,CAAEF,OAAQ,kCAAmCC,SAAU,kCAAmCC,SAAU,QACpG,CAAEF,OAAQ,4CAA6CC,SAAU,kCAAmCC,SAAU,QAC9G,CAAEF,OAAQ,iDAAkDC,SAAU,kCAAmCC,SAAU,QACnH,CAAEF,OAAQ,yDAA0DC,SAAU,kCAAmCC,SAAU,QAC3H,CAAEF,OAAQ,8CAA+CC,SAAU,kCAAmCC,SAAU,QAChH,CAAEF,OAAQ,qCAAsCC,SAAU,kCAAmCC,SAAU,QACvG,CAAEF,OAAQ,kDAAmDC,SAAU,kCAAmCC,SAAU,QACpH,CAAEF,OAAQ,iCAAkCC,SAAU,kCAAmCC,SAAU,QACnG,CAAEF,OAAQ,4CAA8CC,SAAU,kCAAmCC,SAAU,QAQ/G,CAAEF,OAAQ,yBAA2BC,SAAU,yBAA0BC,SAAU,YACnF,CAAEF,OAAQ,6BAA+BC,SAAU,yBAA0BC,SAAU,YACvF,CAAEF,OAAQ,sBAAwBC,SAAU,yBAA0BC,SAAU,YAChF,CAAEF,OAAQ,gCAAkCC,SAAU,yBAA0BC,SAAU,YAC1F,CAAEF,OAAQ,8CAAiDC,SAAU,yBAA0BC,SAAU,YACzG,CAAEF,OAAQ,2BAA4BC,SAAU,yBAA0BC,SAAU,YACpF,CAAEF,OAAQ,kDAAoDC,SAAU,yBAA0BC,SAAU,YAC5G,CAAEF,OAAQ,qBAAuBC,SAAU,yBAA0BC,SAAU,YAC/E,CAAEF,OAAQ,6BAA8BC,SAAU,yBAA0BC,SAAU,YACtF,CAAEF,OAAQ,8BAA+BC,SAAU,yBAA0BC,SAAU,YACvF,CAAEF,OAAQ,8BAA+BC,SAAU,yBAA0BC,SAAU,YACvF,CAAEF,OAAQ,8BAAgCC,SAAU,yBAA0BC,SAAU,YACxF,CAAEF,OAAQ,gCAAkCC,SAAU,yBAA0BC,SAAU,YAC1F,CAAEF,OAAQ,8BAAgCC,SAAU,yBAA0BC,SAAU,YACxF,CAAEF,OAAQ,+BAAiCC,SAAU,yBAA0BC,SAAU,YACzF,CAAEF,OAAQ,+CAAiDC,SAAU,yBAA0BC,SAAU,aAmCpG,SAASC,EAAuBF,GAWrC,MAV8C,CAC5CG,gCAAmC,4BACnCC,kCAAqC,8BACrCC,0BAA6B,8BAC7BC,iBAAoB,YACpBC,yBAA4B,sBAC5BC,0BAA6B,2BAC7BC,gCAAmC,qBACnCC,uBAA0B,oBAEfV,IAAaA,CAC5B,CC9PO,SAASW,EAAaC,EAAcC,GACzC,MAAMC,EAAYF,EAAKjK,cAIjBoK,EAA4B,GAC5BC,EAAuC,GAC7C,IAAIC,EAAwD,MAG5D,UAAWC,KAAgBpB,EACrBgB,EAAU/J,SAASmK,EAAanB,UAClCgB,EAAgBvL,KAAK0L,EAAanB,QAC7BiB,EAAmBjK,SAASmK,EAAalB,WAC5CgB,EAAmBxL,KAAK0L,EAAalB,UAIT,aAA1BkB,EAAajB,SACfgB,EAAc,WACqB,SAA1BC,EAAajB,UAAuC,aAAhBgB,EAC7CA,EAAc,OACqB,aAA1BC,EAAajB,UAA2C,QAAhBgB,IACjDA,EAAc,aAMpB,MAAME,EAAkBH,EAAmBI,KAAKC,GACtC,6BAARA,GAA8C,8BAARA,GAElCC,EAAoBN,EAAmBI,KAAKC,GAChDA,EAAIE,WAAW,YAGbJ,GAAmBG,GAAqC,aAAhBL,IAC1CA,EAAc,QAGhB,MAAMO,EAAWT,EAAgBU,OAAS,EAG1C,IAAIC,EAA0D,WAc9D,MAZoB,aAAhBT,EACFS,EAAoB,YAEJ,SAAhBT,GACAD,EAAmBjK,SAAS,qBAC5BiK,EAAmBjK,SAAS,mCAE5B2K,EAAoB,eACXF,IACTE,EAAoB,oBAGf,CACLF,WACAvB,SAAUgB,EACVF,kBACAW,oBACAC,WAAYX,EAEhB,CAOO,SAASY,EAAkBC,EAAyBhB,GACzD,MAAMiB,EAAmBjB,GAAYiB,iBAC/BC,EAAmBD,EACrB,GAAGA,EAAiBnI,MAAQ,qBAAqBmI,EAAiBE,QAClE,wCAGJ,GAAwB,aAApBH,EAAO5B,UAAwD,cAA7B4B,EAAOH,kBAK3C,OAHmBG,EAAOF,YAAY5K,SAAS,2BAC7B8K,EAAOF,YAAY5K,SAAS,6BAGrC,s3BAAs3BgL,6RAIx3B,i5BAAi5BA,kSAI15B,GAAwB,SAApBF,EAAO5B,UAAoD,iBAA7B4B,EAAOH,kBAAsC,CAC7E,MAAMO,EAAaJ,EAAOF,YAAY5K,SAAS,oBACzCmL,EAAeL,EAAOF,YAAY5K,SAAS,mCAEjD,OAAIkL,EACK,+UAA+UF,8pBAGpVG,EACK,qfAAqfH,0PAIvf,mTAAmTA,8vBAC5T,CAGA,MAAO,iOAAiOA,y0BAC1O,CCeO,SAASI,EAAuBC,EAAkBC,GACvD,MAAMC,EAAsC,GACtCC,EAAqC,GAE3CH,EAAKlJ,QAAQsJ,IACX,MAAMC,EAAYJ,EAAOK,KAAKC,GAAKA,EAAEC,KAAOJ,EAAIK,UAAUlJ,MAAQ,UAClE2I,EAAYG,IAAcH,EAAYG,IAAc,GAAK,EACrDD,EAAIM,OACNP,EAAWC,EAAIM,OAASP,EAAWC,EAAIM,OAAS,GAAK,KAIzD,MAAMC,EAAWC,OAAOC,QAAQX,GAAaY,KAAK,CAACC,EAAGC,IAAMA,EAAE,GAAKD,EAAE,IAAI,KAAK,IAAM,MAC9EE,EAAUL,OAAOC,QAAQV,GAAYW,KAAK,CAACC,EAAGC,IAAMA,EAAE,GAAKD,EAAE,IAAI,KAAK,IAAM,MAElF,MAAO,6EAI2Bf,EAAKX,oDAAoDsB,kCAAyCM,oGAEzC,IAAI7K,KAAK4J,EAAKA,EAAKX,OAAS,IAAI6B,MAAQ9K,KAAKC,OAAO8K,2BAA2B,IAAI/K,KAAK4J,EAAK,IAAIkB,MAAQ9K,KAAKC,OAAO8K,mPAUtMnB,EAAKX,mBAAmBuB,OAAOzH,KAAK+G,GAAab,wIAE0BsB,uSAYpDX,EAAKX,mMAOxC,CAKAxG,eAAsBuI,EACpBpB,EACAC,EACAxB,GAEA,IACE,GAAoB,IAAhBuB,EAAKX,OACP,MAAO,mCAIT,MACMgC,EAAc9C,EADJyB,EAAKsB,IAAIC,GAAKA,EAAEC,MAAMC,KAAK,MAG3C,GAAIJ,EAAYjC,UAAqC,aAAzBiC,EAAYxD,SAAyB,CAC/D,MAAM6B,EAAmBjB,GAAYiB,iBAKrC,MAAO,m6BAJkBA,EACrB,GAAGA,EAAiBnI,MAAQ,qBAAqBmI,EAAiBE,QAClE,2VAGN,CAIA,IAD6BpH,aAEAa,KACR,CAIjB,MAAO,GAFgB0G,EAAuBC,EAAMC,wHAGtD,CAGF,MAKMyB,EAAS,8MALC1B,EAAKsB,IAAIC,IACvB,MAAMI,EAAQ1B,EAAOK,KAAKC,GAAKA,EAAEC,KAAOe,EAAEd,UAAUlJ,MAAQ,UAC5D,MAAO,IAAIgK,EAAEL,KAAKU,MAAM,KAAK,cAAcD,YAAgBJ,EAAEb,MAAQ,gBAAgBa,EAAEC,SACtFC,KAAK,0MAWR,IAAI1M,EAASgL,EAAuBC,EAAMC,GAGtC4B,EAA8BrJ,IAGlC,IAAKqJ,EAEH,GADuBpJ,IACH,CAElB,MAAMqJ,EAAc,IACdC,EAAY3L,KAAKC,MACvB,MAAQwL,GAAgCzL,KAAKC,MAAQ0L,EAAaD,SAC1D,IAAI/G,QAAQC,GAAWvB,WAAWuB,EAAS,MACjD6G,EAA8BrJ,GAElC,YACQa,IACNwI,EAA8BrJ,IAIlC,GAAIqJ,EACF,IACE,MAAMG,QAAeH,EAA4BH,EAAQ,CACvDO,eAAgB,IAChBC,YAAa,GACbC,WAAW,IAIPC,GADgBJ,EAAO,IAAIK,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OAChDH,IACFrN,EAASqN,EAEb,OAASrL,GAGP,GAAIA,aAAiBuD,QACnBvD,EAAMhB,QAAQpB,SAAS,mBACvBoC,EAAMhB,QAAQpB,SAAS,gBACtB,OACK0E,GAAiB,GACvB,MAAMmJ,EAAgBhK,IACtB,GAAIgK,EACF,IACE,MAAMC,QAAoBD,EAAcd,EAAQ,CAC9CO,eAAgB,IAChBC,YAAa,GACbC,WAAW,IAGPO,GADYD,EAAY,IAAIJ,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OACjDG,IACF3N,EAAS2N,EAEb,OAASC,GAET,CAEJ,CAEF,CAMF,OAAO5N,EAFY,sKAGrB,OAASgC,GAKP,MAAO,GAFgBgJ,EAAuBC,EAAMC,wHAGtD,CACF,CCtSA,SAAS2C,EACPC,EACAC,EACArE,GAEA,MAAMsE,EAAkBF,EAAWtO,cAG7ByO,EAAmB,IACrBD,EAAgBpO,SAAS,YAAcoO,EAAgBpO,SAAS,YAAcoO,EAAgBpO,SAAS,YACzGqO,EAAO5P,KAAK,mBAEV2P,EAAgBpO,SAAS,QAAUoO,EAAgBpO,SAAS,SAAWoO,EAAgBpO,SAAS,eAClGqO,EAAO5P,KAAK,oBAEV2P,EAAgBpO,SAAS,SAAWoO,EAAgBpO,SAAS,QAAUoO,EAAgBpO,SAAS,eAClGqO,EAAO5P,KAAK,qBAEV2P,EAAgBpO,SAAS,WAAaoO,EAAgBpO,SAAS,iBAAmBoO,EAAgBpO,SAAS,YAC7GqO,EAAO5P,KAAK,gCAEV2P,EAAgBpO,SAAS,UAAYoO,EAAgBpO,SAAS,UAAYoO,EAAgBpO,SAAS,eACrGqO,EAAO5P,KAAK,uBAEQ,IAAlB4P,EAAO3D,QACT2D,EAAO5P,KAAK,kBAAmB,mBAIjC,IAAI6P,EAAkB,GAEpBA,EADEF,EAAgBpO,SAAS,SAAWoO,EAAgBpO,SAAS,UAC7C,4JACToO,EAAgBpO,SAAS,SAAWoO,EAAgBpO,SAAS,SACpD,8IAEA,sHAIpB,MAMMuO,EAA+B,cAAdJ,EAA4B,UAAYA,EACzDK,EAAcH,EAAO3D,OAAS,EAChC,uBAAuB2D,EAAO,2IAC9B,6CAA6CE,iFAEjD,MAAO,mBACPF,EAAOI,MAAM,EAAG,GAAG9B,IAAI+B,GAAK,KAAKA,KAAK5B,KAAK,gCAG3CwB,+BAfkB,CAChB,kGACA,oGAgBQ3B,IAAI,CAACgC,EAAGC,IAAM,GAAGA,EAAI,MAAMD,KAAK7B,KAAK,6BAG/C0B,GACF,CAMAtK,eAAsB2K,EACpBX,EACAC,EACArE,GAEA,IAEE,MAAM4C,EAAc9C,EAAasE,GACjC,GAAIxB,EAAYjC,SACd,OAAOI,EAAkB6B,EAAa5C,GAGxC,IAAKoE,EAAWN,OACd,MAAO,oDAGT,MAAMkB,EAAYhF,GAAYgF,WAAa,GA0B3C,OAzBwBA,EAAUpE,OAAS,GACGoE,EAAUhC,KAAK,MAwBtDmB,EAAmCC,EAAYC,EACxD,OAAS/L,GAEP,OAAO6L,EAAmCC,EAAYC,EACxD,CACF,CAOAjK,eAAsB6K,EACpBC,EACAjD,EACAmC,EACApE,GAEA,IAEE,MAAM4C,EAAc9C,EAAasE,GACjC,GAAIxB,EAAYjC,SACd,OAAOI,EAAkB6B,EAAa5C,GAIxC,IAAI1G,EAAuBS,IAC3B,MAAML,EAAiBM,IAEvB,IAAKV,EACH,GAAII,EAAgB,CAElB,MAAM2J,EAAc,IACdC,EAAY3L,KAAKC,MACvB,MAAQ0B,GAAyB3B,KAAKC,MAAQ0L,EAAaD,SACnD,IAAI/G,QAAQC,GAAWvB,WAAWuB,EAAS,MACjDjD,EAAuBS,GAE3B,YAEQa,IACNtB,EAAuBS,IAK3B,MAAMiL,EAAYhF,GAAYgF,WAAa,GAKrC/B,EAAS,4GAJS+B,EAAUpE,OAAS,EACvC,0CAA0CoE,EAAUhC,KAAK,mBACzD,iZAYgCkC,EAAMpM,UAAUoM,EAAMjM,gDAC9BgJ,yBACXmC,6UAUjB,IAAIe,EAAW,qFAEf,GAAI7L,EACF,IACE,MAAMiK,QAAejK,EAAqB2J,EAAQ,CAChDO,eAAgB,IAChBC,YAAa,GACbC,WAAW,EACX0B,MAAO,KAKHzB,GAFgBJ,EAAO,IAAIK,gBAAkB,IAEnBC,QAAQZ,EAAQ,IAAIa,OAChDH,IACFwB,EAAWxB,EAEf,OAASrL,GAGP,GAAIA,aAAiBuD,QACnBvD,EAAMhB,QAAQpB,SAAS,mBACvBoC,EAAMhB,QAAQpB,SAAS,gBACvBoC,EAAMhB,QAAQpB,SAAS,sBACtB,OAEK0E,GAAiB,GACvB,MAAMmJ,EAAgBhK,IACtB,GAAIgK,EACF,IACE,MAAMC,QAAoBD,EAAcd,EAAQ,CAC9CO,eAAgB,IAChBC,YAAa,GACbC,WAAW,EACX0B,MAAO,KAGHnB,GADYD,EAAY,IAAIJ,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OACjDG,IACFkB,EAAWlB,EAEf,OAASC,GAET,CAEJ,CAEF,CAQF,MAJiB,uFAAbiB,IACFA,EAxPN,SAAkCD,EAAkBjD,GAClD,MAAMoD,EAAc,CAClB,KAAM,wBACN,KAAM,sBACN,IAAK,qBACL,KAAM,4BACNpD,IAAS,eAEX,MAAO,iBAAiBiD,EAAMpM,4BAA4BuM,iLAC5D,CA+OiBC,CAAyBJ,EAAOjD,IAGtCkD,CACT,OAAS7M,GAGP,MAAO,iBAAiB4M,EAAMpM,0GAChC,CACF,CAKAsB,eAAsBmL,EACpBL,EACAjD,EAAe,IACfjC,GAEA,OAAOiF,EAA2BC,EAAOjD,EAAM,GAAIjC,EACrD,CAMA5F,eAAsBoL,EACpBC,EACAC,EACAC,EACA3F,EACA4F,GAOA,MAAMC,kBAAEA,SAAsB1K,EAAAf,UAAA,MAAAyL,2BAAMzK,OAAO,iCAAoB,OAAAyK,sBAAAxK,IACzDyK,EAAcD,EAAkBJ,GAEtC,IAAKK,EAEH,MAAO,+DAGT,MAAMd,EAAYhF,GAAYgF,WAAa,GACrCe,EAAkBf,EAAUpE,OAAS,EACvC,0CAA0CoE,EAAUhC,KAAK,mBACzD,8DAEEgD,EAAiBN,EAAkB,iCAAiCA,KAAqB,GAGzFO,EACoB,YAAtBL,EAAQM,UACN,+DACsB,YAAtBN,EAAQM,WAAiD,UAAtBN,EAAQM,UAC3C,uDACA,oDAIAC,EAAiBP,GAASQ,kBAC5B,wBAAwBR,EAAQQ,kBAAkBC,UAAU,EAAG,QAC/D,GAGEC,EAAiBV,GAASW,cAAgBX,EAAQW,aAAaC,eAAe5F,OAAS,EACzF,8BAA8BgF,EAAQW,aAAaC,eAAexD,KAAK,oBACvE,GAGEyD,EAAgC,YAAnBhB,GAAmD,UAAnBA,GAAiD,gBAAnBA,EAC3EiB,EAAaD,GAAcd,GAAiB,EAC5CgB,EAAmBD,EACrB,gKACAD,EACA,4EACA,GAGEG,EAAkBd,EAAYe,oBAAoBC,YAGlD7D,EAAS,sDAAsDgD,IAAcE,IAAiBG,4BAEhFR,EAAYpP,MAAMZ,iBAAiBkQ,QAEvDD,QAEAa,IAAkBD,iOAKqBD,EAAa,+DAAiE,mFAKrH,IAAIK,EAAmB,GAGrBA,EADqB,YAAnBtB,EACiB,4NAA2NiB,EAAa,gIAAkI,IACjW,UAAnBjB,EACU,qLAAoLiB,EAAa,mHAAqH,0DAC7S,gBAAnBjB,EACU,mPAAkPiB,EAAa,2DAA6D,IACnT,UAAnBjB,EACU,2PACS,SAAnBA,EACU,gNACS,YAAnBA,EACU,8NACS,aAAnBA,EACU,wPAEA,4OAIrB,IAAInM,EAAuBS,IAG3B,IAAKT,EAEH,GADuBU,IAchB,CAGL,MAAMqJ,EAAc,IACdC,EAAY3L,KAAKC,MACvB,MAAQ0B,GAAyB3B,KAAKC,MAAQ0L,EAAaD,UACnD,IAAI/G,QAAQC,GAAWvB,WAAWuB,EAAS,MACjDjD,EAAuBS,IAElBC,KAAwBV,KAKjC,MAzBE,IACE,MAAM0N,EAAcpM,IACdqM,EAAiB,IAAI3K,QAAiB,CAAC4K,EAAGC,IAC9CnM,WAAW,IAAMmM,EAAO,IAAItL,MAAM,iCAAkC,YAEhES,QAAQ8K,KAAK,CAACJ,EAAaC,IACjC3N,EAAuBS,GACzB,OAASzB,GAGT,CAkBJ,GAAIgB,EACF,IACE,MAAMiK,QAAejK,EAAqB2J,EAAQ,CAChDO,eAAgB,IAChBC,YAAa,GACbC,WAAW,EACX0B,MAAO,KAIHzB,GADgBJ,EAAO,IAAIK,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OACpD,GAAIH,GAAaA,EAAU/C,OAAS,GAClC,OAAO+C,CAEX,OAASrL,GAIP,GAAIA,aAAiBuD,QACnBvD,EAAMhB,QAAQpB,SAAS,mBACvBoC,EAAMhB,QAAQpB,SAAS,gBACvBoC,EAAMhB,QAAQpB,SAAS,sBACtB,OAEK0E,GAAiB,GACvB,MAAMmJ,EAAgBhK,IACtB,GAAIgK,EACF,IACE,MAAMC,QAAoBD,EAAcd,EAAQ,CAC9CO,eAAgB,IAChBC,YAAa,GACbC,WAAW,EACX0B,MAAO,KAGHnB,GADYD,EAAY,IAAIJ,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OACrD,GAAIG,GAAkBA,EAAerD,OAAS,GAC5C,OAAOqD,CAEX,OAASC,GAET,CAEJ,CACF,CAIF,OAAO6C,CACT,CAKA3M,eAAsBiN,EAAoBnC,GAsCxC,MApCwC,CACtCoC,UAAa,kBACbC,OAAU,mBACVC,WAAc,oBACdC,OAAU,sBACVC,QAAW,mBACXC,QAAW,mBACXC,SAAY,uBACZC,SAAY,2BACZC,OAAU,oBACVC,MAAS,cACTC,QAAW,kBACXC,QAAW,mBACXC,aAAgB,yBAChBC,QAAW,2BACXC,OAAU,kBACVC,OAAU,iBACVC,aAAgB,kBAChBC,WAAc,qBACdC,MAAS,wBACTC,WAAc,mBACdC,WAAc,uBACdC,eAAkB,iBAClBC,QAAW,qBACXC,SAAY,iBACZC,QAAW,kBACXC,UAAa,qBACbC,SAAY,mBACZC,UAAa,qBACbC,QAAW,oBACXC,eAAkB,oBAClB,kBAAmB,oBACnBC,OAAU,oBACVC,UAAa,kBAGAnE,EAAMpM,OAAS,SAASoM,EAAMpM,YAC/C,CAKAsB,eAAsBkP,EACpBpE,EACAb,EACAD,EAAqB,GACrBpE,GAEA,IAGE,GADoBF,EAAasE,GACjBzD,SACd,MAAO,gTAGT,IAAIrH,EAAuBS,IAC3B,IAAKT,EAEH,GADuBU,IACH,CAElB,MAAMqJ,EAAc,IACdC,EAAY3L,KAAKC,MACvB,MAAQ0B,GAAyB3B,KAAKC,MAAQ0L,EAAaD,SACnD,IAAI/G,QAAQC,GAAWvB,WAAWuB,EAAS,MACjDjD,EAAuBS,GAE3B,YACQa,IACNtB,EAAuBS,IAK3B,MAAMwP,EAAoBnF,EAAWlO,SAAS,qBAAuBkO,EAAWN,OAAOlD,OAAS,GAC1F4I,EAAcpF,EAAWlO,SAAS,mBAAqBkO,EAAWlO,SAAS,uBAA2BkO,EAAWlO,SAAS,wBAE1H+M,EAAUsG,GAAqBC,EACjC,uPAE8BtE,EAAMpM,UAAUoM,EAAMjM,4BAC/CoL,QAEXD,qUAK4Bc,EAAMpM,oDACSuL,wqBAerC,gFAAgFa,EAAMpM,UAAUoM,EAAMjM,+BAEjGoL,0BACSD,6VAalB,IAAIe,EAAW,uFAAuFD,EAAMpM,sMAE5G,GAAIQ,EACF,IACE,MAAMiK,QAAejK,EAAqB2J,EAAQ,CAChDO,eAAgB,IAChBC,YAAa,GACbC,WAAW,IAIPC,GADgBJ,EAAO,IAAIK,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OAChDH,IACFwB,EAAWxB,EAEf,OAASrL,GAGP,GAAIA,aAAiBuD,QACnBvD,EAAMhB,QAAQpB,SAAS,mBACvBoC,EAAMhB,QAAQpB,SAAS,gBACtB,OACK0E,GAAiB,GACvB,MAAMmJ,EAAgBhK,IACtB,GAAIgK,EACF,IACE,MAAMC,QAAoBD,EAAcd,EAAQ,CAC9CO,eAAgB,IAChBC,YAAa,GACbC,WAAW,IAGPO,GADYD,EAAY,IAAIJ,gBAAkB,IACnBC,QAAQZ,EAAQ,IAAIa,OACjDG,IACFkB,EAAWlB,EAEf,OAASC,GAET,CAEJ,CACF,CAGF,OAAOiB,CACT,OAAS7M,GAEP,MAAO,mDAAmD4M,EAAMpM,oMAClE,CACF","names":["checkBrowserCompatibility","sharedArrayBuffer","crossOriginIsolated","webGPU","wasm","memory","deviceType","browser","os","issues","recommendations","canUseAI","suggestedStrategy","push","Math","round","estimatedMemory","isCompatible","generateReport","SharedArrayBuffer","checkSharedArrayBuffer","self","checkCrossOriginIsolated","navigator","gpu","checkWebGPU","WebAssembly","instantiate","checkWASM","deviceMemory","ua","userAgent","toLowerCase","test","estimateMemory","detectDeviceType","includes","detectBrowser","detectOS","getCompatibilitySummary","report","currentProgress","progress","status","label","callbacks","Set","subscribeToProgress","callback","fetch","method","headers","body","JSON","stringify","location","message","data","currentStatus","currentLabel","timestamp","Date","now","sessionId","runId","hypothesisId","catch","add","delete","notifyProgress","state","forEach","error","setModelLoadingProgress","details","max","min","setProgressError","MODEL_CONFIGS","distilbert","name","path","task","description","size","tinyllama","minicpm","moodTrackerModel","counselingCoachModel","allModelsCache","Map","selectedModel","isModelLoading","modelLoadPromise","compatibilityReport","lastErrorCategory","getMoodTrackerModel","getCounselingCoachModel","getIsModelLoading","setSelectedModel","modelType","getAllModelConfigs","async","clearModels","clear","window","cacheKeys","caches","keys","key","initializeModels","forceReload","targetModel","loadingTimeout","setTimeout","transformersModule","__TRANSFORMERS_ENV__","__vitePreload","import","__VITE_PRELOAD__","pipeline","importError","errorMsg","String","errorStack","stack","env","Error","allowLocalModels","allowRemoteModels","useBrowserCache","useCustomCache","cacheDir","backends","e","configError","Promise","resolve","totalProgress","modelsLoaded","totalModels","progressCallback","percent","modelProgress","modelName","modelConfig","quantized","progress_callback","set","modelError","canReuseModel","counselingModelType","counselingConfig","has","get","counselingError","counselingMsg","counselingStack","modelsReady","setProgressSuccess","errorMessage","preloadModels","areModelsLoaded","attempts","maxAttempts","lastError","delay","pow","finalMoodModel","finalCounselingModel","requireBoth","getModelStatus","loaded","loading","moodTracker","counselingCoach","compatibility","errorCategory","getCompatibilityReport","ALL_CRISIS_PHRASES","phrase","category","severity","getCategoryDisplayName","CRISIS_SUICIDAL_IDEATION_DIRECT","CRISIS_SUICIDAL_IDEATION_INDIRECT","CRISIS_PLANNING_OR_METHOD","CRISIS_SELF_HARM","RISK_SEVERE_HOPELESSNESS","RISK_BEHAVIORAL_RED_FLAGS","CRISIS_THIRD_PARTY_SUICIDE_RISK","CRISIS_IMMINENT_DANGER","detectCrisis","text","lcswConfig","lowerText","detectedPhrases","detectedCategories","maxSeverity","crisisPhrase","hasModerateRisk","some","cat","hasCrisisCategory","startsWith","isCrisis","length","recommendedAction","categories","getCrisisResponse","crisis","emergencyContact","therapistContact","phone","isSelfHarm","isThirdParty","generateFallbackReport","logs","values","valueCounts","moodCounts","log","valueName","find","v","id","valueId","mood","topValue","Object","entries","sort","a","b","topMood","date","toLocaleDateString","generateHumanReports","crisisCheck","map","l","note","join","prompt","vName","split","currentCounselingCoachModel","maxWaitTime","startTime","result","max_new_tokens","temperature","do_sample","extracted","generated_text","replace","trim","reloadedModel","retryResult","retryExtracted","retryError","generateFallbackReflectionAnalysis","reflection","frequency","lowerReflection","themes","environmentNote","frequencyLabel","sessionPrep","slice","t","q","i","analyzeReflection","protocols","generateCounselingGuidance","value","response","top_p","moodContext","generateFallbackGuidance","generateEncouragement","generateEmotionalEncouragement","emotionalState","selectedFeeling","lowStateCount","context","getEmotionalState","stateConfig","protocolContext","feelingContext","timeContext","timeOfDay","journalContext","recentJournalText","substring","patternContext","userPatterns","frequentStates","isLowState","isRepeated","connectionPrompt","baseInstruction","encouragementPrompt","instruction","fallbackResponse","initPromise","timeoutPromise","_","reject","race","generateValueMantra","Integrity","Family","Creativity","Health","Freedom","Justice","Kindness","Learning","Nature","Peace","Respect","Service","Spirituality","Success","Wealth","Wisdom","Authenticity","Compassion","Humor","Leadership","Resilience","Responsibility","Courage","Humility","Loyalty","Community","Artistry","Curiosity","Balance","Sustainability","Impact","Adventure","suggestGoal","hasDeepReflection","hasAnalysis"],"ignoreList":[],"sources":["../../services/ai/browserCompatibility.ts","../../services/progressTracker.ts","../../services/ai/models.ts","../../services/crisisConfig.ts","../../services/ai/crisis.ts","../../services/ai/reports.ts","../../services/ai/encouragement.ts"],"sourcesContent":["/**\n * Browser Compatibility Detection for ONNX Runtime\n * \n * Checks browser capabilities required for AI model execution:\n * - SharedArrayBuffer availability (requires COOP/COEP headers)\n * - Cross-origin isolation status\n * - Memory constraints\n * - WebGPU support\n * - WASM support\n * - Browser/device type\n */\n\nexport interface CompatibilityReport {\n  sharedArrayBuffer: boolean;\n  crossOriginIsolated: boolean;\n  webGPU: boolean;\n  wasm: boolean;\n  estimatedMemory: number | null; // MB\n  deviceType: 'mobile' | 'tablet' | 'desktop' | 'unknown';\n  browser: string;\n  os: string;\n  isCompatible: boolean;\n  issues: string[];\n  recommendations: string[];\n  canUseAI: boolean;\n  suggestedStrategy: 'standard' | 'single-threaded' | 'low-memory' | 'cpu-only' | 'unavailable';\n}\n\n/**\n * Check if SharedArrayBuffer is available\n * Requires COOP/COEP headers to be set on the server\n */\nfunction checkSharedArrayBuffer(): boolean {\n  try {\n    // SharedArrayBuffer is only available in cross-origin isolated contexts\n    return typeof SharedArrayBuffer !== 'undefined';\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check if cross-origin isolation is enabled\n * This is required for SharedArrayBuffer\n */\nfunction checkCrossOriginIsolated(): boolean {\n  try {\n    // crossOriginIsolated is a read-only property\n    return (self as any).crossOriginIsolated === true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check WebGPU support\n */\nfunction checkWebGPU(): boolean {\n  try {\n    return 'gpu' in navigator && navigator.gpu !== undefined;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check WASM support\n */\nfunction checkWASM(): boolean {\n  try {\n    return typeof WebAssembly !== 'undefined' && \n           typeof WebAssembly.instantiate === 'function';\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Estimate available device memory\n * Returns memory in MB, or null if not available\n */\nfunction estimateMemory(): number | null {\n  try {\n    // @ts-ignore - navigator.deviceMemory is not in all type definitions\n    if ('deviceMemory' in navigator && navigator.deviceMemory) {\n      // deviceMemory is in GB, convert to MB\n      return navigator.deviceMemory * 1024;\n    }\n    \n    // Fallback: Estimate based on user agent and device type\n    const ua = navigator.userAgent.toLowerCase();\n    const isMobile = /mobile|android|iphone|ipad|ipod|blackberry|iemobile|opera mini/i.test(ua);\n    \n    if (isMobile) {\n      // Conservative estimate for mobile devices\n      return 2048; // 2GB\n    }\n    \n    // Desktop typically has more memory\n    return 4096; // 4GB default\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Detect device type\n */\nfunction detectDeviceType(): 'mobile' | 'tablet' | 'desktop' | 'unknown' {\n  try {\n    const ua = navigator.userAgent.toLowerCase();\n    \n    if (/tablet|ipad|playbook|silk/i.test(ua)) {\n      return 'tablet';\n    }\n    \n    if (/mobile|android|iphone|ipod|blackberry|iemobile|opera mini/i.test(ua)) {\n      return 'mobile';\n    }\n    \n    if (/windows|macintosh|linux/i.test(ua)) {\n      return 'desktop';\n    }\n    \n    return 'unknown';\n  } catch {\n    return 'unknown';\n  }\n}\n\n/**\n * Detect browser name\n */\nfunction detectBrowser(): string {\n  try {\n    const ua = navigator.userAgent;\n    \n    if (ua.includes('Chrome') && !ua.includes('Edg')) return 'Chrome';\n    if (ua.includes('Firefox')) return 'Firefox';\n    if (ua.includes('Safari') && !ua.includes('Chrome')) return 'Safari';\n    if (ua.includes('Edg')) return 'Edge';\n    if (ua.includes('Opera') || ua.includes('OPR')) return 'Opera';\n    \n    return 'Unknown';\n  } catch {\n    return 'Unknown';\n  }\n}\n\n/**\n * Detect operating system\n */\nfunction detectOS(): string {\n  try {\n    const ua = navigator.userAgent;\n    \n    if (ua.includes('Windows')) return 'Windows';\n    if (ua.includes('Mac OS')) return 'macOS';\n    if (ua.includes('Linux')) return 'Linux';\n    if (ua.includes('Android')) return 'Android';\n    if (ua.includes('iOS') || ua.includes('iPhone') || ua.includes('iPad')) return 'iOS';\n    \n    return 'Unknown';\n  } catch {\n    return 'Unknown';\n  }\n}\n\n/**\n * Generate compatibility report with issues and recommendations\n */\nfunction generateReport(\n  sharedArrayBuffer: boolean,\n  crossOriginIsolated: boolean,\n  webGPU: boolean,\n  wasm: boolean,\n  memory: number | null,\n  deviceType: string,\n  browser: string,\n  os: string\n): CompatibilityReport {\n  const issues: string[] = [];\n  const recommendations: string[] = [];\n  let canUseAI = true;\n  let suggestedStrategy: CompatibilityReport['suggestedStrategy'] = 'standard';\n  \n  // Check SharedArrayBuffer requirement\n  if (!sharedArrayBuffer) {\n    issues.push('SharedArrayBuffer is not available');\n    recommendations.push('Enable COOP/COEP headers on your server (see SERVER_CONFIG.md)');\n    canUseAI = false; // Critical for multi-threaded performance\n    suggestedStrategy = 'single-threaded';\n  }\n  \n  // Check cross-origin isolation\n  if (!crossOriginIsolated) {\n    issues.push('Cross-origin isolation is not enabled');\n    if (!sharedArrayBuffer) {\n      recommendations.push('Set Cross-Origin-Opener-Policy: same-origin and Cross-Origin-Embedder-Policy: require-corp headers');\n    }\n  }\n  \n  // Check WASM (critical)\n  if (!wasm) {\n    issues.push('WebAssembly is not supported');\n    recommendations.push('Use a modern browser that supports WebAssembly');\n    canUseAI = false;\n    suggestedStrategy = 'unavailable';\n  }\n  \n  // Check memory constraints\n  if (memory !== null) {\n    if (memory < 1024) {\n      issues.push(`Low device memory detected (${Math.round(memory)}MB)`);\n      recommendations.push('Use smaller models or close other applications');\n      suggestedStrategy = 'low-memory';\n    } else if (memory < 2048) {\n      issues.push(`Limited device memory (${Math.round(memory)}MB)`);\n      recommendations.push('Consider using smaller models for better performance');\n      if (suggestedStrategy === 'standard') {\n        suggestedStrategy = 'low-memory';\n      }\n    }\n  }\n  \n  // Check WebGPU (optional but helpful)\n  if (!webGPU) {\n    issues.push('WebGPU is not available');\n    recommendations.push('GPU acceleration unavailable - will use CPU only');\n    if (suggestedStrategy === 'standard') {\n      suggestedStrategy = 'cpu-only';\n    }\n  }\n  \n  // Mobile-specific considerations\n  if (deviceType === 'mobile' && memory !== null && memory < 3072) {\n    issues.push('Mobile device with limited memory');\n    recommendations.push('AI models may be slow or unavailable on this device');\n    if (suggestedStrategy === 'standard') {\n      suggestedStrategy = 'low-memory';\n    }\n  }\n  \n  // Determine if AI can be used\n  if (!wasm) {\n    canUseAI = false;\n    suggestedStrategy = 'unavailable';\n  } else if (!sharedArrayBuffer && !crossOriginIsolated) {\n    // Can still try single-threaded mode\n    canUseAI = true;\n    suggestedStrategy = 'single-threaded';\n  }\n  \n  const isCompatible = wasm && (sharedArrayBuffer || crossOriginIsolated);\n  \n  return {\n    sharedArrayBuffer,\n    crossOriginIsolated,\n    webGPU,\n    wasm,\n    estimatedMemory: memory,\n    deviceType: deviceType as CompatibilityReport['deviceType'],\n    browser,\n    os,\n    isCompatible,\n    issues,\n    recommendations,\n    canUseAI,\n    suggestedStrategy\n  };\n}\n\n/**\n * Run comprehensive browser compatibility check\n * @returns CompatibilityReport with detailed diagnostics\n */\nexport function checkBrowserCompatibility(): CompatibilityReport {\n  const sharedArrayBuffer = checkSharedArrayBuffer();\n  const crossOriginIsolated = checkCrossOriginIsolated();\n  const webGPU = checkWebGPU();\n  const wasm = checkWASM();\n  const memory = estimateMemory();\n  const deviceType = detectDeviceType();\n  const browser = detectBrowser();\n  const os = detectOS();\n  \n  return generateReport(\n    sharedArrayBuffer,\n    crossOriginIsolated,\n    webGPU,\n    wasm,\n    memory,\n    deviceType,\n    browser,\n    os\n  );\n}\n\n/**\n * Get a user-friendly summary of compatibility status\n */\nexport function getCompatibilitySummary(report: CompatibilityReport): string {\n  if (!report.canUseAI) {\n    return 'AI models unavailable - browser compatibility issue';\n  }\n  \n  if (report.suggestedStrategy === 'unavailable') {\n    return 'AI models unavailable - WebAssembly not supported';\n  }\n  \n  if (report.suggestedStrategy === 'single-threaded') {\n    return 'AI models available (single-threaded mode) - enable COOP/COEP headers for better performance';\n  }\n  \n  if (report.suggestedStrategy === 'low-memory') {\n    return 'AI models available (low-memory mode) - may be slower';\n  }\n  \n  if (report.suggestedStrategy === 'cpu-only') {\n    return 'AI models available (CPU-only mode) - GPU acceleration unavailable';\n  }\n  \n  return 'AI models available - all features supported';\n}\n\n","/**\n * Progress Tracker Service\n * Centralized progress tracking for various operations (model loading, downloads, etc.)\n */\n\nexport type ProgressStatus = 'idle' | 'loading' | 'success' | 'error';\n\nexport interface ProgressState {\n  progress: number; // 0-100\n  status: ProgressStatus;\n  label: string;\n  details?: string;\n}\n\ntype ProgressCallback = (state: ProgressState) => void;\n\nlet currentProgress: ProgressState = {\n  progress: 0,\n  status: 'idle',\n  label: '',\n};\n\nconst callbacks: Set<ProgressCallback> = new Set();\n\n/**\n * Subscribe to progress updates\n */\nexport function subscribeToProgress(callback: ProgressCallback): () => void {\n  // #region agent log\n  fetch('http://127.0.0.1:7245/ingest/7d9ee931-8dee-46f8-918b-e417134eb58f',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'progressTracker.ts:28',message:'subscribeToProgress called',data:{currentStatus:currentProgress.status,currentLabel:currentProgress.label,currentProgress:currentProgress.progress},timestamp:Date.now(),sessionId:'debug-session',runId:'run1',hypothesisId:'A'})}).catch(()=>{});\n  // #endregion\n  callbacks.add(callback);\n  // Immediately call with current state\n  // #region agent log\n  fetch('http://127.0.0.1:7245/ingest/7d9ee931-8dee-46f8-918b-e417134eb58f',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'progressTracker.ts:31',message:'Immediately invoking callback with current state',data:{status:currentProgress.status,label:currentProgress.label,progress:currentProgress.progress},timestamp:Date.now(),sessionId:'debug-session',runId:'run1',hypothesisId:'A'})}).catch(()=>{});\n  // #endregion\n  callback(currentProgress);\n  \n  // Return unsubscribe function\n  return () => {\n    callbacks.delete(callback);\n  };\n}\n\n/**\n * Update progress\n */\nfunction notifyProgress(state: ProgressState) {\n  currentProgress = state;\n  callbacks.forEach(callback => {\n    try {\n      callback(state);\n    } catch (error) {\n      console.error('Progress callback error:', error);\n    }\n  });\n}\n\n/**\n * Set progress for model loading\n */\nexport function setModelLoadingProgress(progress: number, label: string, details?: string) {\n  notifyProgress({\n    progress: Math.max(0, Math.min(100, progress)),\n    status: 'loading',\n    label,\n    details,\n  });\n}\n\n/**\n * Set progress to success\n */\nexport function setProgressSuccess(label: string = 'Complete', details?: string) {\n  notifyProgress({\n    progress: 100,\n    status: 'success',\n    label,\n    details,\n  });\n}\n\n/**\n * Set progress to error\n */\nexport function setProgressError(label: string = 'Error', details?: string) {\n  notifyProgress({\n    progress: currentProgress.progress, // Keep current progress\n    status: 'error',\n    label,\n    details,\n  });\n}\n\n/**\n * Reset progress\n */\nexport function resetProgress() {\n  notifyProgress({\n    progress: 0,\n    status: 'idle',\n    label: '',\n  });\n}\n\n/**\n * Get current progress state\n */\nexport function getCurrentProgress(): ProgressState {\n  return { ...currentProgress };\n}\n\n","/**\n * AI MODEL LOADING & MANAGEMENT\n * \n * Handles loading and initialization of on-device AI models.\n * Uses @xenova/transformers for browser-based inference.\n * \n * Model Selection:\n * - 'tinyllama' (default): Best for healthcare/psychology - balanced quality and performance\n * - 'distilbert': Fast classification, good for mood assessment\n * - 'minicpm': Higher quality, larger model for complex analysis\n */\n\nimport { checkBrowserCompatibility, CompatibilityReport, getCompatibilitySummary } from './browserCompatibility';\nimport { setModelLoadingProgress, setProgressSuccess, setProgressError } from '../progressTracker';\nimport { AIModelType } from '../types';\n\n// Model definitions\nexport const MODEL_CONFIGS: Record<AIModelType, { \n  name: string; \n  path: string; \n  task: 'text-classification' | 'text-generation';\n  description: string;\n  size: string;\n}> = {\n  distilbert: {\n    name: 'DistilBERT',\n    path: 'Xenova/distilbert-base-uncased-finetuned-sst-2-english',\n    task: 'text-classification',\n    description: 'Fast sentiment analysis and mood classification',\n    size: '~67MB'\n  },\n  tinyllama: {\n    name: 'TinyLlama',\n    path: 'Xenova/TinyLlama-1.1B-Chat-v1.0',\n    task: 'text-generation',\n    description: 'Best for healthcare/psychology - balanced quality and performance',\n    size: '~637MB'\n  },\n  minicpm: {\n    name: 'MiniCPM',\n    path: 'Xenova/MiniCPM-2-4B-ONNX',\n    task: 'text-generation',\n    description: 'Higher quality for complex analysis and detailed reports',\n    size: '~1.5GB'\n  }\n};\n\n// Default model: TinyLlama (best for healthcare/psychology)\nconst DEFAULT_MODEL: AIModelType = 'tinyllama';\n\n// Model loading state\nlet moodTrackerModel: any = null;\nlet counselingCoachModel: any = null;\nlet allModelsCache: Map<AIModelType, any> = new Map(); // Cache all loaded models\nlet selectedModel: AIModelType = DEFAULT_MODEL;\nlet isModelLoading = false;\nlet modelLoadPromise: Promise<boolean> | null = null;\nlet compatibilityReport: CompatibilityReport | null = null;\nlet lastErrorCategory: 'coop-coep' | 'memory' | 'webgpu' | 'network' | 'wasm' | 'unknown' | null = null;\n\n/**\n * Get model references (for use by other modules)\n */\nexport function getMoodTrackerModel() {\n  return moodTrackerModel;\n}\n\nexport function getCounselingCoachModel() {\n  return counselingCoachModel;\n}\n\nexport function getIsModelLoading() {\n  return isModelLoading;\n}\n\n/**\n * Check if a model supports text generation\n */\nexport function isTextGenerationModel(model: any): boolean {\n  if (!model) return false;\n  \n  try {\n    // Check if model has task property indicating text-generation\n    if (model.task === 'text-generation') {\n      return true;\n    }\n    \n    // Check if model is a function that accepts generation options\n    // Text-generation models accept (text, options) signature\n    if (typeof model === 'function') {\n      // Generation models typically accept options object\n      return true; // Assume function models are generation-capable\n    }\n    \n    return false;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Get the currently selected model type\n */\nexport function getSelectedModel(): AIModelType {\n  return selectedModel;\n}\n\n/**\n * Set the selected model type (will reload models on next initialization)\n */\nexport function setSelectedModel(modelType: AIModelType): void {\n  selectedModel = modelType;\n}\n\n/**\n * Get model configuration for a specific model type\n */\nexport function getModelConfig(modelType: AIModelType) {\n  return MODEL_CONFIGS[modelType];\n}\n\n/**\n * Get all available model configurations\n */\nexport function getAllModelConfigs() {\n  return MODEL_CONFIGS;\n}\n\n/**\n * Clear models to force re-download/update\n */\nexport async function clearModels(): Promise<void> {\n  moodTrackerModel = null;\n  counselingCoachModel = null;\n  allModelsCache.clear();\n  isModelLoading = false;\n  modelLoadPromise = null;\n  \n  // Clear model cache\n  if ('caches' in window) {\n    const cacheKeys = await caches.keys();\n    for (const key of cacheKeys) {\n      if (key.includes('transformers') || key.includes('model') || key.includes('onnx')) {\n        await caches.delete(key);\n      }\n    }\n  }\n}\n\n/**\n * Initialize on-device models\n * Uses @xenova/transformers for browser-based inference\n * Loads the user-selected model (default: TinyLlama for healthcare/psychology)\n * @param forceReload - If true, clears existing models and reloads\n * @param modelType - Optional model type override (uses selected model if not provided)\n * @returns true if models loaded successfully, false if fallback mode is used\n */\nexport async function initializeModels(forceReload: boolean = false, modelType?: AIModelType): Promise<boolean> {\n  // If modelType provided, update selected model\n  if (modelType && modelType !== selectedModel) {\n    selectedModel = modelType;\n    // If switching models, force reload\n    if (moodTrackerModel || counselingCoachModel) {\n      forceReload = true;\n    }\n  }\n  \n  const targetModel = modelType || selectedModel;\n  \n  if (forceReload) {\n    await clearModels();\n  }\n  \n  // Check if we already have the selected model loaded\n  if (moodTrackerModel && counselingCoachModel && selectedModel === targetModel && !forceReload) {\n    return true; // Already loaded with correct model\n  }\n\n  if (isModelLoading && modelLoadPromise && !forceReload) {\n    // Wait for existing load and return its result\n    try {\n      await modelLoadPromise;\n      return moodTrackerModel !== null && counselingCoachModel !== null;\n    } catch {\n      return false;\n    }\n  }\n  \n  // Update selected model if override provided\n  if (modelType && modelType !== selectedModel) {\n    selectedModel = modelType;\n  }\n\n  isModelLoading = true;\n  \n  // Set a timeout to prevent infinite loading\n  let loadingTimeout: NodeJS.Timeout | null = null;\n  loadingTimeout = setTimeout(() => {\n    if (isModelLoading) {\n      console.warn('‚ö†Ô∏è Model loading timeout - stopping after 60 seconds');\n      isModelLoading = false;\n      setProgressError('Model loading timeout', 'Models took too long to load. Using rule-based responses.');\n    }\n  }, 60000);\n  \n  modelLoadPromise = (async () => {\n    try {\n      // Run browser compatibility check first\n      compatibilityReport = checkBrowserCompatibility();\n      lastErrorCategory = null;\n      \n      // Log compatibility summary\n      const summary = getCompatibilitySummary(compatibilityReport);\n      console.log(`üîç Browser compatibility: ${summary}`);\n      \n      // If AI cannot be used at all (e.g., no WASM), skip initialization\n      if (!compatibilityReport.canUseAI) {\n        console.warn('‚ö†Ô∏è AI models cannot be used on this browser. Using rule-based responses.');\n        if (!compatibilityReport.wasm) {\n          lastErrorCategory = 'wasm';\n        } else if (!compatibilityReport.sharedArrayBuffer) {\n          lastErrorCategory = 'coop-coep';\n          console.warn('‚ö†Ô∏è SharedArrayBuffer not available. Enable COOP/COEP headers or use HTTP/HTTPS server.');\n        }\n        isModelLoading = false;\n        setProgressError('AI models unavailable', 'SharedArrayBuffer not available. Use HTTP/HTTPS server with COOP/COEP headers.');\n        return false;\n      }\n      \n      // Set up environment before importing\n      if (typeof window !== 'undefined') {\n        (window as any).__TRANSFORMERS_ENV__ = (window as any).__TRANSFORMERS_ENV__ || {};\n      }\n      \n      // Dynamic import with error boundary\n      // The registerBackend error is a known browser compatibility issue\n      // We'll catch it gracefully and use rule-based responses\n      let transformersModule;\n      \n      try {\n        // Attempt import - this may fail with registerBackend error in some browsers\n        transformersModule = await import('@xenova/transformers');\n        \n        // Verify the module loaded correctly\n        if (!transformersModule || !transformersModule.pipeline) {\n          console.info('‚ÑπÔ∏è Transformers module structure invalid. Using rule-based responses.');\n          return false;\n        }\n      } catch (importError: any) {\n        // Catch the registerBackend error and other import errors\n        const errorMsg = importError?.message || String(importError);\n        const errorStack = importError?.stack || '';\n        \n        // Categorize the error\n        if (errorMsg.includes('registerBackend') || errorMsg.includes('ort-web') || errorStack.includes('ort-web')) {\n          lastErrorCategory = 'coop-coep';\n          console.info('‚ÑπÔ∏è AI models unavailable: ONNX Runtime backend initialization failed.');\n          if (compatibilityReport && !compatibilityReport.sharedArrayBuffer) {\n            console.info('‚ÑπÔ∏è This is likely due to missing COOP/COEP headers. See SERVER_CONFIG.md for setup instructions.');\n          }\n          console.info('‚ÑπÔ∏è App uses rule-based responses (fully functional).');\n        } else if (errorMsg.includes('memory') || errorMsg.includes('OOM') || errorMsg.includes('out of memory')) {\n          lastErrorCategory = 'memory';\n          console.info('‚ÑπÔ∏è AI models unavailable: Insufficient device memory.');\n          console.info('‚ÑπÔ∏è App uses rule-based responses (fully functional).');\n        } else if (errorMsg.includes('network') || errorMsg.includes('fetch') || errorMsg.includes('Failed to fetch')) {\n          lastErrorCategory = 'network';\n          console.info('‚ÑπÔ∏è AI models unavailable: Network error during download.');\n          console.info('‚ÑπÔ∏è App uses rule-based responses (fully functional).');\n        } else {\n          lastErrorCategory = 'unknown';\n          console.info('‚ÑπÔ∏è AI models unavailable. App uses rule-based responses (fully functional).');\n        }\n        return false;\n      }\n      \n      const { pipeline, env } = transformersModule;\n      \n      // Check if the module loaded correctly\n      if (!pipeline || !env) {\n        throw new Error('Transformers module did not load correctly');\n      }\n      \n      // Verify pipeline is a function\n      if (typeof pipeline !== 'function') {\n        throw new Error('Pipeline function not available in transformers module');\n      }\n      \n      // Configure transformers.js for browser use based on compatibility\n      // Configure BEFORE any backend access to avoid registerBackend errors\n      try {\n        env.allowLocalModels = true;\n        env.allowRemoteModels = true;\n        env.useBrowserCache = true;\n        env.useCustomCache = false;\n        \n        // Configure model loading and storage\n        // Transformers.js automatically:\n        // 1. Downloads models from HuggingFace on first use\n        // 2. Stores them in browser IndexedDB (when useBrowserCache = true)\n        // 3. Loads from IndexedDB cache on subsequent runs (instant, no download)\n        // \n        // Storage location: Browser IndexedDB (managed by transformers.js)\n        // Cache key format: transformers-cache-{model-name}\n        // Models persist across browser sessions automatically\n        env.cacheDir = './models-cache'; // Virtual path - actual storage is IndexedDB\n        env.useBrowserCache = true; // Enable IndexedDB caching\n        env.allowRemoteModels = true; // Allow downloading from HuggingFace\n        \n        console.log('üì¶ Models will download from HuggingFace and cache in IndexedDB');\n        \n        // Configure based on compatibility report\n        if (compatibilityReport) {\n          // Disable WebGPU if not available\n          if (!compatibilityReport.webGPU) {\n            try {\n              env.backends = env.backends || {};\n              // Prefer CPU backend when WebGPU unavailable\n              console.log('‚ö†Ô∏è WebGPU unavailable, using CPU backend');\n            } catch (e) {\n              // Ignore if backends config not available\n            }\n          }\n          \n          // Use single-threaded mode if SharedArrayBuffer unavailable\n          if (!compatibilityReport.sharedArrayBuffer) {\n            console.log('‚ö†Ô∏è SharedArrayBuffer unavailable, using single-threaded mode');\n            // Note: transformers.js will automatically fall back to single-threaded\n          }\n        }\n      } catch (configError) {\n        console.warn('Could not configure transformers environment, using defaults:', configError);\n        // Continue anyway - library may have defaults\n      }\n      \n      // Wait a moment for any backend initialization to complete\n      await new Promise(resolve => setTimeout(resolve, 100));\n      \n      // Don't try to configure backends manually - let transformers.js handle it\n      // This avoids the registerBackend error\n      \n      // Models will be downloaded and cached locally on first use\n      \n      // Model A: Mental state tracker (mood/anxiety/depression assessment)\n      // Start with a simpler, more reliable model that works better in browsers\n      // Use text-classification models first as they're more stable than text-generation\n      console.log('Loading psychology-centric AI model...');\n      \n      // Progress callback for model loading\n      let totalProgress = 0;\n      let modelsLoaded = 0;\n      const totalModels = 2; // moodTracker + counselingCoach\n      \n      const progressCallback = (progress: any) => {\n        if (progress.status === 'progress') {\n          const percent = progress.progress ? Math.round(progress.progress * 100) : 0;\n          const modelProgress = Math.round((modelsLoaded / totalModels) * 100 + (percent / totalModels));\n          totalProgress = Math.min(100, modelProgress);\n          \n          const modelName = progress.name || 'model';\n          setModelLoadingProgress(\n            totalProgress,\n            `Loading AI models...`,\n            `${modelName}: ${percent}%`\n          );\n          console.log(`Model loading: ${modelName} - ${percent}%`);\n        } else if (progress.status === 'done') {\n          modelsLoaded++;\n          const modelProgress = Math.round((modelsLoaded / totalModels) * 100);\n          totalProgress = Math.min(100, modelProgress);\n          \n          const modelName = progress.name || 'model';\n          setModelLoadingProgress(\n            totalProgress,\n            `Loading AI models...`,\n            `${modelName} loaded`\n          );\n          console.log(`Model loaded: ${modelName}`);\n        }\n      };\n      \n      // Load the user-selected model (default: TinyLlama for healthcare/psychology)\n      const modelConfig = MODEL_CONFIGS[targetModel];\n      console.log(`Loading ${modelConfig.name} (${modelConfig.description})...`);\n      \n      // Check memory constraints - warn if low memory and trying to load large model\n      const strategy = compatibilityReport?.suggestedStrategy || 'standard';\n      const useLowMemory = strategy === 'low-memory' || (compatibilityReport?.estimatedMemory !== null && compatibilityReport.estimatedMemory < 2048);\n      \n      if (useLowMemory && targetModel === 'minicpm') {\n        console.warn('‚ö†Ô∏è Low memory detected. MiniCPM may not load. Consider using TinyLlama instead.');\n      }\n      \n      // Load Model A: Mental state tracker (mood/anxiety/depression assessment)\n      // For DistilBERT, use text-classification; for others, use text-generation\n      try {\n        console.log(`Attempting to load ${modelConfig.name} for mood tracking...`);\n        moodTrackerModel = await pipeline(\n          modelConfig.task,\n          modelConfig.path,\n          { \n            quantized: true,\n            progress_callback: progressCallback\n          }\n        );\n        console.log(`‚úì ${modelConfig.name} model loaded successfully for mood tracking`);\n        \n        // Cache the model\n        allModelsCache.set(targetModel, moodTrackerModel);\n      } catch (modelError: any) {\n        const errorMsg = modelError?.message || String(modelError);\n        const errorStack = modelError?.stack || '';\n        \n        // Check if it's a backend/ONNX error\n        const isBackendError = errorMsg.includes('registerBackend') || \n                               errorMsg.includes('ort-web') ||\n                               errorStack.includes('ort-web') ||\n                               errorMsg.includes('Cannot read properties');\n        \n        if (isBackendError) {\n          lastErrorCategory = 'coop-coep';\n          console.error('Backend initialization error detected. This is likely a browser compatibility issue with ONNX Runtime.');\n          if (compatibilityReport && !compatibilityReport.sharedArrayBuffer) {\n            console.warn('SharedArrayBuffer unavailable. Enable COOP/COEP headers (see SERVER_CONFIG.md).');\n          }\n          console.warn('The app will continue using rule-based responses. AI features will not be available.');\n          moodTrackerModel = null;\n        } else if (errorMsg.includes('memory') || errorMsg.includes('OOM')) {\n          lastErrorCategory = 'memory';\n          console.error(`Memory error loading ${modelConfig.name}. Device may have insufficient memory.`);\n          moodTrackerModel = null;\n        } else {\n          lastErrorCategory = 'unknown';\n          console.error(`Failed to load ${modelConfig.name}:`, modelError);\n          moodTrackerModel = null;\n        }\n      }\n\n      // Model B: Counseling coach - Use same model if it's text-generation, otherwise load TinyLlama\n      console.log('Loading counseling coach model...');\n      \n      // Check if moodTrackerModel is a text-generation model we can reuse\n      let canReuseModel = false;\n      if (moodTrackerModel) {\n        try {\n          const modelTask = (moodTrackerModel as any).task;\n          if (modelTask === 'text-generation') {\n            canReuseModel = true;\n            console.log(`‚úì Reusing ${modelConfig.name} for counseling (text-generation model)`);\n          }\n        } catch {\n          canReuseModel = false;\n        }\n      }\n      \n      if (!canReuseModel) {\n        // Need a text-generation model for counseling\n        // If user selected DistilBERT (classification), load TinyLlama for counseling\n        const counselingModelType = targetModel === 'distilbert' ? 'tinyllama' : targetModel;\n        const counselingConfig = MODEL_CONFIGS[counselingModelType];\n        \n        // Check if we already have this model cached\n        if (allModelsCache.has(counselingModelType)) {\n          counselingCoachModel = allModelsCache.get(counselingModelType);\n          console.log(`‚úì Using cached ${counselingConfig.name} for counseling`);\n        } else {\n          try {\n            console.log(`Attempting to load ${counselingConfig.name} for counseling...`);\n            counselingCoachModel = await pipeline(\n              'text-generation',\n              counselingConfig.path,\n              { \n                quantized: true,\n                progress_callback: progressCallback\n              }\n            );\n            console.log(`‚úì ${counselingConfig.name} loaded successfully for counseling`);\n            \n            // Cache the model\n            allModelsCache.set(counselingModelType, counselingCoachModel);\n          } catch (counselingError: any) {\n            const counselingMsg = counselingError?.message || String(counselingError);\n            const counselingStack = counselingError?.stack || '';\n            const isCounselingBackendError = counselingMsg.includes('registerBackend') || \n                                            counselingMsg.includes('ort-web') ||\n                                            counselingStack.includes('ort-web');\n            \n            if (isCounselingBackendError) {\n              lastErrorCategory = 'coop-coep';\n              console.error('Backend initialization error with counseling model. Browser may not support ONNX Runtime.');\n              counselingCoachModel = null;\n            } else if (counselingMsg.includes('memory') || counselingMsg.includes('OOM')) {\n              lastErrorCategory = 'memory';\n              console.error('Memory error loading counseling model.');\n              counselingCoachModel = null;\n            } else {\n              lastErrorCategory = 'unknown';\n              console.error('Counseling model load failed:', counselingError);\n              counselingCoachModel = null;\n            }\n          }\n        }\n      } else {\n        // Reuse the text-generation model for both tasks\n        counselingCoachModel = moodTrackerModel;\n        console.log(`‚úì Using ${modelConfig.name} for both mood tracking and counseling`);\n      }\n      \n      if (counselingCoachModel) {\n        console.log('‚úì Counseling coach model ready for guidance and encouragement');\n      } else {\n        console.log('‚ö†Ô∏è Using rule-based counseling guidance (models unavailable)');\n      }\n\n      const modelsReady = moodTrackerModel !== null && counselingCoachModel !== null;\n      if (loadingTimeout) clearTimeout(loadingTimeout);\n      isModelLoading = false;\n      \n      if (modelsReady) {\n        setProgressSuccess('AI models loaded successfully!', 'All models are ready to use');\n        console.log('‚úÖ All AI models loaded and ready!');\n        console.log(`  - Mood tracker: ${moodTrackerModel ? '‚úì' : '‚úó'}`);\n        console.log(`  - Counseling coach: ${counselingCoachModel ? '‚úì' : '‚úó'}`);\n      } else {\n        setProgressError('AI models unavailable', 'App will use rule-based responses');\n        console.warn('‚ö†Ô∏è AI models not available. App will use rule-based responses.');\n        console.warn(`  - Mood tracker: ${moodTrackerModel ? '‚úì Loaded' : '‚úó Failed'}`);\n        console.warn(`  - Counseling coach: ${counselingCoachModel ? '‚úì Loaded' : '‚úó Failed'}`);\n        \n        // If at least one model loaded, log that partial loading is available\n        if (moodTrackerModel || counselingCoachModel) {\n          console.info('‚ÑπÔ∏è Partial model loading: Some AI features may be available.');\n        } else {\n          console.info('‚ÑπÔ∏è All models failed to load. This is likely a browser compatibility issue with ONNX Runtime.');\n          console.info('‚ÑπÔ∏è The app will use rule-based responses which are fully functional.');\n        }\n      }\n      \n      return modelsReady;\n    } catch (error) {\n      if (loadingTimeout) clearTimeout(loadingTimeout);\n      console.error('Model initialization error:', error);\n      isModelLoading = false;\n      moodTrackerModel = null;\n      counselingCoachModel = null;\n      setProgressError('Model loading failed', 'App will use rule-based responses');\n      \n      // Provide more specific error message based on category\n      const errorMessage = error instanceof Error ? error.message : String(error);\n      \n      if (!lastErrorCategory) {\n        // Categorize error if not already categorized\n        if (errorMessage.includes('registerBackend') || errorMessage.includes('backend') || errorMessage.includes('ort-web')) {\n          lastErrorCategory = 'coop-coep';\n        } else if (errorMessage.includes('memory') || errorMessage.includes('OOM') || errorMessage.includes('out of memory')) {\n          lastErrorCategory = 'memory';\n        } else if (errorMessage.includes('network') || errorMessage.includes('fetch') || errorMessage.includes('Failed to fetch')) {\n          lastErrorCategory = 'network';\n        } else if (errorMessage.includes('WebAssembly') || errorMessage.includes('WASM')) {\n          lastErrorCategory = 'wasm';\n        } else {\n          lastErrorCategory = 'unknown';\n        }\n      }\n      \n      // Provide specific error messages\n      switch (lastErrorCategory) {\n        case 'coop-coep':\n          console.error('Backend initialization failed. This is likely due to missing COOP/COEP headers.');\n          if (compatibilityReport && !compatibilityReport.sharedArrayBuffer) {\n            console.warn('SharedArrayBuffer unavailable. See SERVER_CONFIG.md for server configuration.');\n          }\n          console.warn('App will continue with rule-based responses. AI features will not be available.');\n          break;\n        case 'memory':\n          console.error('Memory error: Device has insufficient memory for AI models.');\n          console.warn('App will continue with rule-based responses. AI features will not be available.');\n          break;\n        case 'network':\n          console.warn('Failed to download AI models. Check your internet connection.');\n          console.warn('App will use rule-based responses.');\n          break;\n        case 'wasm':\n          console.error('WebAssembly not supported. AI models cannot run on this browser.');\n          console.warn('App will continue with rule-based responses.');\n          break;\n        default:\n          console.warn('Failed to load on-device models. App will use rule-based responses instead.');\n      }\n      \n      // Return false to indicate failure, but don't throw\n      return false;\n    }\n  })();\n\n  return modelLoadPromise;\n}\n\n/**\n * Preload models in the background\n * Called on app startup to prepare models for faster response times\n */\nexport async function preloadModels(): Promise<boolean> {\n  console.log('üöÄ Starting background model preload...');\n  \n  try {\n    // Check if models are already loaded\n    if (areModelsLoaded()) {\n      console.log('‚úÖ Models already loaded, skipping preload.');\n      return true;\n    }\n    \n    // Try to load models with retries\n    let attempts = 0;\n    const maxAttempts = 4;\n    let lastError: any = null;\n    \n    while (attempts < maxAttempts) {\n      attempts++;\n      \n      // Only log first and last attempts to reduce console noise\n      if (attempts === 1 || attempts === maxAttempts) {\n        console.log(`üöÄ Starting AI model preload in background (attempt ${attempts}/${maxAttempts})...`);\n      }\n      \n      try {\n        const loaded = await initializeModels();\n        if (loaded) {\n          console.log('‚úÖ Background model preload successful!');\n          return true;\n        }\n        \n        // Check what we actually have\n        const moodModel = getMoodTrackerModel();\n        const counselingModel = getCounselingCoachModel();\n        \n        if (moodModel || counselingModel) {\n          console.log(`‚ÑπÔ∏è Partial model loading: ${moodModel ? 'Mood tracker ‚úì' : 'Mood tracker ‚úó'}, ${counselingModel ? 'Counseling coach ‚úì' : 'Counseling coach ‚úó'}`);\n          // Continue trying to load the missing model\n        }\n      } catch (error) {\n        lastError = error;\n        const errorMsg = error instanceof Error ? error.message : String(error);\n        if (attempts === maxAttempts) {\n          console.warn(`Model preload attempt ${attempts} failed:`, errorMsg);\n        }\n      }\n      \n      if (attempts < maxAttempts) {\n        // Wait before retrying (exponential backoff)\n        const delay = Math.min(1000 * Math.pow(2, attempts - 1), 5000);\n        await new Promise(resolve => setTimeout(resolve, delay));\n      }\n    }\n    \n    // Final status check\n    const finalMoodModel = getMoodTrackerModel();\n    const finalCounselingModel = getCounselingCoachModel();\n    \n    if (finalMoodModel || finalCounselingModel) {\n      console.log(`‚ö†Ô∏è Model preload completed with partial loading:`);\n      console.log(`  - Mood tracker: ${finalMoodModel ? '‚úì' : '‚úó'}`);\n      console.log(`  - Counseling coach: ${finalCounselingModel ? '‚úì' : '‚úó'}`);\n      console.log(`  - Some AI features may be available.`);\n    } else {\n      console.log('‚ö†Ô∏è Model preload completed but models not available. Will use rule-based fallbacks.');\n      if (lastError) {\n        const errorMsg = lastError instanceof Error ? lastError.message : String(lastError);\n        if (errorMsg.includes('registerBackend') || errorMsg.includes('ort-web')) {\n          console.info('‚ÑπÔ∏è This appears to be a browser compatibility issue with ONNX Runtime.');\n          console.info('‚ÑπÔ∏è The app is fully functional with rule-based responses.');\n        }\n      }\n    }\n    \n    return false;\n  } catch (error) {\n    console.warn('Model preload error (non-critical):', error);\n    return false;\n  }\n}\n\n/**\n * Check if models are currently loaded\n * @param requireBoth - If true, requires both models. If false, returns true if at least one is loaded.\n */\nexport function areModelsLoaded(requireBoth: boolean = true): boolean {\n  if (requireBoth) {\n    return moodTrackerModel !== null && counselingCoachModel !== null;\n  }\n  return moodTrackerModel !== null || counselingCoachModel !== null;\n}\n\n/**\n * Get current model status\n */\nexport function getModelStatus(): { \n  loaded: boolean; \n  loading: boolean;\n  moodTracker: boolean;\n  counselingCoach: boolean;\n  compatibility?: CompatibilityReport;\n  errorCategory?: 'coop-coep' | 'memory' | 'webgpu' | 'network' | 'wasm' | 'unknown' | null;\n} {\n  return {\n    loaded: areModelsLoaded(),\n    loading: isModelLoading,\n    moodTracker: moodTrackerModel !== null,\n    counselingCoach: counselingCoachModel !== null,\n    compatibility: compatibilityReport,\n    errorCategory: lastErrorCategory\n  };\n}\n\n/**\n * Get compatibility report\n */\nexport function getCompatibilityReport(): CompatibilityReport | null {\n  return compatibilityReport;\n}\n\n","/**\n * COMPREHENSIVE CRISIS DETECTION CONFIGURATION\n * \n * This file contains all crisis detection phrases and categories.\n * These are HARDCODED and NON-EDITABLE to ensure user safety.\n * \n * Based on mental health best practices and crisis intervention guidelines.\n */\n\nexport type CrisisCategory = \n  | 'CRISIS_SUICIDAL_IDEATION_DIRECT'\n  | 'CRISIS_SUICIDAL_IDEATION_INDIRECT'\n  | 'CRISIS_PLANNING_OR_METHOD'\n  | 'CRISIS_SELF_HARM'\n  | 'RISK_SEVERE_HOPELESSNESS'\n  | 'RISK_BEHAVIORAL_RED_FLAGS'\n  | 'CRISIS_THIRD_PARTY_SUICIDE_RISK'\n  | 'CRISIS_IMMINENT_DANGER';\n\nexport interface CrisisPhrase {\n  phrase: string;\n  category: CrisisCategory;\n  severity: 'critical' | 'high' | 'moderate';\n}\n\n/**\n * 1. Direct suicide statements\n * CRITICAL - Immediate emergency response required\n */\nconst DIRECT_SUICIDE_PHRASES: CrisisPhrase[] = [\n  { phrase: 'i want to die', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i want to kill myself', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i am going to kill myself', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'m suicidal', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i have suicidal thoughts', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'ve been thinking about suicide', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i am planning to end my life', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'m going to end it all', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'m going to end my life', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i want to end it', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'m done with life', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i don\\'t want to live anymore', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'life is not worth living', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'m better off dead', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'everyone would be better off without me', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i wish i hadn\\'t been born', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i wish i were dead', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i wish i didn\\'t exist', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i\\'m thinking about ending everything', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i just want it all to stop permanently', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i can\\'t go on living like this', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n  { phrase: 'i have no reason to live', category: 'CRISIS_SUICIDAL_IDEATION_DIRECT', severity: 'critical' },\n];\n\n/**\n * 2. Indirect or coded suicidal ideation\n * HIGH - Crisis response required\n */\nconst INDIRECT_SUICIDE_PHRASES: CrisisPhrase[] = [\n  { phrase: 'i can\\'t go on', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i can\\'t do this anymore', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i\\'m at the end of my rope', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i feel trapped', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'there\\'s no way out', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i\\'m done', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i\\'m finished', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i\\'m so tired of this life', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i just want to disappear', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i just want to go to sleep and not wake up', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i don\\'t want to be here anymore', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i don\\'t see a future for myself', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'nothing will ever get better', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'there\\'s no point in trying anymore', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i have nothing to live for', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i\\'m such a burden', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'people would be better off without me', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'the world would be better if i were gone', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'soon this will all be over', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'if i see you again', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'i won\\'t be around much longer', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n  { phrase: 'you won\\'t have to worry about me soon', category: 'CRISIS_SUICIDAL_IDEATION_INDIRECT', severity: 'high' },\n];\n\n/**\n * 3. Mentioning specific methods or preparation\n * CRITICAL - Immediate emergency response required\n */\nconst METHOD_PHRASES: CrisisPhrase[] = [\n  { phrase: 'i\\'m going to jump', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'jump off a bridge', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'jump in front of a train', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'i\\'m going to take all my pills', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'i\\'m going to overdose', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'use gun on myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'use knife on myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'use razor on myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'i\\'m going to hang myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'i\\'m going to drown myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'researching painless ways to die', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'looking up how to kill myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'how many pills it takes to overdose', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'most effective suicide methods', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'bought a gun for myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'bought a rope', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'saving my meds for when i\\'m ready', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'wrote my suicide note', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'picked the day i\\'m going to do it', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'i know exactly how i\\'m going to end my life', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'i have everything ready to end it', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'tried to overdose before', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'tried to cut before', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'tried to jump before', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'tried to hang myself before', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n  { phrase: 'last time i tried to kill myself', category: 'CRISIS_PLANNING_OR_METHOD', severity: 'critical' },\n];\n\n/**\n * 4. Self-harm without explicit suicide\n * HIGH - Crisis response required\n */\nconst SELF_HARM_PHRASES: CrisisPhrase[] = [\n  { phrase: 'i\\'ve been cutting myself', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i cut myself to cope', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i hurt myself on purpose', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'scratching myself until i bleed', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i\\'ve been burning myself', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i punch myself', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i hit my head', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i pull out my hair when i\\'m upset', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i starve myself on purpose', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i binge and then make myself throw up', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i want to hurt myself', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i\\'m scared i might hurt myself', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i can\\'t stop hurting myself', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i like seeing myself bleed', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i deserve to be hurt', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i\\'m thinking about cutting again', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i have the blade ready', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i have the knife ready', category: 'CRISIS_SELF_HARM', severity: 'high' },\n  { phrase: 'i have the razor ready', category: 'CRISIS_SELF_HARM', severity: 'high' },\n];\n\n/**\n * 5. Severe hopelessness, worthlessness, and burden language\n * MODERATE - Escalate if combined with other crisis phrases\n */\nconst HOPELESSNESS_PHRASES: CrisisPhrase[] = [\n  { phrase: 'i feel hopeless', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'nothing will ever change', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i feel completely alone', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i feel empty all the time', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i\\'m useless', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i\\'m worthless', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i\\'m a failure at everything', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i hate myself', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i\\'m disgusting', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i\\'m a burden to everyone', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'everyone hates me', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'nobody cares if i live or die', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'no one would miss me', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i don\\'t matter', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i have no purpose', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n  { phrase: 'i\\'m broken beyond repair', category: 'RISK_SEVERE_HOPELESSNESS', severity: 'moderate' },\n];\n\n/**\n * 6. Drastic behavior or context flags\n * MODERATE - Escalate if combined with crisis phrases\n */\nconst BEHAVIORAL_RED_FLAGS: CrisisPhrase[] = [\n  { phrase: 'i\\'ve been giving away my stuff', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i\\'m saying goodbye to people', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i\\'ve been writing letters to everyone', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'making sure everything is in order for when i\\'m gone', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i quit my job and don\\'t care what happens', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i\\'ve been isolating from everyone', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i don\\'t talk to my friends or family anymore', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i stay in my room all day', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i started drinking a lot more', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i\\'m using drugs to escape', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i\\'ve been driving recklessly on purpose', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n  { phrase: 'i don\\'t care if i get hurt anymore', category: 'RISK_BEHAVIORAL_RED_FLAGS', severity: 'moderate' },\n];\n\n/**\n * 7. Third-person / concern-for-others language\n * HIGH - Crisis response for the person being described\n */\nconst THIRD_PARTY_PHRASES: CrisisPhrase[] = [\n  { phrase: 'my friend wants to kill themselves', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'my friend is talking about suicide', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'my friend said they want to die', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'someone i know is going to end their life', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'my child keeps saying they wish they were dead', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'my partner said the world would be better without them', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'a friend told me they are going to overdose', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'someone i know is cutting themself', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'my friend is talking about how they would do it', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'my friend wrote a suicide note', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n  { phrase: 'i\\'m scared my friend will hurt themselves', category: 'CRISIS_THIRD_PARTY_SUICIDE_RISK', severity: 'high' },\n];\n\n/**\n * 8. Escalation / urgency phrases\n * CRITICAL - Immediate emergency response required\n */\nconst IMMINENT_DANGER_PHRASES: CrisisPhrase[] = [\n  { phrase: 'i\\'m going to do it now', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m going to do it tonight', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i can\\'t stop myself', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i don\\'t think i can stay safe', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m alone and i\\'m scared of what i might do', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i already took the pills', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i already cut myself and it won\\'t stop bleeding', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m bleeding a lot', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i swallowed a lot of pills', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i just tried to hang myself', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i just tried to kill myself', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m sitting here with a gun', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m sitting here with a knife', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m sitting here with pills', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m sitting here with a rope', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n  { phrase: 'i\\'m in the car ready to drive off the bridge', category: 'CRISIS_IMMINENT_DANGER', severity: 'critical' },\n];\n\n/**\n * All crisis phrases combined\n * This is the master list used for detection\n */\nexport const ALL_CRISIS_PHRASES: CrisisPhrase[] = [\n  ...DIRECT_SUICIDE_PHRASES,\n  ...INDIRECT_SUICIDE_PHRASES,\n  ...METHOD_PHRASES,\n  ...SELF_HARM_PHRASES,\n  ...HOPELESSNESS_PHRASES,\n  ...BEHAVIORAL_RED_FLAGS,\n  ...THIRD_PARTY_PHRASES,\n  ...IMMINENT_DANGER_PHRASES,\n];\n\n/**\n * Get all phrases for a specific category\n */\nexport function getPhrasesByCategory(category: CrisisCategory): CrisisPhrase[] {\n  return ALL_CRISIS_PHRASES.filter(p => p.category === category);\n}\n\n/**\n * Get all phrases by severity\n */\nexport function getPhrasesBySeverity(severity: 'critical' | 'high' | 'moderate'): CrisisPhrase[] {\n  return ALL_CRISIS_PHRASES.filter(p => p.severity === severity);\n}\n\n/**\n * Get category display name\n */\nexport function getCategoryDisplayName(category: CrisisCategory): string {\n  const names: Record<CrisisCategory, string> = {\n    'CRISIS_SUICIDAL_IDEATION_DIRECT': 'Direct Suicide Statements',\n    'CRISIS_SUICIDAL_IDEATION_INDIRECT': 'Indirect Suicide Statements',\n    'CRISIS_PLANNING_OR_METHOD': 'Suicide Planning or Methods',\n    'CRISIS_SELF_HARM': 'Self-Harm',\n    'RISK_SEVERE_HOPELESSNESS': 'Severe Hopelessness',\n    'RISK_BEHAVIORAL_RED_FLAGS': 'Behavioral Warning Signs',\n    'CRISIS_THIRD_PARTY_SUICIDE_RISK': 'Concern for Others',\n    'CRISIS_IMMINENT_DANGER': 'Immediate Danger',\n  };\n  return names[category] || category;\n}\n\n","/**\n * CRISIS DETECTION & RESPONSE\n * \n * Handles crisis detection and provides appropriate safety responses.\n * Uses comprehensive, hardcoded crisis phrase list (non-editable for safety).\n */\n\nimport { CrisisDetection, LCSWConfig } from \"../types\";\nimport { ALL_CRISIS_PHRASES, CrisisCategory } from \"../crisisConfig\";\n\n/**\n * Crisis detection - scans text for safety phrases and crisis indicators\n * This runs BEFORE any AI processing to ensure safety\n * Uses comprehensive, hardcoded crisis phrase list (non-editable for safety)\n */\nexport function detectCrisis(text: string, lcswConfig?: LCSWConfig): CrisisDetection {\n  const lowerText = text.toLowerCase();\n  \n  // Use comprehensive hardcoded crisis phrases (non-editable)\n  // User-provided phrases in lcswConfig are IGNORED for safety\n  const detectedPhrases: string[] = [];\n  const detectedCategories: CrisisCategory[] = [];\n  let maxSeverity: 'low' | 'moderate' | 'high' | 'critical' = 'low';\n\n  // Scan text against all crisis phrases\n  for (const crisisPhrase of ALL_CRISIS_PHRASES) {\n    if (lowerText.includes(crisisPhrase.phrase)) {\n      detectedPhrases.push(crisisPhrase.phrase);\n      if (!detectedCategories.includes(crisisPhrase.category)) {\n        detectedCategories.push(crisisPhrase.category);\n      }\n      \n      // Determine maximum severity\n      if (crisisPhrase.severity === 'critical') {\n        maxSeverity = 'critical';\n      } else if (crisisPhrase.severity === 'high' && maxSeverity !== 'critical') {\n        maxSeverity = 'high';\n      } else if (crisisPhrase.severity === 'moderate' && maxSeverity === 'low') {\n        maxSeverity = 'moderate';\n      }\n    }\n  }\n\n  // Escalation logic: if moderate risk phrases are combined with any crisis phrase, escalate\n  const hasModerateRisk = detectedCategories.some(cat => \n    cat === 'RISK_SEVERE_HOPELESSNESS' || cat === 'RISK_BEHAVIORAL_RED_FLAGS'\n  );\n  const hasCrisisCategory = detectedCategories.some(cat => \n    cat.startsWith('CRISIS_')\n  );\n  \n  if (hasModerateRisk && hasCrisisCategory && maxSeverity === 'moderate') {\n    maxSeverity = 'high';\n  }\n\n  const isCrisis = detectedPhrases.length > 0;\n  \n  // Determine recommended action based on severity and categories\n  let recommendedAction: CrisisDetection['recommendedAction'] = 'continue';\n  \n  if (maxSeverity === 'critical') {\n    recommendedAction = 'emergency';\n  } else if (\n    maxSeverity === 'high' || \n    detectedCategories.includes('CRISIS_SELF_HARM') ||\n    detectedCategories.includes('CRISIS_THIRD_PARTY_SUICIDE_RISK')\n  ) {\n    recommendedAction = 'contact_lcsw';\n  } else if (isCrisis) {\n    recommendedAction = 'show_crisis_info';\n  }\n\n  return {\n    isCrisis,\n    severity: maxSeverity,\n    detectedPhrases,\n    recommendedAction,\n    categories: detectedCategories\n  };\n}\n\n/**\n * Get crisis response - provides safety information and resources\n * Uses clear, direct, non-judgmental language that avoids stigmatizing phrases\n * Always routes to real-world support (988/911) and trusted people\n */\nexport function getCrisisResponse(crisis: CrisisDetection, lcswConfig?: LCSWConfig): string {\n  const emergencyContact = lcswConfig?.emergencyContact;\n  const therapistContact = emergencyContact \n    ? `${emergencyContact.name || 'Your therapist'}: ${emergencyContact.phone}`\n    : 'Your therapist or healthcare provider';\n\n  // CRITICAL/EMERGENCY - Immediate danger or active planning\n  if (crisis.severity === 'critical' || crisis.recommendedAction === 'emergency') {\n    // Check if it's imminent danger category\n    const isImminent = crisis.categories?.includes('CRISIS_IMMINENT_DANGER') || \n                      crisis.categories?.includes('CRISIS_PLANNING_OR_METHOD');\n    \n    if (isImminent) {\n      return `üö® **IMMEDIATE SAFETY CONCERN**\\n\\n**Your safety is the most important thing right now.**\\n\\n**If you are in immediate danger or feel you might act on thoughts of ending your life, please contact emergency services (911 in the U.S.) or the 988 Suicide & Crisis Lifeline right now.**\\n\\n**This app cannot help in an emergency. If you are about to harm yourself or someone else, please call 911 or 988, or your local emergency number, immediately.**\\n\\n**Please also reach out to someone you trust right now**‚Äîa close friend, family member, or someone who can be with you or check in on you. You don't have to go through this alone.\\n\\n**Resources available right now:**\\n‚Ä¢ **988 Suicide & Crisis Lifeline** - Dial 988 (24/7, free, confidential)\\n‚Ä¢ **Crisis Text Line** - Text HOME to 741741\\n‚Ä¢ **Emergency Services** - 911 (U.S.) or your local emergency number\\n‚Ä¢ **Your Therapist**: ${therapistContact}\\n\\n**If you have started to carry out a plan to end your life, stop using this app and contact 911, 988, or your local crisis service for urgent help.**\\n\\n*Feeling suicidal is a medical and emotional emergency, not a personal failure. You deserve support, and help is available.*`;\n    }\n    \n    // Direct suicide ideation or planning\n    return `üö® **SAFETY CHECK**\\n\\n**It sounds like you may be thinking about ending your life or hurting yourself.**\\n\\n**Are you having thoughts of suicide right now?**\\n\\n**If you are thinking about suicide or have a plan, your safety is the priority. Please contact emergency services (911 in the U.S.) or the 988 Suicide & Crisis Lifeline right now.**\\n\\n**This app cannot help in an emergency. If you are about to harm yourself, please call 911 or 988, or your local emergency number, immediately.**\\n\\n**Please also reach out to someone you trust right now**‚Äîa close friend, family member, or someone who can be with you. You don't have to go through this alone.\\n\\n**Resources available right now:**\\n‚Ä¢ **988 Suicide & Crisis Lifeline** - Dial 988 (24/7, free, confidential)\\n‚Ä¢ **Crisis Text Line** - Text HOME to 741741\\n‚Ä¢ **Emergency Services** - 911 (U.S.) or your local emergency number\\n‚Ä¢ **Your Therapist**: ${therapistContact}\\n\\n*You are not alone in feeling this way, and it is OK to talk about suicide. Reaching out for help can make a difference. Many people have thoughts of suicide when pain feels overwhelming. Talking with a trained crisis counselor or mental health professional can help you stay safe.*`;\n  }\n\n  // HIGH - Self-harm, indirect ideation, or third-party concern\n  if (crisis.severity === 'high' || crisis.recommendedAction === 'contact_lcsw') {\n    const isSelfHarm = crisis.categories?.includes('CRISIS_SELF_HARM');\n    const isThirdParty = crisis.categories?.includes('CRISIS_THIRD_PARTY_SUICIDE_RISK');\n    \n    if (isSelfHarm) {\n      return `‚ö†Ô∏è **SUPPORT NEEDED**\\n\\n**Thank you for sharing this. It sounds like you may be hurting yourself or thinking about self-harm.**\\n\\n**What has helped you stay safe so far when you've had thoughts of suicide or self-harm?**\\n\\n**Your safety matters. Please reach out for help:**\\n\\n1. **Contact your therapist as soon as possible**: ${therapistContact}\\n2. **988 Suicide & Crisis Lifeline** - Dial 988 (24/7, free, confidential)\\n3. **Crisis Text Line** - Text HOME to 741741\\n4. **Reach out to someone you trust**‚Äîa close friend, family member, or someone who can support you right now\\n\\n**This app is not a crisis or emergency service and cannot keep you safe in an emergency. For urgent help, contact 988, 911, or your local crisis line.**\\n\\n**If you feel you might act on thoughts of self-harm, please contact a crisis line, emergency services, or your local equivalent immediately.**\\n\\n*Feeling suicidal is a medical and emotional emergency, not a personal failure. You deserve support, and help is available.*`;\n    }\n    \n    if (isThirdParty) {\n      return `‚ö†Ô∏è **CONCERN FOR SOMEONE ELSE**\\n\\n**It sounds like you're concerned about someone else who may be thinking about suicide or self-harm.**\\n\\n**If someone you know is in immediate danger, please contact emergency services (911) or a crisis line right away.**\\n\\n**Resources to help:**\\n‚Ä¢ **988 Suicide & Crisis Lifeline** - Dial 988 (24/7, free, confidential)\\n‚Ä¢ **Crisis Text Line** - Text HOME to 741741\\n‚Ä¢ **Emergency Services** - 911 (U.S.) or your local emergency number\\n‚Ä¢ **Your Therapist**: ${therapistContact}\\n\\n**You can also encourage the person to reach out to a trusted friend, family member, or mental health professional.**\\n\\n*This app is not a crisis or emergency service. For urgent situations, contact local emergency services or crisis lines.*`;\n    }\n    \n    // Indirect ideation or high risk\n    return `‚ö†Ô∏è **SUPPORT AVAILABLE**\\n\\n**It sounds like you're going through a very difficult time right now.**\\n\\n**Who in your life (family, friends, professionals) could you contact today to talk about how you're feeling?**\\n\\n**Please reach out for help:**\\n\\n1. **Contact your therapist as soon as possible**: ${therapistContact}\\n2. **988 Suicide & Crisis Lifeline** - Dial 988 (24/7, free, confidential)\\n3. **Crisis Text Line** - Text HOME to 741741\\n4. **Reach out to a trusted person**‚Äîa close friend, family member, or someone you trust‚Äîand let them know you need support right now\\n\\n**This app is not a crisis or emergency service and cannot keep you safe in an emergency. For urgent help, contact 988, 911, or your local crisis line.**\\n\\n**If you are thinking about suicide or self-harm, this app cannot keep you safe. Please call a crisis hotline or emergency services immediately.**\\n\\n*You are not alone in feeling this way. Reaching out for help can make a difference. Would you consider creating or updating a safety plan with a mental health professional or crisis counselor?*`;\n  }\n\n  // MODERATE - Hopelessness or behavioral red flags\n  return `**SUPPORT AVAILABLE**\\n\\n**It sounds like you're going through a difficult time. Thank you for sharing this.**\\n\\n**Please know that support is available:**\\n\\n1. **Discuss this with your therapist** in your next session: ${therapistContact}\\n2. **988 Suicide & Crisis Lifeline** - Dial 988 if you need to talk to someone (24/7, free, confidential)\\n3. **Crisis Text Line** - Text HOME to 741741\\n4. **Consider reaching out to a trusted person**‚Äîa friend, family member, or someone you trust‚Äîand sharing what you're experiencing\\n\\n**If you are thinking about suicide or self-harm, or feel you might act on harmful thoughts, please stop using the app and reach out to a trusted person or crisis service now.**\\n\\n**This app cannot help in emergencies. If you are in crisis or considering self-harm, call your local emergency number or a crisis hotline now.**\\n\\n*This app is not a substitute for professional therapy or crisis support. I can offer general information, but only trained people and local services can provide the immediate help you deserve when you feel suicidal.*`;\n}\n\n","/**\n * CLINICAL REPORT GENERATION\n * \n * Generates clinical reports in SOAP, DAP, and BIRP formats.\n * Synthesizes logs into structured formats for therapist review.\n */\n\nimport { LogEntry, ValueItem, MentalStateAssessment, LCSWConfig } from \"../types\";\nimport { initializeModels, getCounselingCoachModel, getIsModelLoading, getMoodTrackerModel } from \"./models\";\nimport { detectCrisis } from \"./crisis\";\n\n/**\n * Model A: Mental State Tracker\n * Analyzes journals and reflections to assess mood, anxiety, depression severity\n * Returns structured assessment similar to MoPHES framework\n */\nexport async function assessMentalState(\n  logs: LogEntry[],\n  currentReflection: string,\n  lcswConfig?: LCSWConfig\n): Promise<MentalStateAssessment> {\n  try {\n    // Check for crisis FIRST - before any processing\n    const crisisCheck = detectCrisis(currentReflection, lcswConfig);\n    if (crisisCheck.isCrisis && crisisCheck.severity === 'critical') {\n      // Return assessment that flags crisis - the UI should handle displaying crisis response\n      return {\n        anxietySeverity: 'high',\n        depressionSeverity: 'high',\n        keyThemes: ['CRISIS_DETECTED'],\n        recommendedActions: ['Contact emergency services (911) or crisis hotline (988) immediately'],\n        timestamp: new Date().toISOString()\n      };\n    }\n\n    // Ensure models are loaded - wait if they're currently loading\n    const moodTrackerModel = getMoodTrackerModel();\n    const isModelLoading = getIsModelLoading();\n    \n    if (!moodTrackerModel) {\n      // Start loading if not already loading\n      await initializeModels();\n    }\n\n    // Combine recent logs and current reflection for context\n    const recentLogs = logs.slice(0, 10).map(l => l.note).join(' ');\n    const combinedText = `${recentLogs} ${currentReflection}`.trim();\n\n    if (!combinedText) {\n      return {\n        anxietySeverity: 'low',\n        depressionSeverity: 'low',\n        keyThemes: [],\n        recommendedActions: [],\n        timestamp: new Date().toISOString()\n      };\n    }\n\n    // Use the mood tracker model to analyze sentiment and emotional state\n    // In a full implementation, this would use a fine-tuned mental health model\n    let result;\n    const currentMoodTrackerModel = getMoodTrackerModel();\n    if (currentMoodTrackerModel) {\n      try {\n        result = await currentMoodTrackerModel(combinedText);\n      } catch (error) {\n        console.warn('Mood tracker inference failed:', error);\n        result = null;\n      }\n    } else {\n      result = null;\n    }\n\n    // Extract themes using keyword analysis (in production, use a proper NER model)\n    const keyThemes: string[] = [];\n    const themeKeywords = {\n      'anxiety': ['worried', 'anxious', 'nervous', 'stressed', 'panic', 'fear'],\n      'depression': ['sad', 'depressed', 'hopeless', 'empty', 'tired', 'worthless'],\n      'anger': ['angry', 'frustrated', 'irritated', 'mad', 'rage'],\n      'gratitude': ['grateful', 'thankful', 'appreciate', 'blessed'],\n      'growth': ['learned', 'progress', 'improved', 'better', 'growing']\n    };\n\n    const lowerText = combinedText.toLowerCase();\n    for (const [theme, keywords] of Object.entries(themeKeywords)) {\n      if (keywords.some(kw => lowerText.includes(kw))) {\n        keyThemes.push(theme);\n      }\n    }\n\n    // Determine severity based on model output and keyword analysis\n    const hasAnxietyKeywords = keyThemes.includes('anxiety') || lowerText.includes('anxious');\n    const hasDepressionKeywords = keyThemes.includes('depression') || lowerText.includes('depressed');\n    \n    const anxietySeverity = hasAnxietyKeywords \n      ? (lowerText.match(/\\b(very|extremely|severely)\\b/gi) ? 'high' : 'moderate')\n      : 'low';\n    \n    const depressionSeverity = hasDepressionKeywords\n      ? (lowerText.match(/\\b(very|extremely|severely)\\b/gi) ? 'high' : 'moderate')\n      : 'low';\n\n    // Generate structured recommendations\n    const recommendedActions: string[] = [];\n    if (anxietySeverity !== 'low') {\n      recommendedActions.push('Practice deep breathing exercises');\n      recommendedActions.push('Consider discussing anxiety management strategies with your LCSW');\n    }\n    if (depressionSeverity !== 'low') {\n      recommendedActions.push('Engage in gentle physical activity');\n      recommendedActions.push('Reach out to your support network');\n    }\n    if (keyThemes.includes('growth')) {\n      recommendedActions.push('Acknowledge your progress and celebrate small wins');\n    }\n\n    return {\n      anxietySeverity: anxietySeverity as 'low' | 'moderate' | 'high',\n      depressionSeverity: depressionSeverity as 'low' | 'moderate' | 'high',\n      keyThemes: [...new Set(keyThemes)], // Remove duplicates\n      recommendedActions,\n      timestamp: new Date().toISOString()\n    };\n  } catch (error) {\n    console.error('Mental state assessment error:', error);\n    // Fallback to safe defaults\n    return {\n      anxietySeverity: 'low',\n      depressionSeverity: 'low',\n      keyThemes: [],\n      recommendedActions: ['Continue journaling and reflecting on your values'],\n      timestamp: new Date().toISOString()\n    };\n  }\n}\n\n/**\n * Fallback report generator (used when models aren't available)\n * Exported so UI components can use it directly when model loading fails\n */\nexport function generateFallbackReport(logs: LogEntry[], values: ValueItem[]): string {\n  const valueCounts: Record<string, number> = {};\n  const moodCounts: Record<string, number> = {};\n  \n  logs.forEach(log => {\n    const valueName = values.find(v => v.id === log.valueId)?.name || 'Unknown';\n    valueCounts[valueName] = (valueCounts[valueName] || 0) + 1;\n    if (log.mood) {\n      moodCounts[log.mood] = (moodCounts[log.mood] || 0) + 1;\n    }\n  });\n\n  const topValue = Object.entries(valueCounts).sort((a, b) => b[1] - a[1])[0]?.[0] || 'N/A';\n  const topMood = Object.entries(moodCounts).sort((a, b) => b[1] - a[1])[0]?.[0] || 'N/A';\n\n  return `# Clinical Summary\n\n## SOAP Format\n\n**Subjective**: Client has logged ${logs.length} reflection entries, with primary focus on ${topValue}. Most common mood indicator: ${topMood}.\n\n**Objective**: Patterns show engagement with value-based reflection practice. Entries span ${new Date(logs[logs.length - 1]?.date || Date.now()).toLocaleDateString()} to ${new Date(logs[0]?.date || Date.now()).toLocaleDateString()}.\n\n**Assessment**: Client is actively engaging in self-reflection and value alignment work.\n\n**Plan**: Continue value-based reflection. Review patterns with LCSW in next session.\n\n---\n\n## DAP Format\n\n**Data**: ${logs.length} entries, ${Object.keys(valueCounts).length} values engaged, mood tracking active.\n\n**Assessment**: Consistent engagement with reflection practice. Primary value focus: ${topValue}.\n\n**Plan**: Maintain current practice. Discuss themes and patterns with LCSW.\n\n---\n\n## BIRP Format\n\n**Behavior**: Client consistently logs reflections and tracks mood states.\n\n**Intervention**: Value-based reflection practice, self-monitoring.\n\n**Response**: Active engagement, ${logs.length} entries completed.\n\n**Plan**: Continue practice, review with LCSW.\n\n---\n\n*This is a basic summary. For detailed analysis, please review entries manually or discuss with your LCSW.*`;\n}\n\n/**\n * Generate clinical reports - synthesizes logs into structured formats\n */\nexport async function generateHumanReports(\n  logs: LogEntry[],\n  values: ValueItem[],\n  lcswConfig?: LCSWConfig\n): Promise<string> {\n  try {\n    if (logs.length === 0) {\n      return \"No logs available for synthesis.\";\n    }\n\n    // Check all logs for crisis indicators\n    const allText = logs.map(l => l.note).join(' ');\n    const crisisCheck = detectCrisis(allText, lcswConfig);\n    \n    if (crisisCheck.isCrisis && crisisCheck.severity === 'critical') {\n      const emergencyContact = lcswConfig?.emergencyContact;\n      const therapistContact = emergencyContact \n        ? `${emergencyContact.name || 'Your therapist'}: ${emergencyContact.phone}`\n        : 'Your therapist or healthcare provider';\n      \n      return `# üö® SAFETY CONCERN DETECTED IN LOGS\\n\\n**Your safety is the priority.** These logs contain language that suggests you may be thinking about ending your life or hurting yourself.\\n\\n**If you are in immediate danger or feel you might act on thoughts of suicide, please contact emergency services (911 in the U.S.) or the 988 Suicide & Crisis Lifeline right now.**\\n\\n**This app cannot help in an emergency. If you are about to harm yourself, please call 911 or 988, or your local emergency number, immediately.**\\n\\n**Please also reach out to someone you trust right now**‚Äîa close friend, family member, or someone who can be with you. You don't have to go through this alone.\\n\\n**Resources available right now:**\\n‚Ä¢ **988 Suicide & Crisis Lifeline** - Dial 988 (24/7, free, confidential)\\n‚Ä¢ **Crisis Text Line** - Text HOME to 741741\\n‚Ä¢ **Emergency Services** - 911 (U.S.) or your local emergency number\\n‚Ä¢ **Your Therapist**: ${therapistContact}\\n\\n---\\n\\n# Clinical Summary\\n\\nDue to safety concerns detected in these logs, a full clinical summary should be reviewed with your LCSW or mental health professional in person.\\n\\n*Feeling suicidal is a medical and emotional emergency, not a personal failure. You deserve support, and help is available.*`;\n    }\n\n    // Try to initialize models if not already loaded\n    const counselingCoachModel = getCounselingCoachModel();\n    if (!counselingCoachModel) {\n      const modelsLoaded = await initializeModels();\n      if (!modelsLoaded) {\n        // Model initialization failed - use rule-based fallback silently\n        const fallbackReport = generateFallbackReport(logs, values);\n        const disclaimer = `\\n\\n---\\n\\n*This report was generated using rule-based analysis. All processing happens on your device for privacy.*`;\n        return `${fallbackReport}${disclaimer}`;\n      }\n    }\n\n    const summary = logs.map(l => {\n      const vName = values.find(v => v.id === l.valueId)?.name || 'General';\n      return `[${l.date.split('T')[0]}] Value: ${vName}, Mood: ${l.mood || 'N/A'}, Note: ${l.note}`;\n    }).join('\\n');\n\n    const prompt = `You are a therapy integration assistant helping synthesize a client's reflection logs for review with their LCSW.\n\nGenerate a comprehensive report in SOAP, DAP, and BIRP formats.\n      \nLogs:\n      ${summary}\n      \nFormat your response with clear sections for each format. Keep the tone supportive, clinical yet human, and focused on patterns and themes that would be useful for therapy integration.`;\n\n    let report = generateFallbackReport(logs, values);\n    \n    // If model is available, try to generate AI report\n    let currentCounselingCoachModel = getCounselingCoachModel();\n    \n    // Ensure model is loaded\n    if (!currentCounselingCoachModel) {\n      const isModelLoading = getIsModelLoading();\n      if (isModelLoading) {\n        // Wait for current load (up to 30 seconds)\n        const maxWaitTime = 30000;\n        const startTime = Date.now();\n        while (!currentCounselingCoachModel && (Date.now() - startTime) < maxWaitTime) {\n          await new Promise(resolve => setTimeout(resolve, 500));\n          currentCounselingCoachModel = getCounselingCoachModel();\n        }\n      } else {\n        await initializeModels();\n        currentCounselingCoachModel = getCounselingCoachModel();\n      }\n    }\n    \n    if (currentCounselingCoachModel) {\n      try {\n        const result = await currentCounselingCoachModel(prompt, {\n          max_new_tokens: 1000,\n          temperature: 0.7,\n          do_sample: true\n        });\n\n        const generatedText = result[0]?.generated_text || '';\n        const extracted = generatedText.replace(prompt, '').trim();\n        if (extracted) {\n          report = extracted;\n        }\n      } catch (error) {\n        console.warn('Report generation inference failed:', error);\n        // Try reload if model type mismatch\n        if (error instanceof Error && (\n          error.message.includes('not a function') ||\n          error.message.includes('Cannot read')\n        )) {\n          await initializeModels(true);\n          const reloadedModel = getCounselingCoachModel();\n          if (reloadedModel) {\n            try {\n              const retryResult = await reloadedModel(prompt, {\n                max_new_tokens: 1000,\n                temperature: 0.7,\n                do_sample: true\n              });\n              const retryText = retryResult[0]?.generated_text || '';\n              const retryExtracted = retryText.replace(prompt, '').trim();\n              if (retryExtracted) {\n                report = retryExtracted;\n              }\n            } catch (retryError) {\n              console.warn('Retry report generation failed:', retryError);\n            }\n          }\n        }\n        // Use fallback report - inference failures are handled gracefully\n      }\n    }\n\n    // Add disclaimer\n    const disclaimer = `\\n\\n---\\n\\n*This report is generated on-device for your personal review and discussion with your LCSW. It is not a substitute for professional clinical assessment.*`;\n\n    return report + disclaimer;\n  } catch (error) {\n    // For any errors, log and return fallback report gracefully\n    console.error('Report generation error:', error);\n    const fallbackReport = generateFallbackReport(logs, values);\n    const disclaimer = `\\n\\n---\\n\\n*This report was generated using rule-based analysis. All processing happens on your device for privacy.*`;\n    return `${fallbackReport}${disclaimer}`;\n  }\n}\n\n","/**\n * ENCOURAGEMENT & GUIDANCE GENERATION\n * \n * Provides personalized encouragement, counseling guidance, and goal suggestions.\n * Supports therapy integration with value-based reflection and emotional support.\n */\n\nimport { ValueItem, GoalFrequency, LCSWConfig } from \"../types\";\nimport { initializeModels, getCounselingCoachModel, getIsModelLoading } from \"./models\";\nimport { detectCrisis, getCrisisResponse } from \"./crisis\";\n\n/**\n * Fallback guidance generator (used when models aren't available)\n */\nfunction generateFallbackGuidance(value: ValueItem, mood: string, reflection: string): string {\n  const moodContext = {\n    'üå±': 'growth and adaptation',\n    'üî•': 'momentum and action',\n    '‚ú®': 'alignment and flow',\n    'üßó': 'challenge and resilience'\n  }[mood] || 'your journey';\n\n  return `Your focus on ${value.name} during this time of ${moodContext} shows self-awareness. Consider how this reflection connects to what you've discussed with your LCSW. What small step can you take today that aligns with your treatment plan?`;\n}\n\n/**\n * Fallback reflection analysis using rule-based approach\n */\nfunction generateFallbackReflectionAnalysis(\n  reflection: string,\n  frequency: GoalFrequency,\n  lcswConfig?: LCSWConfig\n): string {\n  const lowerReflection = reflection.toLowerCase();\n  \n  // Detect themes\n  const themes: string[] = [];\n  if (lowerReflection.includes('anxious') || lowerReflection.includes('worried') || lowerReflection.includes('stress')) {\n    themes.push('Anxiety/Stress');\n  }\n  if (lowerReflection.includes('sad') || lowerReflection.includes('down') || lowerReflection.includes('depressed')) {\n    themes.push('Mood/Low Energy');\n  }\n  if (lowerReflection.includes('work') || lowerReflection.includes('job') || lowerReflection.includes('colleague')) {\n    themes.push('Work Environment');\n  }\n  if (lowerReflection.includes('family') || lowerReflection.includes('relationship') || lowerReflection.includes('friend')) {\n    themes.push('Interpersonal Relationships');\n  }\n  if (lowerReflection.includes('sleep') || lowerReflection.includes('tired') || lowerReflection.includes('exhausted')) {\n    themes.push('Physical Well-being');\n  }\n  if (themes.length === 0) {\n    themes.push('Self-Reflection', 'Personal Growth');\n  }\n\n  // Environment connections\n  let environmentNote = '';\n  if (lowerReflection.includes('work') || lowerReflection.includes('office')) {\n    environmentNote = 'Your work environment appears to be influencing your mental state. Notice how your physical space and work relationships impact your internal experience.';\n  } else if (lowerReflection.includes('home') || lowerReflection.includes('house')) {\n    environmentNote = 'Your home environment seems significant in this reflection. Consider how your physical space and home relationships affect your well-being.';\n  } else {\n    environmentNote = 'Consider how your environment‚Äîwhether work, home, or social spaces‚Äîconnects to what you\\'re experiencing internally.';\n  }\n\n  // Generate questions\n  const questions = [\n    `What specific coping mechanism did you use (or could you use) in response to what you observed?`,\n    `How might advocating for yourself in this situation look different than what you've done before?`\n  ];\n\n  // Session prep\n  const frequencyLabel = frequency === 'quarterly' ? 'monthly' : frequency;\n  const sessionPrep = themes.length > 0 \n    ? `Bring the theme of \"${themes[0]}\" to your next session. Consider discussing how your environment and coping strategies are working (or not working) for you right now.`\n    : `Focus on discussing your reflection about ${frequencyLabel} patterns with your therapist. Consider what you want to explore more deeply.`;\n\n  return `## Core Themes\n${themes.slice(0, 3).map(t => `- ${t}`).join('\\n')}\n\n## The 'LCSW Lens'\n${environmentNote}\n\n## Reflective Inquiry\n${questions.map((q, i) => `${i + 1}. ${q}`).join('\\n')}\n\n## Session Prep\n${sessionPrep}`;\n}\n\n/**\n * Analyze reflection with LCSW-focused lens\n * Provides: Core Themes, LCSW Lens, Reflective Inquiry, Session Prep\n */\nexport async function analyzeReflection(\n  reflection: string,\n  frequency: GoalFrequency,\n  lcswConfig?: LCSWConfig\n): Promise<string> {\n  try {\n    // Check for crisis first\n    const crisisCheck = detectCrisis(reflection, lcswConfig);\n    if (crisisCheck.isCrisis) {\n      return getCrisisResponse(crisisCheck, lcswConfig);\n    }\n\n    if (!reflection.trim()) {\n      return 'Please enter your reflection to receive analysis.';\n    }\n\n    const protocols = lcswConfig?.protocols || [];\n    const protocolContext = protocols.length > 0 \n      ? `The user is working with an LCSW using ${protocols.join(', ')} protocols.`\n      : 'The user is working with a licensed clinical social worker.';\n\n    const frequencyLabel = frequency === 'quarterly' ? 'monthly' : frequency;\n    const prompt = `I am providing a deep reflection of my ${frequencyLabel} below under the heading [Observation].\n\nActing as a supportive and insightful reflective partner, please analyze my notes and provide the following:\n\n**Core Themes**: Identify 2‚Äì3 recurring emotional or situational themes you notice in my reflection.\n\n**The 'LCSW Lens'**: Note any connections between my environment (work, relationships, physical space) and my internal mental state. Focus on social work pillars: environment, coping mechanisms, and self-advocacy.\n\n**Reflective Inquiry**: Ask me 2 'growth-oriented' questions that challenge me to look deeper into a specific part of my observation.\n\n**Session Prep**: Summarize one key takeaway or 'priority topic' I should consider bringing to my next therapy session to ensure I'm making the most of my time.\n\n${protocolContext}\n\n[Observation]\n${reflection}\n\nFormat your response clearly with these four sections. Be supportive, insightful, and focused on helping me prepare for meaningful work in my next therapy session.`;\n\n    // Use rule-based analysis since text-generation models are disabled\n    return generateFallbackReflectionAnalysis(reflection, frequency, lcswConfig);\n  } catch (error) {\n    console.error('Reflection analysis error:', error);\n    return generateFallbackReflectionAnalysis(reflection, frequency, lcswConfig);\n  }\n}\n\n/**\n * Model B: Counseling Coach\n * Provides structured guidance, homework reminders, and psychoeducation\n * Aligned with LCSW treatment plans, not replacing them\n */\nexport async function generateCounselingGuidance(\n  value: ValueItem,\n  mood: string,\n  reflection: string,\n  lcswConfig?: LCSWConfig\n): Promise<string> {\n  try {\n    // Check for crisis first\n    const crisisCheck = detectCrisis(reflection, lcswConfig);\n    if (crisisCheck.isCrisis) {\n      return getCrisisResponse(crisisCheck, lcswConfig);\n    }\n\n    // Ensure models are loaded - wait if they're currently loading\n    let counselingCoachModel = getCounselingCoachModel();\n    const isModelLoading = getIsModelLoading();\n    \n    if (!counselingCoachModel) {\n      if (isModelLoading) {\n        // Wait for current load to complete (up to 30 seconds)\n        const maxWaitTime = 30000;\n        const startTime = Date.now();\n        while (!counselingCoachModel && (Date.now() - startTime) < maxWaitTime) {\n          await new Promise(resolve => setTimeout(resolve, 500));\n          counselingCoachModel = getCounselingCoachModel();\n        }\n      } else {\n        // Start loading if not already loading\n        await initializeModels();\n        counselingCoachModel = getCounselingCoachModel();\n      }\n    }\n\n    // Build prompt aligned with LCSW integration role\n    const protocols = lcswConfig?.protocols || [];\n    const protocolContext = protocols.length > 0 \n      ? `The user is working with an LCSW using ${protocols.join(', ')} protocols.`\n      : 'The user is working with a licensed clinical social worker.';\n\n    const prompt = `You are a supportive therapy integration assistant helping a client between sessions with their LCSW.\n\n${protocolContext}\n\nYour role is to:\n- Help the client remember and practice what was discussed in therapy\n- Provide structured reflection prompts aligned with their treatment plan\n- Offer psychoeducation and coping skills (NOT diagnoses or crisis handling)\n- Support value-based living and goal achievement\n\nThe client is focusing on the value: \"${value.name}\" (${value.description}).\nTheir current mood indicator: ${mood}\nTheir reflection: \"${reflection}\"\n\nProvide a brief, warm, and structured response (2-3 sentences) that:\n1. Validates their experience\n2. Connects to their value\n3. Suggests a small, actionable step they can take before their next session\n\nRemember: You are supporting therapy integration, not providing therapy. Keep responses educational and supportive.`;\n\n    // Generate response using the counseling coach model\n    let response = \"Your commitment to reflecting on your values is a meaningful step in your journey.\";\n    \n    if (counselingCoachModel) {\n      try {\n        const result = await counselingCoachModel(prompt, {\n          max_new_tokens: 150,\n          temperature: 0.7,\n          do_sample: true,\n          top_p: 0.9\n        });\n\n        const generatedText = result[0]?.generated_text || '';\n        // Extract just the assistant's response (remove the prompt)\n        const extracted = generatedText.replace(prompt, '').trim();\n        if (extracted) {\n          response = extracted;\n        }\n      } catch (error) {\n        console.warn('Counseling coach inference failed:', error);\n        // If error suggests model type mismatch, try to reload\n        if (error instanceof Error && (\n          error.message.includes('not a function') ||\n          error.message.includes('Cannot read') ||\n          error.message.includes('is not a function')\n        )) {\n          console.warn('Possible model type mismatch, attempting reload...');\n          await initializeModels(true); // Force reload\n          const reloadedModel = getCounselingCoachModel();\n          if (reloadedModel) {\n            try {\n              const retryResult = await reloadedModel(prompt, {\n                max_new_tokens: 150,\n                temperature: 0.7,\n                do_sample: true,\n                top_p: 0.9\n              });\n              const retryText = retryResult[0]?.generated_text || '';\n              const retryExtracted = retryText.replace(prompt, '').trim();\n              if (retryExtracted) {\n                response = retryExtracted;\n              }\n            } catch (retryError) {\n              console.warn('Retry inference failed:', retryError);\n            }\n          }\n        }\n        // Use fallback response if all attempts fail\n      }\n    }\n    \n    // Fallback: Generate rule-based response if model unavailable\n    if (response === \"Your commitment to reflecting on your values is a meaningful step in your journey.\") {\n      response = generateFallbackGuidance(value, mood, reflection);\n    }\n    \n    return response;\n  } catch (error) {\n    console.error('Counseling guidance error:', error);\n    // Fallback response\n    return `Your focus on ${value.name} shows self-awareness. Consider discussing this reflection with your therapist in your next session.`;\n  }\n}\n\n/**\n * Generate encouragement - uses counseling coach with specific prompt\n */\nexport async function generateEncouragement(\n  value: ValueItem,\n  mood: string = '‚ú®',\n  lcswConfig?: LCSWConfig\n): Promise<string> {\n  return generateCounselingGuidance(value, mood, '', lcswConfig);\n}\n\n/**\n * Generate encouragement based on emotional state\n * Provides personalized support and opportunities based on how the user is feeling\n */\nexport async function generateEmotionalEncouragement(\n  emotionalState: 'drained' | 'heavy' | 'overwhelmed' | 'mixed' | 'calm' | 'hopeful' | 'positive' | 'energized',\n  selectedFeeling: string | null,\n  lowStateCount: number,\n  lcswConfig?: LCSWConfig,\n  context?: {\n    recentJournalText?: string;\n    timeOfDay?: 'morning' | 'afternoon' | 'evening' | 'night';\n    userPatterns?: { frequentStates: string[], progress: number };\n  }\n): Promise<string> {\n  // Import emotional states configuration\n  const { getEmotionalState } = await import('../emotionalStates');\n  const stateConfig = getEmotionalState(emotionalState);\n  \n  if (!stateConfig) {\n    // Fallback if state not found\n    return \"You're doing important work. Keep going, one step at a time.\";\n  }\n\n  const protocols = lcswConfig?.protocols || [];\n  const protocolContext = protocols.length > 0 \n    ? `The user is working with an LCSW using ${protocols.join(', ')} protocols.`\n    : 'The user is working with a licensed clinical social worker.';\n\n  const feelingContext = selectedFeeling ? ` They're specifically feeling ${selectedFeeling}.` : '';\n  \n  // Build time-of-day context\n  const timeContext = context?.timeOfDay \n    ? context.timeOfDay === 'morning' \n      ? ' It is morning‚Äîa time for fresh starts and forward momentum.'\n      : context.timeOfDay === 'evening' || context.timeOfDay === 'night'\n      ? ' It is evening/night‚Äîa time for reflection and rest.'\n      : ' It is afternoon‚Äîa time for continued engagement.'\n    : '';\n\n  // Build journal context\n  const journalContext = context?.recentJournalText \n    ? ` Recent reflection: \"${context.recentJournalText.substring(0, 200)}\"`\n    : '';\n\n  // Build pattern context\n  const patternContext = context?.userPatterns && context.userPatterns.frequentStates.length > 0\n    ? ` The user has been feeling ${context.userPatterns.frequentStates.join(', ')} frequently.`\n    : '';\n\n  // Low states tracking (drained, heavy, overwhelmed)\n  const isLowState = emotionalState === 'drained' || emotionalState === 'heavy' || emotionalState === 'overwhelmed';\n  const isRepeated = isLowState && lowStateCount >= 3;\n  const connectionPrompt = isRepeated \n    ? ' Strongly encourage them to reach out to a trusted person, their therapist, or a support line (988). Emphasize that they don\\'t have to go through this alone.'\n    : isLowState\n    ? ' Gently suggest that connecting with someone they trust might be helpful.'\n    : '';\n\n  // Use encouragement instruction from state config\n  const baseInstruction = stateConfig.encouragementPrompt.instruction;\n  \n  // Build dynamic prompt\n  const prompt = `You are a supportive therapy integration assistant.${timeContext}${journalContext}${patternContext}\n\nThe user is feeling ${stateConfig.label.toLowerCase()}.${feelingContext}\n\n${protocolContext}\n\n${baseInstruction}${connectionPrompt}\n\nProvide warm, compassionate encouragement (30-60 words, 2-3 sentences) that:\n1. Acknowledges what they're experiencing\n2. Helps them see possibilities and opportunities ahead\n3. Offers gentle support and next steps${isRepeated ? '\\n4. Strongly encourages reaching out to someone for support' : ''}\n\nBe genuine, hopeful, and supportive. Avoid platitudes or toxic positivity.`;\n\n  // Build fallback response based on state\n  let fallbackResponse = '';\n  \n  if (emotionalState === 'drained') {\n    fallbackResponse = `Feeling drained is real and valid. Right now might feel heavy, but there are opportunities ahead. Consider reaching out to someone you trust‚Äîyou don't have to carry this alone. Small steps forward are still progress.${isRepeated ? ' Please consider reaching out to your therapist, a trusted friend, or the 988 Crisis & Suicide Lifeline. You deserve support.' : ''}`;\n  } else if (emotionalState === 'heavy') {\n    fallbackResponse = `Feeling heavy is understandable. These moments can feel overwhelming, but they also show your capacity to feel deeply. There are possibilities and opportunities waiting for you.${isRepeated ? ' Please consider reaching out to your therapist, a trusted friend, or a support line (988). You deserve support.' : ' Consider connecting with someone who cares about you.'}`;\n  } else if (emotionalState === 'overwhelmed') {\n    fallbackResponse = `Feeling overwhelmed is completely understandable when there's so much happening. Take a moment to breathe. You can break things down into smaller, manageable steps. There are opportunities ahead, and you have the capacity to navigate them.${isRepeated ? ' Consider reaching out to someone you trust for support.' : ''}`;\n  } else if (emotionalState === 'mixed') {\n    fallbackResponse = `Mixed feelings are completely normal and valid. This in-between space can actually be a place of growth and possibility. There are opportunities ahead, and you have the capacity to navigate them. Consider what feels most authentic to you right now.`;\n  } else if (emotionalState === 'calm') {\n    fallbackResponse = `It's wonderful that you're feeling calm and centered. This peaceful state is a gift‚Äîtake time to appreciate it and notice what brought you here. There are opportunities to build on this sense of stability.`;\n  } else if (emotionalState === 'hopeful') {\n    fallbackResponse = `Feeling hopeful is a sign of resilience and possibility. This forward-looking energy is valuable‚Äîthere are opportunities ahead that align with your values and goals. How can you channel this hope into meaningful action?`;\n  } else if (emotionalState === 'positive') {\n    fallbackResponse = `It's wonderful that you're feeling positive and grounded. This is a great time to explore opportunities and possibilities. Consider what you'd like to build on or move toward. You have momentum‚Äîhow can you channel this energy in meaningful ways?`;\n  } else { // energized\n    fallbackResponse = `You're feeling energized and motivated‚Äîthat's powerful! This is a great time to explore opportunities and take meaningful action. What possibilities are calling to you? How can you channel this energy toward what matters most to you?`;\n  }\n\n  // Try to use AI model if available\n  let counselingCoachModel = getCounselingCoachModel();\n  \n  // If model not available, try to initialize it (with timeout)\n  if (!counselingCoachModel) {\n    const isModelLoading = getIsModelLoading();\n    if (!isModelLoading) {\n      // Try to initialize models with a timeout\n      try {\n        const initPromise = initializeModels();\n        const timeoutPromise = new Promise<boolean>((_, reject) => \n          setTimeout(() => reject(new Error('Model initialization timeout')), 10000)\n        );\n        await Promise.race([initPromise, timeoutPromise]);\n        counselingCoachModel = getCounselingCoachModel();\n      } catch (error) {\n        console.warn('Model initialization failed or timed out, using rule-based encouragement');\n        // Don't wait - just use rule-based\n      }\n    } else {\n      // Wait for current load to complete, but with shorter timeout\n      // Wait up to 5 seconds for model to load (not 30)\n      const maxWaitTime = 5000;\n      const startTime = Date.now();\n      while (!counselingCoachModel && (Date.now() - startTime) < maxWaitTime) {\n        await new Promise(resolve => setTimeout(resolve, 500));\n        counselingCoachModel = getCounselingCoachModel();\n        // Check if loading failed\n        if (!getIsModelLoading() && !counselingCoachModel) {\n          // Loading completed but no model - break early\n          break;\n        }\n      }\n    }\n  }\n  \n  if (counselingCoachModel) {\n    try {\n      const result = await counselingCoachModel(prompt, {\n        max_new_tokens: 200,\n        temperature: 0.8,\n        do_sample: true,\n        top_p: 0.9\n      });\n\n      const generatedText = result[0]?.generated_text || '';\n      const extracted = generatedText.replace(prompt, '').trim();\n      if (extracted && extracted.length > 20) {\n        return extracted;\n      }\n    } catch (error) {\n      console.warn('Emotional encouragement inference failed:', error);\n      // If inference fails, check if it's because model is wrong type\n      // and try to reload with correct model type\n      if (error instanceof Error && (\n        error.message.includes('not a function') ||\n        error.message.includes('Cannot read') ||\n        error.message.includes('is not a function')\n      )) {\n        console.warn('Model type mismatch detected, attempting to reload...');\n        await initializeModels(true); // Force reload\n        const reloadedModel = getCounselingCoachModel();\n        if (reloadedModel) {\n          try {\n            const retryResult = await reloadedModel(prompt, {\n              max_new_tokens: 200,\n              temperature: 0.8,\n              do_sample: true,\n              top_p: 0.9\n            });\n            const retryText = retryResult[0]?.generated_text || '';\n            const retryExtracted = retryText.replace(prompt, '').trim();\n            if (retryExtracted && retryExtracted.length > 20) {\n              return retryExtracted;\n            }\n          } catch (retryError) {\n            console.warn('Retry inference also failed:', retryError);\n          }\n        }\n      }\n    }\n  }\n\n  // Return fallback response\n  return fallbackResponse;\n}\n\n/**\n * Generate value mantra - short, memorable phrase\n */\nexport async function generateValueMantra(value: ValueItem): Promise<string> {\n  // Simple rule-based mantras for on-device use\n  const mantras: Record<string, string> = {\n    'Integrity': 'Truth guides me',\n    'Family': 'Love connects us',\n    'Creativity': 'Ideas flow freely',\n    'Health': 'Body and mind unite',\n    'Freedom': 'I choose my path',\n    'Justice': 'Fairness for all',\n    'Kindness': 'Compassion in action',\n    'Learning': 'Growth through curiosity',\n    'Nature': 'Earth sustains me',\n    'Peace': 'Calm within',\n    'Respect': 'Dignity for all',\n    'Service': 'Help others rise',\n    'Spirituality': 'Connection beyond self',\n    'Success': 'Progress over perfection',\n    'Wealth': 'Abundance flows',\n    'Wisdom': 'Insight guides',\n    'Authenticity': 'Be true to self',\n    'Compassion': 'Kindness in action',\n    'Humor': 'Joy lightens the load',\n    'Leadership': 'Guide with heart',\n    'Resilience': 'Bounce back stronger',\n    'Responsibility': 'Own my choices',\n    'Courage': 'Face fears bravely',\n    'Humility': 'Learn from all',\n    'Loyalty': 'Stand by others',\n    'Community': 'Together we thrive',\n    'Artistry': 'Create with soul',\n    'Curiosity': 'Wonder opens doors',\n    'Balance': 'Harmony in motion',\n    'Sustainability': 'Care for tomorrow',\n    'Open-Mindedness': 'Embrace new views',\n    'Impact': 'Make a difference',\n    'Adventure': 'Explore boldly'\n  };\n\n  return mantras[value.name] || `Honor ${value.name} today`;\n}\n\n/**\n * Suggest goal - structured, achievable micro-action\n */\nexport async function suggestGoal(\n  value: ValueItem,\n  frequency: GoalFrequency,\n  reflection: string = '',\n  lcswConfig?: LCSWConfig\n): Promise<string> {\n  try {\n    // Check for crisis\n    const crisisCheck = detectCrisis(reflection, lcswConfig);\n    if (crisisCheck.isCrisis) {\n      return `### Safety First\\n- **Description**: Contact your therapist or emergency services if you're in crisis\\n- **What this helps with**: Immediate support and safety\\n- **How do I measure progress**:\\n  1. Reached out to a professional\\n  2. Followed your safety plan\\n  3. Engaged with your support network`;\n    }\n\n    let counselingCoachModel = getCounselingCoachModel();\n    if (!counselingCoachModel) {\n      const isModelLoading = getIsModelLoading();\n      if (isModelLoading) {\n        // Wait for current load (up to 30 seconds)\n        const maxWaitTime = 30000;\n        const startTime = Date.now();\n        while (!counselingCoachModel && (Date.now() - startTime) < maxWaitTime) {\n          await new Promise(resolve => setTimeout(resolve, 500));\n          counselingCoachModel = getCounselingCoachModel();\n        }\n      } else {\n        await initializeModels();\n        counselingCoachModel = getCounselingCoachModel();\n      }\n    }\n\n    // Check if reflection contains deep reflection and/or analysis\n    const hasDeepReflection = reflection.includes('Deep Reflection:') || reflection.trim().length > 50;\n    const hasAnalysis = reflection.includes('## Core Themes') || reflection.includes('## The \\'LCSW Lens\\'') || reflection.includes('Reflection Analysis:');\n    \n    const prompt = (hasDeepReflection || hasAnalysis)\n      ? `Based on the following deep reflection and analysis, suggest a specific, achievable \"commit to do\" next step that helps the user see they have options and different approaches to their growth and success.\n\nThe user is focusing on the value: \"${value.name}\" (${value.description})\nFrequency: ${frequency}\n\n${reflection}\n\nActing as a supportive and insightful reflective partner, generate a \"commit to do\" next guidance that:\n1. Directly addresses the specific themes, insights, and observations from their DEEP REFLECTION\n2. Shows them they have OPTIONS and different approaches (not just one path forward)\n3. Connects to their value: ${value.name}\n4. Is actionable and achievable within the ${frequency} timeframe\n5. Supports their therapy work and personal growth\n\nThe goal is to help them see multiple pathways and approaches, not just one solution. Show them options.\n\nFormat the response as:\n### Structured Aim\n- **Description**: [One specific action they can commit to do - show them this is ONE option among many]\n- **What this helps with**: [Brief benefit related to their value and the reflection themes - emphasize this is one approach]\n- **How do I measure progress**:\n  1. [First milestone]\n  2. [Second milestone]\n  3. [Third milestone]\n\nKeep it small, specific, and aligned with the insights from their deep reflection. Help them see they have choices.`\n      : `Suggest a specific, achievable micro-goal for someone focusing on the value \"${value.name}\" (${value.description}).\n\nFrequency: ${frequency}\nRecent reflection: \"${reflection}\"\n\nFormat the response as:\n### Structured Aim\n- **Description**: [One specific action they can take]\n- **What this helps with**: [Brief benefit related to their value]\n- **How do I measure progress**:\n  1. [First milestone]\n  2. [Second milestone]\n  3. [Third milestone]\n\nKeep it small, specific, and aligned with therapy integration.`;\n\n    let response = `### Structured Aim\\n- **Description**: Take one small action today that aligns with ${value.name}\\n- **What this helps with**: Building consistency and self-efficacy\\n- **How do I measure progress**:\\n  1. Identified the action\\n  2. Completed the action\\n  3. Reflected on the experience`;\n    \n    if (counselingCoachModel) {\n      try {\n        const result = await counselingCoachModel(prompt, {\n          max_new_tokens: 200,\n          temperature: 0.8,\n          do_sample: true\n        });\n\n        const generatedText = result[0]?.generated_text || '';\n        const extracted = generatedText.replace(prompt, '').trim();\n        if (extracted) {\n          response = extracted;\n        }\n      } catch (error) {\n        console.warn('Goal suggestion inference failed:', error);\n        // Try reload if model type mismatch\n        if (error instanceof Error && (\n          error.message.includes('not a function') ||\n          error.message.includes('Cannot read')\n        )) {\n          await initializeModels(true);\n          const reloadedModel = getCounselingCoachModel();\n          if (reloadedModel) {\n            try {\n              const retryResult = await reloadedModel(prompt, {\n                max_new_tokens: 200,\n                temperature: 0.8,\n                do_sample: true\n              });\n              const retryText = retryResult[0]?.generated_text || '';\n              const retryExtracted = retryText.replace(prompt, '').trim();\n              if (retryExtracted) {\n                response = retryExtracted;\n              }\n            } catch (retryError) {\n              console.warn('Retry goal suggestion failed:', retryError);\n            }\n          }\n        }\n      }\n    }\n    \n    return response;\n  } catch (error) {\n    console.error('Goal suggestion error:', error);\n    return `### Structured Aim\\n- **Description**: Practice ${value.name} in one specific way today\\n- **What this helps with**: Building value-aligned habits\\n- **How do I measure progress**:\\n  1. Planned the action\\n  2. Took the action\\n  3. Noted the outcome`;\n  }\n}\n\n"],"file":"assets/ai-services-Dyqhbvbu.js"}