var px=Object.defineProperty;var Nb=(o,t,e)=>t in o?px(o,t,{enumerable:!0,configurable:!0,writable:!0,value:e}):o[t]=e;var a=(o,t)=>px(o,"name",{value:t,configurable:!0});var E=(o,t,e)=>Nb(o,typeof t!="symbol"?t+"":t,e);import{v as Ib,O as Ob,T as zb}from"./vendor-CFU3Mex3.js";const J={},Sb=Object.freeze(Object.defineProperty({__proto__:null,default:J},Symbol.toStringTag,{value:"Module"}));typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});function Ft(o,t){o&&o(t)}a(Ft,"dispatchCallback");function jb(o){return Object.fromEntries(Object.entries(o).map(([t,e])=>[e,t]))}a(jb,"reverseDictionary");function Ix(o){return o.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}a(Ix,"escapeRegExp");var te;const lt=(te=class{constructor(){let t=a(function(...e){return t._call(...e)},"closure");return Object.setPrototypeOf(t,new.target.prototype)}_call(...t){throw Error("Must implement _call method in subclass")}},a(te,"Callable"),te);function $b(o){return o?.prototype?.__proto__?.constructor?.name==="TypedArray"}a($b,"isTypedArray");function Ox(o){return Number.isInteger(o)||typeof o=="bigint"}a(Ox,"isIntegralNumber");function Rb(o){return o!=null}a(Rb,"exists");function mx(o){const t=[];let e=o;for(;Array.isArray(e);)t.push(e.length),e=e[0];return t}a(mx,"calculateDimensions");function gx(o,t,e=void 0){const s=o[t];if(s!==void 0)return delete o[t],s;if(e===void 0)throw Error(`Key ${t} does not exist in object.`);return e}a(gx,"pop");function et(...o){return Array.prototype.concat.apply([],o)}a(et,"mergeArrays");function Ub(...o){return o.reduce((t,e)=>t.flatMap(s=>e.map(n=>[s,n])))}a(Ub,"product");function Ys(o,t){return Math.abs((o+t)%(2*t)-t)}a(Ys,"calculateReflectOffset");let _t;const Ws=["wasm"];typeof process<"u"&&process?.release?.name==="node"?(_t=J??Sb,Ws.unshift("cpu")):(_t=Ib??Ob,typeof navigator<"u"&&/iP(hone|od|ad).+16_4.+AppleWebKit/.test(navigator.userAgent)&&(_t.env.wasm.simd=!1));const{env:ph}=typeof _t<"u"&&_t?_t:{env:{}},zx="2.17.2",Db=typeof self<"u"&&"caches"in self,mh=!Sx(J),Lb=!Sx(J),rh=mh&&Lb,oh=rh?J.dirname(J.dirname(J.fileURLToPath(import.meta.url))):"./",Gb=rh?J.join(oh,"/.cache/"):null,wx="/models/",qb=rh?J.join(oh,wx):wx;ph?.wasm&&(ph.wasm.wasmPaths=rh?J.join(oh,"/dist/"):`https://cdn.jsdelivr.net/npm/@xenova/transformers@${zx}/dist/`);const Q={backends:{onnx:ph,tfjs:{}},__dirname:oh,version:zx,allowRemoteModels:!0,remoteHost:"https://huggingface.co/",remotePathTemplate:"{model}/resolve/{revision}/",allowLocalModels:!0,localModelPath:qb,useFS:mh,useBrowserCache:Db,useFSCache:mh,cacheDir:Gb,useCustomCache:!1,customCache:null};function Sx(o){return Object.keys(o).length===0}a(Sx,"isEmpty");typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});var uh={};const jc=class jc{constructor(t){E(this,"_CONTENT_TYPE_MAP",{txt:"text/plain",html:"text/html",css:"text/css",js:"text/javascript",json:"application/json",png:"image/png",jpg:"image/jpeg",jpeg:"image/jpeg",gif:"image/gif"});if(this.filePath=t,this.headers=new Headers,this.exists=J.existsSync(t),this.exists){this.status=200,this.statusText="OK";let e=J.statSync(t);this.headers.set("content-length",e.size.toString()),this.updateContentType();let s=this;this.body=new ReadableStream({start(n){s.arrayBuffer().then(i=>{n.enqueue(new Uint8Array(i)),n.close()})}})}else this.status=404,this.statusText="Not Found",this.body=null}updateContentType(){const t=this.filePath.toString().split(".").pop().toLowerCase();this.headers.set("content-type",this._CONTENT_TYPE_MAP[t]??"application/octet-stream")}clone(){let t=new jc(this.filePath);return t.exists=this.exists,t.status=this.status,t.statusText=this.statusText,t.headers=new Headers(this.headers),t}async arrayBuffer(){return(await J.promises.readFile(this.filePath)).buffer}async blob(){const t=await J.promises.readFile(this.filePath);return new Blob([t],{type:this.headers.get("content-type")})}async text(){return await J.promises.readFile(this.filePath,"utf8")}async json(){return JSON.parse(await this.text())}};a(jc,"FileResponse");let Js=jc;function gh(o,t=null,e=null){let s;try{s=new URL(o)}catch{return!1}return!(t&&!t.includes(s.protocol)||e&&!e.includes(s.hostname))}a(gh,"isValidUrl");async function Zs(o){if(Q.useFS&&!gh(o,["http:","https:","blob:"]))return new Js(o);if(typeof process<"u"&&process?.release?.name==="node"){const t=!!uh?.TESTING_REMOTELY,e=Q.version,s=new Headers;if(s.set("User-Agent",`transformers.js/${e}; is_ci/${t};`),gh(o,["http:","https:"],["huggingface.co","hf.co"])){const i=uh?.HF_TOKEN??uh?.HF_ACCESS_TOKEN;i&&s.set("Authorization",`Bearer ${i}`)}return fetch(o,{headers:s})}else return fetch(o)}a(Zs,"getFile");const Bb={400:"Bad request error occurred while trying to load file",401:"Unauthorized access to file",403:"Forbidden access to file",404:"Could not locate file",408:"Request timeout error occurred while trying to load file",500:"Internal server error error occurred while trying to load file",502:"Bad gateway error occurred while trying to load file",503:"Service unavailable error occurred while trying to load file",504:"Gateway timeout error occurred while trying to load file"};function Hb(o,t,e){if(!e)return null;const s=Bb[o]??`Error (${o}) occurred while trying to load file`;throw Error(`${s}: "${t}".`)}a(Hb,"handleError");const Wd=class Wd{constructor(t){this.path=t}async match(t){let e=J.join(this.path,t),s=new Js(e);if(s.exists)return s}async put(t,e){const s=Buffer.from(await e.arrayBuffer());let n=J.join(this.path,t);try{await J.promises.mkdir(J.dirname(n),{recursive:!0}),await J.promises.writeFile(n,s)}catch(i){console.warn("An error occurred while writing the file to cache:",i)}}};a(Wd,"FileCache");let Qs=Wd;async function Xb(o,...t){for(let e of t)try{let s=await o.match(e);if(s)return s}catch{continue}}a(Xb,"tryCache");async function jx(o,t,e=!0,s={}){if(!Q.allowLocalModels){if(s.local_files_only)throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");if(!Q.allowRemoteModels)throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.")}Ft(s.progress_callback,{status:"initiate",name:o,file:t});let n;if(!n&&Q.useBrowserCache){if(typeof caches>"u")throw Error("Browser cache is not available in this environment.");try{n=await caches.open("transformers-cache")}catch(w){console.warn("An error occurred while opening the browser cache:",w)}}if(!n&&Q.useFSCache&&(n=new Qs(s.cache_dir??Q.cacheDir)),!n&&Q.useCustomCache){if(!Q.customCache)throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");if(!Q.customCache.match||!Q.customCache.put)throw new Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache");n=Q.customCache}const i=s.revision??"main";let r=Xs(o,t),l=Xs(Q.localModelPath,r),c=Xs(Q.remoteHost,Q.remotePathTemplate.replaceAll("{model}",o).replaceAll("{revision}",encodeURIComponent(i)),t),h=i==="main"?r:Xs(o,i,t),d,u=n instanceof Qs?h:c,f=!1,_;n&&(_=await Xb(n,l,u));const p=_!==void 0;if(_===void 0){if(Q.allowLocalModels)if(gh(r,["http:","https:"])){if(s.local_files_only)throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${r}.`);if(!Q.allowRemoteModels)throw new Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${r}.`)}else try{_=await Zs(l),d=l}catch(y){console.warn(`Unable to load from local path "${l}": "${y}"`)}if(_===void 0||_.status===404){if(s.local_files_only||!Q.allowRemoteModels){if(e)throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${l}".`);return null}if(_=await Zs(c),_.status!==200)return Hb(_.status,c,e);d=u}f=n&&typeof Response<"u"&&_ instanceof Response&&_.status===200}Ft(s.progress_callback,{status:"download",name:o,file:t});const m={status:"progress",name:o,file:t};let g;return s.progress_callback?p&&typeof navigator<"u"&&/firefox/i.test(navigator.userAgent)?(g=new Uint8Array(await _.arrayBuffer()),Ft(s.progress_callback,{...m,progress:100,loaded:g.length,total:g.length})):g=await Cb(_,w=>{Ft(s.progress_callback,{...m,...w})}):g=new Uint8Array(await _.arrayBuffer()),f&&d&&await n.match(d)===void 0&&await n.put(d,new Response(g,{headers:_.headers})).catch(w=>{console.warn(`Unable to add response to browser cache: ${w}.`)}),Ft(s.progress_callback,{status:"done",name:o,file:t}),g}a(jx,"getModelFile");async function se(o,t,e=!0,s={}){let n=await jx(o,t,e,s);if(n===null)return{};let r=new TextDecoder("utf-8").decode(n);return JSON.parse(r)}a(se,"getModelJSON");async function Cb(o,t){const e=o.headers.get("Content-Length");e===null&&console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");let s=parseInt(e??"0"),n=new Uint8Array(s),i=0;const r=o.body.getReader();async function l(){const{done:c,value:h}=await r.read();if(c)return;let d=i+h.length;if(d>s){s=d;let f=new Uint8Array(s);f.set(n),n=f}n.set(h,i),i=d;const u=i/s*100;return t({progress:u,loaded:i,total:s}),l()}return a(l,"read"),await l(),n}a(Cb,"readResponse");function Xs(...o){return o=o.map((t,e)=>(e&&(t=t.replace(new RegExp("^/"),"")),e!==o.length-1&&(t=t.replace(new RegExp("/$"),"")),t)),o.join("/")}a(Xs,"pathJoin");typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});function $x(o,[t,e,s],[n,i],r="bilinear",l=!1){const c=i/s,h=n/e,d=new o.constructor(n*i*t),u=e*s,f=n*i;for(let _=0;_<n;++_)for(let p=0;p<i;++p){const m=_*i+p,g=(p+.5)/c-.5,w=(_+.5)/h-.5;let y=Math.floor(g),k=Math.floor(w);const A=Math.min(y+1,s-1),b=Math.min(k+1,e-1);y=Math.max(y,0),k=Math.max(k,0);const N=g-y,I=w-k,$=(1-N)*(1-I),G=N*(1-I),L=(1-N)*I,Y=N*I,q=k*s,U=b*s,D=q+y,X=q+A,R=U+y,B=U+A;for(let K=0;K<t;++K){const S=K*u;d[K*f+m]=$*o[S+D]+G*o[S+X]+L*o[S+R]+Y*o[S+B]}}return d}a($x,"interpolate_data");function Rx(o,t,e){const s=new Array(e.length),n=new Array(e.length);for(let l=e.length-1,c=1;l>=0;--l)n[l]=c,s[l]=t[e[l]],c*=s[l];const i=e.map((l,c)=>n[e.indexOf(c)]),r=new o.constructor(o.length);for(let l=0;l<o.length;++l){let c=0;for(let h=t.length-1,d=l;h>=0;--h)c+=d%t[h]*i[h],d=Math.floor(d/t[h]);r[c]=o[l]}return[r,s]}a(Rx,"permute_data");function st(o){const t=ct(o)[0],e=o.map(i=>Math.exp(i-t)),s=e.reduce((i,r)=>i+r,0);return e.map(i=>i/s)}a(st,"softmax");function Ux(o){return st(o).map(s=>Math.log(s))}a(Ux,"log_softmax");function Dx(o,t){let e=0;for(let s=0;s<o.length;++s)e+=o[s]*t[s];return e}a(Dx,"dot");function Qt(o,t=0){return o=Array.from(o).map((e,s)=>[s,e]).sort((e,s)=>s[1]-e[1]),t!==null&&t>0&&(o=o.slice(0,t)),o}a(Qt,"getTopItems");function Kb(o,t){const e=Dx(o,t),s=wh(o),n=wh(t);return e/(s*n)}a(Kb,"cos_sim");function wh(o){return Math.sqrt(o.reduce((t,e)=>t+e*e,0))}a(wh,"magnitude");function $d(o){if(o.length===0)throw Error("Array must not be empty");let t=o[0],e=0;for(let s=1;s<o.length;++s)o[s]<t&&(t=o[s],e=s);return[t,e]}a($d,"min");function ct(o){if(o.length===0)throw Error("Array must not be empty");let t=o[0],e=0;for(let s=1;s<o.length;++s)o[s]>t&&(t=o[s],e=s);return[Number(t),e]}a(ct,"max");function Lx(o){return o>0&&(o&o-1)===0}a(Lx,"isPowerOfTwo");const Yd=class Yd{constructor(t){if(this.size=t|0,this.size<=1||!Lx(this.size))throw new Error("FFT size must be a power of two larger than 1");this._csize=t<<1,this.table=new Float64Array(this.size*2);for(let s=0;s<this.table.length;s+=2){const n=Math.PI*s/this.size;this.table[s]=Math.cos(n),this.table[s+1]=-Math.sin(n)}let e=0;for(let s=1;this.size>s;s<<=1)++e;this._width=e%2===0?e-1:e,this._bitrev=new Int32Array(1<<this._width);for(let s=0;s<this._bitrev.length;++s){this._bitrev[s]=0;for(let n=0;n<this._width;n+=2){const i=this._width-n-2;this._bitrev[s]|=(s>>>n&3)<<i}}}createComplexArray(){return new Float64Array(this._csize)}fromComplexArray(t,e){const s=e||new Array(t.length>>>1);for(let n=0;n<t.length;n+=2)s[n>>>1]=t[n];return s}toComplexArray(t,e){const s=e||this.createComplexArray();for(let n=0;n<s.length;n+=2)s[n]=t[n>>>1],s[n+1]=0;return s}transform(t,e){if(t===e)throw new Error("Input and output buffers must be different");this._transform4(t,e,1)}realTransform(t,e){if(t===e)throw new Error("Input and output buffers must be different");this._realTransform4(t,e,1)}inverseTransform(t,e){if(t===e)throw new Error("Input and output buffers must be different");this._transform4(t,e,-1);for(let s=0;s<t.length;++s)t[s]/=this.size}_transform4(t,e,s){const n=this._csize;let r=1<<this._width,l=n/r<<1,c,h;const d=this._bitrev;if(l===4)for(c=0,h=0;c<n;c+=l,++h){const f=d[h];this._singleTransform2(e,t,c,f,r)}else for(c=0,h=0;c<n;c+=l,++h){const f=d[h];this._singleTransform4(e,t,c,f,r,s)}const u=this.table;for(r>>=2;r>=2;r>>=2){l=n/r<<1;const f=l>>>2;for(c=0;c<n;c+=l){const _=c+f-1;for(let p=c,m=0;p<_;p+=2,m+=r){const g=p,w=g+f,y=w+f,k=y+f,A=t[g],b=t[g+1],N=t[w],I=t[w+1],$=t[y],G=t[y+1],L=t[k],Y=t[k+1],q=u[m],U=s*u[m+1],D=N*q-I*U,X=N*U+I*q,R=u[2*m],B=s*u[2*m+1],K=$*R-G*B,S=$*B+G*R,rt=u[3*m],F=s*u[3*m+1],pe=L*rt-Y*F,me=L*F+Y*rt,ge=A+K,we=b+S,ye=A-K,xe=b-S,Vt=D+pe,Mt=X+me,be=s*(D-pe),ke=s*(X-me);t[g]=ge+Vt,t[g+1]=we+Mt,t[w]=ye+ke,t[w+1]=xe-be,t[y]=ge-Vt,t[y+1]=we-Mt,t[k]=ye-ke,t[k+1]=xe+be}}}}_singleTransform2(t,e,s,n,i){const r=t[n],l=t[n+1],c=t[n+i],h=t[n+i+1];e[s]=r+c,e[s+1]=l+h,e[s+2]=r-c,e[s+3]=l-h}_singleTransform4(t,e,s,n,i,r){const l=i*2,c=i*3,h=t[n],d=t[n+1],u=t[n+i],f=t[n+i+1],_=t[n+l],p=t[n+l+1],m=t[n+c],g=t[n+c+1],w=h+_,y=d+p,k=h-_,A=d-p,b=u+m,N=f+g,I=r*(u-m),$=r*(f-g);e[s]=w+b,e[s+1]=y+N,e[s+2]=k+$,e[s+3]=A-I,e[s+4]=w-b,e[s+5]=y-N,e[s+6]=k-$,e[s+7]=A+I}_realTransform4(t,e,s){const n=this._csize;let r=1<<this._width,l=n/r<<1,c,h;const d=this._bitrev;if(l===4)for(c=0,h=0;c<n;c+=l,++h){const _=d[h];this._singleRealTransform2(e,t,c,_>>>1,r>>>1)}else for(c=0,h=0;c<n;c+=l,++h){const _=d[h];this._singleRealTransform4(e,t,c,_>>>1,r>>>1,s)}const u=this.table;for(r>>=2;r>=2;r>>=2){l=n/r<<1;const _=l>>>1,p=_>>>1,m=p>>>1;for(c=0;c<n;c+=l)for(let g=0,w=0;g<=m;g+=2,w+=r){const y=c+g,k=y+p,A=k+p,b=A+p,N=t[y],I=t[y+1],$=t[k],G=t[k+1],L=t[A],Y=t[A+1],q=t[b],U=t[b+1],D=N,X=I,R=u[w],B=s*u[w+1],K=$*R-G*B,S=$*B+G*R,rt=u[2*w],F=s*u[2*w+1],pe=L*rt-Y*F,me=L*F+Y*rt,ge=u[3*w],we=s*u[3*w+1],ye=q*ge-U*we,xe=q*we+U*ge,Vt=D+pe,Mt=X+me,be=D-pe,ke=X-me,hh=K+ye,dh=S+xe,dx=s*(K-ye),ux=s*(S-xe);if(t[y]=Vt+hh,t[y+1]=Mt+dh,t[k]=be+ux,t[k+1]=ke-dx,g===0){t[A]=Vt-hh,t[A+1]=Mt-dh;continue}if(g===m)continue;const _x=c+p-g,fx=c+_-g;t[_x]=be-s*ux,t[_x+1]=-ke-s*dx,t[fx]=Vt-s*hh,t[fx+1]=-Mt+s*dh}}const f=n>>>1;for(let _=2;_<f;_+=2)t[n-_]=t[_],t[n-_+1]=-t[_+1]}_singleRealTransform2(t,e,s,n,i){const r=t[n],l=t[n+i];e[s]=r+l,e[s+1]=0,e[s+2]=r-l,e[s+3]=0}_singleRealTransform4(t,e,s,n,i,r){const l=i*2,c=i*3,h=t[n],d=t[n+i],u=t[n+l],f=t[n+c],_=h+u,p=h-u,m=d+f,g=r*(d-f);e[s]=_+m,e[s+1]=0,e[s+2]=p,e[s+3]=-g,e[s+4]=_-m,e[s+5]=0,e[s+6]=p,e[s+7]=g}};a(Yd,"P2FFT");let Vs=Yd;const Jd=class Jd{constructor(t){const e=2*(t-1),s=2*(2*t-1),n=2**Math.ceil(Math.log2(s));this.bufferSize=n,this._a=e;const i=new Float64Array(s),r=new Float64Array(n);this._chirpBuffer=new Float64Array(n),this._buffer1=new Float64Array(n),this._buffer2=new Float64Array(n),this._outBuffer1=new Float64Array(n),this._outBuffer2=new Float64Array(n);const l=-2*Math.PI/t,c=Math.cos(l),h=Math.sin(l);for(let d=0;d<s>>1;++d){const u=(d+1-t)**2/2,f=Math.sqrt(c**2+h**2)**u,_=u*Math.atan2(h,c),p=2*d;i[p]=f*Math.cos(_),i[p+1]=f*Math.sin(_),r[p]=i[p],r[p+1]=-i[p+1]}this._slicedChirpBuffer=i.subarray(e,s),this._f=new Vs(n>>1),this._f.transform(this._chirpBuffer,r)}_transform(t,e,s){const n=this._buffer1,i=this._buffer2,r=this._outBuffer1,l=this._outBuffer2,c=this._chirpBuffer,h=this._slicedChirpBuffer,d=this._a;if(s)for(let u=0;u<h.length;u+=2){const f=u+1,_=u>>1,p=e[_];n[u]=p*h[u],n[f]=p*h[f]}else for(let u=0;u<h.length;u+=2){const f=u+1;n[u]=e[u]*h[u]-e[f]*h[f],n[f]=e[u]*h[f]+e[f]*h[u]}this._f.transform(r,n);for(let u=0;u<c.length;u+=2){const f=u+1;i[u]=r[u]*c[u]-r[f]*c[f],i[f]=r[u]*c[f]+r[f]*c[u]}this._f.inverseTransform(l,i);for(let u=0;u<l.length;u+=2){const f=l[u+d],_=l[u+d+1],p=h[u],m=h[u+1];t[u]=f*p-_*m,t[u+1]=f*m+_*p}}transform(t,e){this._transform(t,e,!1)}realTransform(t,e){this._transform(t,e,!0)}};a(Jd,"NP2FFT");let yh=Jd;const Zd=class Zd{constructor(t){this.fft_length=t,this.isPowerOfTwo=Lx(t),this.isPowerOfTwo?(this.fft=new Vs(t),this.outputBufferSize=2*t):(this.fft=new yh(t),this.outputBufferSize=this.fft.bufferSize)}realTransform(t,e){this.fft.realTransform(t,e)}transform(t,e){this.fft.transform(t,e)}};a(Zd,"FFT");let Ms=Zd;function Gx(o,t){if(t%2===0||t<=0)throw new Error("Window size must be a positive odd number");const e=new o.constructor(o.length),s=new o.constructor(t),n=Math.floor(t/2);for(let i=0;i<o.length;++i){let r=0;for(let l=-n;l<=n;++l){let c=i+l;c<0?c=Math.abs(c):c>=o.length&&(c=2*(o.length-1)-c),s[r++]=o[c]}s.sort(),e[i]=s[n]}return e}a(Gx,"medianFilter");function Tt(o,t){const e=Math.pow(10,t);return Math.round(o*e)/e}a(Tt,"round");function qx(o){const t=Math.round(o);return Math.abs(o)%1===.5?t%2===0?t:t-1:t}a(qx,"bankers_round");const yx=Object.freeze({float32:Float32Array,float64:Float64Array,string:Array,int8:Int8Array,uint8:Uint8Array,int16:Int16Array,uint16:Uint16Array,int32:Int32Array,uint32:Uint32Array,int64:BigInt64Array,uint64:BigUint64Array,bool:Uint8Array}),xx=_t.Tensor,ot=class ot{constructor(...t){E(this,"dims");E(this,"type");E(this,"data");E(this,"size");return t[0]instanceof xx?Object.assign(this,t[0]):Object.assign(this,new xx(t[0],t[1],t[2])),new Proxy(this,{get:a((e,s)=>{if(typeof s=="string"){let n=Number(s);if(Number.isInteger(n))return e._getitem(n)}return e[s]},"get"),set:a((e,s,n)=>e[s]=n,"set")})}*[Symbol.iterator](){const[t,...e]=this.dims;if(e.length>0){const s=e.reduce((n,i)=>n*i);for(let n=0;n<t;++n)yield this._subarray(n,s,e)}else yield*this.data}_getitem(t){const[e,...s]=this.dims;if(t=vt(t,e),s.length>0){const n=s.reduce((i,r)=>i*r);return this._subarray(t,n,s)}else return new ot(this.type,[this.data[t]],s)}indexOf(t){for(let e=0;e<this.data.length;++e)if(this.data[e]==t)return e;return-1}_subarray(t,e,s){const n=t*e,i=(t+1)*e,r="subarray"in this.data?this.data.subarray(n,i):this.data.slice(n,i);return new ot(this.type,r,s)}item(){if(this.data.length!==1)throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`);return this.data[0]}tolist(){return Wb(this.data,this.dims)}sigmoid(){return this.clone().sigmoid_()}sigmoid_(){for(let t=0;t<this.data.length;++t)this.data[t]=1/(1+Math.exp(-this.data[t]));return this}mul(t){return this.clone().mul_(t)}mul_(t){for(let e=0;e<this.data.length;++e)this.data[e]*=t;return this}add(t){return this.clone().add_(t)}add_(t){for(let e=0;e<this.data.length;++e)this.data[e]+=t;return this}clone(){return new ot(this.type,this.data.slice(),this.dims.slice())}slice(...t){let e=[],s=[];for(let c=0;c<this.dims.length;++c){let h=t[c];if(h==null)s.push([0,this.dims[c]]),e.push(this.dims[c]);else if(typeof h=="number")h=vt(h,this.dims[c],c),s.push([h,h+1]);else if(Array.isArray(h)&&h.length===2){if(h[0]>h[1])throw new Error(`Invalid slice: ${h}`);let d=[Math.max(h[0],0),Math.min(h[1],this.dims[c])];s.push(d),e.push(d[1]-d[0])}else throw new Error(`Invalid slice: ${h}`)}let n=s.map(([c,h])=>h-c),i=n.reduce((c,h)=>c*h),r=new this.data.constructor(i);const l=this.stride();for(let c=0;c<i;++c){let h=0;for(let d=n.length-1,u=c;d>=0;--d){const f=n[d];h+=(u%f+s[d][0])*l[d],u=Math.floor(u/f)}r[c]=this.data[h]}return new ot(this.type,r,e)}permute(...t){return Bx(this,t)}transpose(...t){return this.permute(...t)}sum(t=null,e=!1){return this.norm(1,t,e)}norm(t="fro",e=null,s=!1){if(t==="fro")t=2;else if(typeof t=="string")throw Error(`Unsupported norm: ${t}`);if(e===null){let r=this.data.reduce((l,c)=>l+c**t,0)**(1/t);return new ot(this.type,[r],[])}e=vt(e,this.dims.length);const n=this.dims.slice();n[e]=1;const i=new this.data.constructor(this.data.length/this.dims[e]);for(let r=0;r<this.data.length;++r){let l=0;for(let c=this.dims.length-1,h=r,d=1;c>=0;--c){const u=this.dims[c];if(c!==e){const f=h%u;l+=f*d,d*=n[c]}h=Math.floor(h/u)}i[l]+=this.data[r]**t}if(t!==1)for(let r=0;r<i.length;++r)i[r]=i[r]**(1/t);return s||n.splice(e,1),new ot(this.type,i,n)}normalize_(t=2,e=1){e=vt(e,this.dims.length);const s=this.norm(t,e,!0);for(let n=0;n<this.data.length;++n){let i=0;for(let r=this.dims.length-1,l=n,c=1;r>=0;--r){const h=this.dims[r];if(r!==e){const d=l%h;i+=d*c,c*=this.dims[r]}l=Math.floor(l/h)}this.data[n]/=s.data[i]}return this}normalize(t=2,e=1){return this.clone().normalize_(t,e)}stride(){return Jb(this.dims)}squeeze(t=null){return new ot(this.type,this.data,bx(this.dims,t))}squeeze_(t=null){return this.dims=bx(this.dims,t),this}unsqueeze(t=null){return new ot(this.type,this.data,kx(this.dims,t))}unsqueeze_(t=null){return this.dims=kx(this.dims,t),this}flatten_(t=0,e=-1){e=(e+this.dims.length)%this.dims.length;let s=this.dims.slice(0,t),n=this.dims.slice(t,e+1),i=this.dims.slice(e+1);return this.dims=[...s,n.reduce((r,l)=>r*l,1),...i],this}flatten(t=0,e=-1){return this.clone().flatten_(t,e)}view(...t){let e=-1;for(let s=0;s<t.length;++s)if(t[s]===-1){if(e!==-1)throw new Error("Only one dimension can be inferred");e=s}if(e!==-1){const s=t.reduce((n,i,r)=>r!==e?n*i:n,1);t[e]=this.data.length/s}return new ot(this.type,this.data,t)}neg_(){for(let t=0;t<this.data.length;++t)this.data[t]=-this.data[t];return this}neg(){return this.clone().neg_()}clamp_(t,e){for(let s=0;s<this.data.length;++s)this.data[s]=Math.min(Math.max(this.data[s],t),e);return this}clamp(t,e){return this.clone().clamp_(t,e)}round_(){for(let t=0;t<this.data.length;++t)this.data[t]=Math.round(this.data[t]);return this}round(){return this.clone().round_()}to(t){if(this.type===t)return this;if(!yx.hasOwnProperty(t))throw new Error(`Unsupported type: ${t}`);return new ot(t,yx[t].from(this.data),this.dims)}};a(ot,"Tensor");let v=ot;function Wb(o,t){const e=o.length,s=t.reduce((i,r)=>i*r);if(e!==s)throw Error(`cannot reshape array of size ${e} into shape (${t})`);let n=o;for(let i=t.length-1;i>=0;i--)n=n.reduce((r,l)=>{let c=r[r.length-1];return c.length<t[i]?c.push(l):r.push([l]),r},[[]]);return n[0]}a(Wb,"reshape");function Bx(o,t){const[e,s]=Rx(o.data,o.dims,t);return new v(o.type,e,s)}a(Bx,"permute");function ne(o,[t,e],s="bilinear",n=!1){const i=o.dims.at(-3)??1,r=o.dims.at(-2),l=o.dims.at(-1);let c=$x(o.data,[i,r,l],[t,e],s,n);return new v(o.type,c,[i,t,e])}a(ne,"interpolate");function Hx(o,t){let e=[o.dims[0],o.dims[2]],s=new o.data.constructor(e[0]*e[1]),[n,i,r]=o.dims,l=0;for(let c=0;c<n;++c){let h=c*r*i;for(let d=0;d<r;++d){let u=0,f=0,_=c*i,p=h+d;for(let g=0;g<i;++g){let w=Number(t.data[_+g]);f+=w,u+=o.data[p+g*r]*w}let m=u/f;s[l++]=m}}return new v(o.type,s,e)}a(Hx,"mean_pooling");function Yb(o,t,{eps:e=1e-5}={}){if(o.dims.length!==2)throw new Error("`layer_norm` currently only supports 2D input.");const[s,n]=o.dims;if(t.length!==1&&t[0]!==n)throw new Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");const[i,r]=Rd(o,1,0,!0),l=new o.data.constructor(o.data.length);for(let c=0;c<s;++c){const h=c*n;for(let d=0;d<n;++d){const u=h+d;l[u]=(o.data[u]-r.data[c])/(i.data[c]+e)}}return new v(o.type,l,o.dims)}a(Yb,"layer_norm");function bx(o,t){return o=o.slice(),t===null?o=o.filter(e=>e!==1):typeof t=="number"?o[t]===1&&o.splice(t,1):Array.isArray(t)&&(o=o.filter((e,s)=>e!==1||!t.includes(s))),o}a(bx,"calc_squeeze_dims");function kx(o,t){return t=vt(t,o.length+1),o=o.slice(),o.splice(t,0,1),o}a(kx,"calc_unsqueeze_dims");function vt(o,t,e=null){if(o<-t||o>=t)throw new Error(`IndexError: index ${o} is out of bounds for dimension${e===null?"":" "+e} with size ${t}`);return o<0&&(o=(o%t+t)%t),o}a(vt,"safeIndex");function Ls(o,t=0){t=vt(t,o[0].dims.length);const e=o[0].dims.slice();e[t]=o.reduce((r,l)=>r+l.dims[t],0);const s=e.reduce((r,l)=>r*l,1),n=new o[0].data.constructor(s),i=o[0].type;if(t===0){let r=0;for(let l of o)n.set(l.data,r),r+=l.data.length}else{let r=0;for(let l=0;l<o.length;++l){let c=o[l];for(let h=0;h<c.data.length;++h){let d=0;for(let u=c.dims.length-1,f=h,_=1;u>=0;--u){const p=c.dims[u];let m=f%p;u===t&&(m+=r),d+=m*_,_*=e[u],f=Math.floor(f/p)}n[d]=c.data[h]}r+=c.dims[t]}}return new v(i,n,e)}a(Ls,"cat");function Gs(o,t=0){return Ls(o.map(e=>e.unsqueeze(t)),t)}a(Gs,"stack");function Rd(o,t=null,e=1,s=!1){if(t===null){const h=o.data.reduce((_,p)=>_+p,0)/o.data.length,d=Math.sqrt(o.data.reduce((_,p)=>_+(p-h)**2,0)/(o.data.length-e)),u=new v(o.type,[h],[]);return[new v(o.type,[d],[]),u]}t=vt(t,o.dims.length);const n=Ud(o,t,s),i=o.dims.slice();i[t]=1;const r=new o.data.constructor(o.data.length/o.dims[t]);for(let c=0;c<o.data.length;++c){let h=0;for(let d=o.dims.length-1,u=c,f=1;d>=0;--d){const _=o.dims[d];if(d!==t){const p=u%_;h+=p*f,f*=i[d]}u=Math.floor(u/_)}r[h]+=(o.data[c]-n.data[h])**2}for(let c=0;c<r.length;++c)r[c]=Math.sqrt(r[c]/(o.dims[t]-e));return s||i.splice(t,1),[new v(o.type,r,i),n]}a(Rd,"std_mean");function Ud(o,t=null,e=!1){if(t===null){let i=o.data.reduce((r,l)=>r+l,0);return new v(o.type,[i/o.data.length],[])}t=vt(t,o.dims.length);const s=o.dims.slice();s[t]=1;const n=new o.data.constructor(o.data.length/o.dims[t]);for(let i=0;i<o.data.length;++i){let r=0;for(let l=o.dims.length-1,c=i,h=1;l>=0;--l){const d=o.dims[l];if(l!==t){const u=c%d;r+=u*h,h*=s[l]}c=Math.floor(c/d)}n[r]+=o.data[i]}if(o.dims[t]!==1)for(let i=0;i<n.length;++i)n[i]=n[i]/o.dims[t];return e||s.splice(t,1),new v(o.type,n,s)}a(Ud,"mean");function Xx(o){const[t,e]=o.dims,s=[t+1,e+1],n=new v("float32",new Float32Array(s[0]*s[1]).fill(1/0),s),i=new v("float32",new Float32Array(s[0]*s[1]).fill(-1),s);n[0].data[0]=0;for(let d=1;d<e+1;++d)for(let u=1;u<t+1;++u){const f=n[u-1][d-1].item(),_=n[u-1][d].item(),p=n[u][d-1].item();let m,g;f<_&&f<p?(m=f,g=0):_<f&&_<p?(m=_,g=1):(m=p,g=2),n[u].data[d]=o[u-1][d-1].item()+m,i[u].data[d]=g}let r=t,l=e;i.data.fill(2,0,s[1]);for(let d=0;d<s[0];++d)i[d].data[0]=1;let c=[],h=[];for(;r>0||l>0;)switch(c.push(r-1),h.push(l-1),i[r][l].item()){case 0:--r,--l;break;case 1:--r;break;case 2:--l;break;default:throw new Error(`Internal error in dynamic time warping. Unexpected trace[${r}, ${l}]. Please file a bug report.`)}return c.reverse(),h.reverse(),[c,h]}a(Xx,"dynamicTimeWarping");function Jb(o){const t=new Array(o.length);for(let e=o.length-1,s=1;e>=0;--e)t[e]=s,s*=o[e];return t}a(Jb,"dimsToStride");function Cx(o){const t=o.reduce((e,s)=>e*s,1);return new v("int64",new BigInt64Array(t).fill(1n),o)}a(Cx,"ones");function Kx(o){return Cx(o.dims)}a(Kx,"ones_like");function Wx(o,t){if(o.dims.length!==2)throw new Error("The tensor must have 2 dimensions");if(o.dims.at(-1)%8!==0)throw new Error("The last dimension of the tensor must be a multiple of 8");if(!["binary","ubinary"].includes(t))throw new Error("The precision must be either 'binary' or 'ubinary'");const e=t==="binary",s=e?"int8":"uint8",n=e?Int8Array:Uint8Array,i=o.data,r=new n(i.length/8);for(let l=0;l<i.length;++l){const c=i[l]>0?1:0,h=Math.floor(l/8),d=l%8;r[h]|=c<<7-d,e&&d===0&&(r[h]-=128)}return new v(s,r,[o.dims[0],o.dims[1]/8])}a(Wx,"quantize_embeddings");typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});const Qd=class Qd{constructor(t=(e,s)=>e>s){this._heap=[],this._comparator=t}get size(){return this._heap.length}isEmpty(){return this.size===0}peek(){return this._heap[0]}push(...t){return this.extend(t)}extend(t){for(const e of t)this._heap.push(e),this._siftUp();return this.size}pop(){const t=this.peek(),e=this.size-1;return e>0&&this._swap(0,e),this._heap.pop(),this._siftDown(),t}replace(t){const e=this.peek();return this._heap[0]=t,this._siftDown(),e}_parent(t){return(t+1>>>1)-1}_left(t){return(t<<1)+1}_right(t){return t+1<<1}_greater(t,e){return this._comparator(this._heap[t],this._heap[e])}_swap(t,e){const s=this._heap[t];this._heap[t]=this._heap[e],this._heap[e]=s}_siftUp(){let t=this.size-1;for(;t>0&&this._greater(t,this._parent(t));)this._swap(t,this._parent(t)),t=this._parent(t)}_siftDown(){let t=0;for(;this._left(t)<this.size&&this._greater(this._left(t),t)||this._right(t)<this.size&&this._greater(this._right(t),t);){const e=this._right(t)<this.size&&this._greater(this._right(t),this._left(t))?this._right(t):this._left(t);this._swap(t,e),t=e}}};a(Qd,"PriorityQueue");let xh=Qd;const Vd=class Vd{constructor(){this.root=Fs.default()}extend(t){for(let e of t)this.push(e)}push(t){let e=this.root;for(let s of t){let n=e.children.get(s);n===void 0&&(n=Fs.default(),e.children.set(s,n)),e=n}e.isLeaf=!0}*commonPrefixSearch(t){let e=this.root,s="";for(let n=0;n<t.length&&e!==void 0;++n){const i=t[n];s+=i,e=e.children.get(i),e!==void 0&&e.isLeaf&&(yield s)}}};a(Vd,"CharTrie");let bh=Vd;const $c=class $c{constructor(t,e){this.isLeaf=t,this.children=e}static default(){return new $c(!1,new Map)}};a($c,"CharTrieNode");let Fs=$c;const Md=class Md{constructor(t,e,s){this.sentence=t,this.len=t.length,this.bosTokenId=e,this.eosTokenId=s,this.nodes=[],this.beginNodes=Array.from({length:this.len+1},()=>[]),this.endNodes=Array.from({length:this.len+1},()=>[]);const n=new ve(this.bosTokenId,0,0,0,0),i=new ve(this.eosTokenId,1,this.len,0,0);this.nodes.push(n.clone()),this.nodes.push(i.clone()),this.beginNodes[this.len].push(i),this.endNodes[0].push(n)}insert(t,e,s,n){const i=this.nodes.length,r=new ve(n,i,t,e,s);this.beginNodes[t].push(r),this.endNodes[t+e].push(r),this.nodes.push(r)}viterbi(){const t=this.len;let e=0;for(;e<=t;){if(this.beginNodes[e].length==0)return[];for(let l of this.beginNodes[e]){l.prev=null;let c=0,h=null;for(let d of this.endNodes[e]){const u=d.backtraceScore+l.score;(h===null||u>c)&&(h=d.clone(),c=u)}if(h!==null)l.prev=h,l.backtraceScore=c;else return[]}++e}const s=[],i=this.beginNodes[t][0].prev;if(i===null)return[];let r=i.clone();for(;r.prev!==null;)s.push(r.clone()),r=r.clone().prev.clone();return s.reverse(),s}piece(t){return this.sentence.slice(t.pos,t.pos+t.length)}tokens(){return this.viterbi().map(e=>this.piece(e))}tokenIds(){return this.viterbi().map(e=>e.tokenId)}};a(Md,"TokenLattice");let kh=Md;const Rc=class Rc{constructor(t,e,s,n,i){this.tokenId=t,this.nodeId=e,this.pos=s,this.length=n,this.score=i,this.prev=null,this.backtraceScore=0}clone(){const t=new Rc(this.tokenId,this.nodeId,this.pos,this.length,this.score);return t.prev=this.prev,t.backtraceScore=this.backtraceScore,t}};a(Rc,"TokenLatticeNode");let ve=Rc;typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});async function Yx(o,t){const e=await Promise.all([se(o,"tokenizer.json",!0,t),se(o,"tokenizer_config.json",!0,t)]);return t.legacy!==null&&(e[1].legacy=t.legacy),e}a(Yx,"loadTokenizer");function Zb(o,t){const e=[];let s=0;for(const n of o.matchAll(t)){const i=n[0];s<n.index&&e.push(o.slice(s,n.index)),i.length>0&&e.push(i),s=n.index+i.length}return s<o.length&&e.push(o.slice(s)),e}a(Zb,"regexSplit");function lh(o,t=!0){if(o.Regex!==void 0){let e=o.Regex.replace(/\\([#&~])/g,"$1");for(const[s,n]of Fb)e=e.replaceAll(s,n);return new RegExp(e,"gu")}else if(o.String!==void 0){const e=Ix(o.String);return new RegExp(t?e:`(${e})`,"gu")}else return console.warn("Unknown pattern type:",o),null}a(lh,"createPattern");function Dd(o){return new Map(Object.entries(o))}a(Dd,"objectToMap");function Jx(o){const t=o.dims;switch(t.length){case 1:return o.tolist();case 2:if(t[0]!==1)throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");return o.tolist()[0];default:throw new Error(`Expected tensor to have 1-2 dimensions, got ${t.length}.`)}}a(Jx,"prepareTensorForDecode");function Ld(o){return o.replace(/ \./g,".").replace(/ \?/g,"?").replace(/ \!/g,"!").replace(/ ,/g,",").replace(/ \' /g,"'").replace(/ n\'t/g,"n't").replace(/ \'m/g,"'m").replace(/ \'s/g,"'s").replace(/ \'ve/g,"'ve").replace(/ \'re/g,"'re")}a(Ld,"clean_up_tokenization");function Zx(o){return o.replace(/[\u0300-\u036f]/g,"")}a(Zx,"remove_accents");function Qb(o){return Zx(o.toLowerCase())}a(Qb,"lowercase_and_remove_accent");function Vb(o,t,e){const s=[];let n=0;for(;n<o.length;){if(s.push(o[n]),(e.get(o[n])??t)!==t){++n;continue}for(;n<o.length&&(e.get(o[n])??t)===t;)++n}return s}a(Vb,"fuse");function Mb(o){return o.match(/\S+/g)||[]}a(Mb,"whitespace_split");const Oe="\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E",Fb=new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)","(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"]]),Fd=class Fd{constructor(t){this.content=t.content,this.id=t.id,this.single_word=t.single_word??!1,this.lstrip=t.lstrip??!1,this.rstrip=t.rstrip??!1,this.special=t.special??!1,this.normalized=t.normalized??null}};a(Fd,"AddedToken");let vh=Fd;const Td=class Td extends lt{constructor(t){super(),this.config=t,this.vocab=[],this.tokens_to_ids=new Map,this.unk_token_id=void 0,this.unk_token=void 0,this.end_of_word_suffix=void 0,this.fuse_unk=this.config.fuse_unk??!1}static fromConfig(t,...e){switch(t.type){case"WordPiece":return new Ah(t);case"Unigram":return new Eh(t,...e);case"BPE":return new Nh(t);default:if(t.vocab)return new Ih(t,...e);throw new Error(`Unknown TokenizerModel type: ${t.type}`)}}_call(t){let e=this.encode(t);return this.fuse_unk&&(e=Vb(e,this.unk_token_id,this.tokens_to_ids)),e}encode(t){throw Error("encode should be implemented in subclass.")}convert_tokens_to_ids(t){return t.map(e=>this.tokens_to_ids.get(e)??this.unk_token_id)}convert_ids_to_tokens(t){return t.map(e=>this.vocab[e]??this.unk_token)}};a(Td,"TokenizerModel");let Et=Td;const Pd=class Pd extends Et{constructor(t){super(t),this.tokens_to_ids=Dd(t.vocab),this.unk_token_id=this.tokens_to_ids.get(t.unk_token),this.unk_token=t.unk_token,this.max_input_chars_per_word=t.max_input_chars_per_word??100,this.vocab=new Array(this.tokens_to_ids.size);for(const[e,s]of this.tokens_to_ids)this.vocab[s]=e}encode(t){const e=[];for(const s of t){const n=[...s];if(n.length>this.max_input_chars_per_word){e.push(this.unk_token);continue}let i=!1,r=0;const l=[];for(;r<n.length;){let c=n.length,h=null;for(;r<c;){let d=n.slice(r,c).join("");if(r>0&&(d=this.config.continuing_subword_prefix+d),this.tokens_to_ids.has(d)){h=d;break}--c}if(h===null){i=!0;break}l.push(h),r=c}i?e.push(this.unk_token):e.push(...l)}return e}};a(Pd,"WordPieceTokenizer");let Ah=Pd;const tu=class tu extends Et{constructor(t,e){super(t);const s=t.vocab.length;this.vocab=new Array(s),this.scores=new Array(s);for(let n=0;n<s;++n){const i=t.vocab[n];this.vocab[n]=i[0],this.scores[n]=i[1]}this.unk_token_id=t.unk_id,this.unk_token=this.vocab[t.unk_id],this.tokens_to_ids=new Map(this.vocab.map((n,i)=>[n,i])),this.bosToken=" ",this.bosTokenId=this.tokens_to_ids.get(this.bosToken),this.eosToken=e.eos_token,this.eosTokenId=this.tokens_to_ids.get(this.eosToken),this.unkToken=this.vocab[this.unk_token_id],this.minScore=$d(this.scores)[0],this.unkScore=this.minScore-10,this.scores[this.unk_token_id]=this.unkScore,this.trie=new bh,this.trie.extend(this.vocab),this.fuse_unk=!0}populateNodes(t){const e=t.sentence,s=e.length;let n=0;for(;n<s;){let r=!1;for(let l of this.trie.commonPrefixSearch(e.slice(n))){const c=this.tokens_to_ids.get(l),h=this.scores[c],d=l.length;t.insert(n,d,h,c),!r&&d===1&&(r=!0)}r||t.insert(n,1,this.unkScore,this.unk_token_id),n+=1}}tokenize(t){const e=new kh(t,this.bosTokenId,this.eosTokenId);return this.populateNodes(e),e.tokens()}encode(t){const e=[];for(const s of t){const n=this.tokenize(s);e.push(...n)}return e}};a(tu,"Unigram");let Eh=tu;const Qx=(()=>{const o=[...Array.from({length:94},(n,i)=>i+33),...Array.from({length:12},(n,i)=>i+161),...Array.from({length:82},(n,i)=>i+174)],t=o.slice();let e=0;for(let n=0;n<256;++n)o.includes(n)||(o.push(n),t.push(256+e),e+=1);const s=t.map(n=>String.fromCharCode(n));return Object.fromEntries(o.map((n,i)=>[n,s[i]]))})(),Tb=jb(Qx),eu=class eu extends Et{constructor(t){super(t),this.BPE_SPLIT_TOKEN=" ",this.tokens_to_ids=Dd(t.vocab),this.unk_token_id=this.tokens_to_ids.get(t.unk_token),this.unk_token=t.unk_token,this.vocab=new Array(this.tokens_to_ids.size);for(const[e,s]of this.tokens_to_ids)this.vocab[s]=e;this.bpe_ranks=new Map(t.merges.map((e,s)=>[e,s])),this.merges=t.merges.map(e=>e.split(this.BPE_SPLIT_TOKEN)),this.end_of_word_suffix=t.end_of_word_suffix,this.continuing_subword_suffix=t.continuing_subword_suffix??null,this.byte_fallback=this.config.byte_fallback??!1,this.byte_fallback&&(this.text_encoder=new TextEncoder),this.ignore_merges=this.config.ignore_merges??!1,this.cache=new Map}bpe(t){if(t.length===0)return[];const e=this.cache.get(t);if(e!==void 0)return e;const s=Array.from(t);this.end_of_word_suffix&&(s[s.length-1]+=this.end_of_word_suffix);let n=[];if(s.length>1){const i=new xh((c,h)=>c.score<h.score);let r={token:s[0],bias:0,prev:null,next:null},l=r;for(let c=1;c<s.length;++c){const h={bias:c/s.length,token:s[c],prev:l,next:null};l.next=h,this._add_node(i,l),l=h}for(;!i.isEmpty();){const c=i.pop();if(c.deleted||!c.next||c.next.deleted)continue;if(c.deleted=!0,c.next.deleted=!0,c.prev){const d={...c.prev};c.prev.deleted=!0,c.prev=d,d.prev?d.prev.next=d:r=d}const h={token:c.token+c.next.token,bias:c.bias,prev:c.prev,next:c.next.next};h.prev?(h.prev.next=h,this._add_node(i,h.prev)):r=h,h.next&&(h.next.prev=h,this._add_node(i,h))}for(let c=r;c!==null;c=c.next)n.push(c.token)}else n=s;if(this.continuing_subword_suffix)for(let i=0;i<n.length-1;++i)n[i]+=this.continuing_subword_suffix;return this.cache.set(t,n),n}_add_node(t,e){const s=this.bpe_ranks.get(e.token+this.BPE_SPLIT_TOKEN+e.next.token);s!==void 0&&(e.score=s+e.bias,t.push(e))}encode(t){const e=[];for(const s of t){if(this.ignore_merges&&this.tokens_to_ids.has(s)){e.push(s);continue}const n=this.bpe(s);for(const i of n)this.tokens_to_ids.has(i)?e.push(i):this.byte_fallback?e.push(...Array.from(this.text_encoder.encode(i)).map(r=>`<0x${r.toString(16).toUpperCase().padStart(2,"0")}>`)):e.push(this.unk_token)}return e}};a(eu,"BPE");let Nh=eu;const su=class su extends Et{constructor(t,e){super(t),this.tokens_to_ids=Dd(e.target_lang?t.vocab[e.target_lang]:t.vocab),this.bos_token=e.bos_token,this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=e.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.pad_token=e.pad_token,this.pad_token_id=this.tokens_to_ids.get(this.pad_token),this.unk_token=e.unk_token,this.unk_token_id=this.tokens_to_ids.get(this.unk_token),this.vocab=new Array(this.tokens_to_ids.size);for(const[s,n]of this.tokens_to_ids)this.vocab[n]=s}encode(t){return t}};a(su,"LegacyTokenizerModel");let Ih=su;const nu=class nu extends lt{constructor(t){super(),this.config=t}static fromConfig(t){if(t===null)return null;switch(t.type){case"BertNormalizer":return new Gh(t);case"Precompiled":return new sd(t);case"Sequence":return new Lh(t);case"Replace":return new Oh(t);case"NFC":return new zh(t);case"NFKC":return new Sh(t);case"NFKD":return new jh(t);case"Strip":return new $h(t);case"StripAccents":return new Rh(t);case"Lowercase":return new Uh(t);case"Prepend":return new Dh(t);default:throw new Error(`Unknown Normalizer type: ${t.type}`)}}normalize(t){throw Error("normalize should be implemented in subclass.")}_call(t){return this.normalize(t)}};a(nu,"Normalizer");let nt=nu;const iu=class iu extends nt{normalize(t){const e=lh(this.config.pattern);return e===null?t:t.replaceAll(e,this.config.content)}};a(iu,"Replace");let Oh=iu;const au=class au extends nt{normalize(t){return t=t.normalize("NFC"),t}};a(au,"NFC");let zh=au;const ru=class ru extends nt{normalize(t){return t=t.normalize("NFKC"),t}};a(ru,"NFKC");let Sh=ru;const ou=class ou extends nt{normalize(t){return t=t.normalize("NFKD"),t}};a(ou,"NFKD");let jh=ou;const lu=class lu extends nt{normalize(t){return this.config.strip_left&&this.config.strip_right?t=t.trim():(this.config.strip_left&&(t=t.trimStart()),this.config.strip_right&&(t=t.trimEnd())),t}};a(lu,"StripNormalizer");let $h=lu;const cu=class cu extends nt{normalize(t){return t=Zx(t),t}};a(cu,"StripAccents");let Rh=cu;const hu=class hu extends nt{normalize(t){return t=t.toLowerCase(),t}};a(hu,"Lowercase");let Uh=hu;const du=class du extends nt{normalize(t){return t=this.config.prepend+t,t}};a(du,"Prepend");let Dh=du;const uu=class uu extends nt{constructor(t){super(t),this.normalizers=t.normalizers.map(e=>nt.fromConfig(e))}normalize(t){return this.normalizers.reduce((e,s)=>s.normalize(e),t)}};a(uu,"NormalizerSequence");let Lh=uu;const _u=class _u extends nt{_tokenize_chinese_chars(t){const e=[];for(let s=0;s<t.length;++s){const n=t[s],i=n.charCodeAt(0);this._is_chinese_char(i)?(e.push(" "),e.push(n),e.push(" ")):e.push(n)}return e.join("")}_is_chinese_char(t){return t>=19968&&t<=40959||t>=13312&&t<=19903||t>=131072&&t<=173791||t>=173824&&t<=177983||t>=177984&&t<=178207||t>=178208&&t<=183983||t>=63744&&t<=64255||t>=194560&&t<=195103}stripAccents(t){return t.normalize("NFD").replace(/[\u0300-\u036f]/g,"")}_is_control(t){switch(t){case"	":case`
`:case"\r":return!1;default:return/^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(t)}}_clean_text(t){const e=[];for(const s of t){const n=s.charCodeAt(0);n===0||n===65533||this._is_control(s)||(/^\s$/.test(s)?e.push(" "):e.push(s))}return e.join("")}normalize(t){return this.config.clean_text&&(t=this._clean_text(t)),this.config.handle_chinese_chars&&(t=this._tokenize_chinese_chars(t)),this.config.lowercase?(t=t.toLowerCase(),this.config.strip_accents!==!1&&(t=this.stripAccents(t))):this.config.strip_accents&&(t=this.stripAccents(t)),t}};a(_u,"BertNormalizer");let Gh=_u;const fu=class fu extends lt{static fromConfig(t){if(t===null)return null;switch(t.type){case"BertPreTokenizer":return new qh(t);case"Sequence":return new nd(t);case"Whitespace":return new id(t);case"WhitespaceSplit":return new ad(t);case"Metaspace":return new en(t);case"ByteLevel":return new Bh(t);case"Split":return new Hh(t);case"Punctuation":return new Xh(t);case"Digits":return new Ch(t);case"Replace":return new rd(t);default:throw new Error(`Unknown PreTokenizer type: ${t.type}`)}}pre_tokenize_text(t,e){throw Error("pre_tokenize_text should be implemented in subclass.")}pre_tokenize(t,e){return(Array.isArray(t)?t.map(s=>this.pre_tokenize_text(s,e)):this.pre_tokenize_text(t,e)).flat()}_call(t,e){return this.pre_tokenize(t,e)}};a(fu,"PreTokenizer");let at=fu;const pu=class pu extends at{constructor(t){super(),this.pattern=new RegExp(`[^\\s${Oe}]+|[${Oe}]`,"gu")}pre_tokenize_text(t,e){return t.trim().match(this.pattern)||[]}};a(pu,"BertPreTokenizer");let qh=pu;const mu=class mu extends at{constructor(t){super(),this.config=t,this.add_prefix_space=this.config.add_prefix_space,this.trim_offsets=this.config.trim_offsets,this.use_regex=this.config.use_regex??!0,this.pattern=/'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu,this.byte_encoder=Qx,this.text_encoder=new TextEncoder}pre_tokenize_text(t,e){return this.add_prefix_space&&!t.startsWith(" ")&&(t=" "+t),(this.use_regex?t.match(this.pattern)||[]:[t]).map(n=>Array.from(this.text_encoder.encode(n),i=>this.byte_encoder[i]).join(""))}};a(mu,"ByteLevelPreTokenizer");let Bh=mu;const gu=class gu extends at{constructor(t){super(),this.config=t,this.pattern=lh(this.config.pattern,this.config.invert)}pre_tokenize_text(t,e){return this.pattern===null?[]:this.config.invert?t.match(this.pattern)||[]:Zb(t,this.pattern)}};a(gu,"SplitPreTokenizer");let Hh=gu;const wu=class wu extends at{constructor(t){super(),this.config=t,this.pattern=new RegExp(`[^${Oe}]+|[${Oe}]+`,"gu")}pre_tokenize_text(t,e){return t.match(this.pattern)||[]}};a(wu,"PunctuationPreTokenizer");let Xh=wu;const yu=class yu extends at{constructor(t){super(),this.config=t;const e=`[^\\d]+|\\d${this.config.individual_digits?"":"+"}`;this.pattern=new RegExp(e,"gu")}pre_tokenize_text(t,e){return t.match(this.pattern)||[]}};a(yu,"DigitsPreTokenizer");let Ch=yu;const xu=class xu extends lt{constructor(t){super(),this.config=t}static fromConfig(t){if(t===null)return null;switch(t.type){case"TemplateProcessing":return new Kh(t);case"ByteLevel":return new tn(t);case"RobertaProcessing":return new Ps(t);case"BertProcessing":return new Ts(t);case"Sequence":return new Wh(t);default:throw new Error(`Unknown PostProcessor type: ${t.type}`)}}post_process(t,...e){throw Error("post_process should be implemented in subclass.")}_call(t,...e){return this.post_process(t,...e)}};a(xu,"PostProcessor");let Nt=xu;const bu=class bu extends Nt{constructor(t){super(t),this.cls=t.cls[0],this.sep=t.sep[0]}post_process(t,e=null,{add_special_tokens:s=!0}={}){s&&(t=et([this.cls],t,[this.sep]));let n=new Array(t.length).fill(0);if(e!==null){const i=s&&this instanceof Ps?[this.sep]:[],r=s?[this.sep]:[];t=et(t,i,e,r),n=et(n,new Array(e.length+i.length+r.length).fill(1))}return{tokens:t,token_type_ids:n}}};a(bu,"BertProcessing");let Ts=bu;const ku=class ku extends Ts{};a(ku,"RobertaProcessing");let Ps=ku;const vu=class vu extends Nt{constructor(t){super(t),this.single=t.single,this.pair=t.pair}post_process(t,e=null,{add_special_tokens:s=!0}={}){const n=e===null?this.single:this.pair;let i=[],r=[];for(const l of n)"SpecialToken"in l?s&&(i.push(l.SpecialToken.id),r.push(l.SpecialToken.type_id)):"Sequence"in l&&(l.Sequence.id==="A"?(i=et(i,t),r=et(r,new Array(t.length).fill(l.Sequence.type_id))):l.Sequence.id==="B"&&(i=et(i,e),r=et(r,new Array(e.length).fill(l.Sequence.type_id))));return{tokens:i,token_type_ids:r}}};a(vu,"TemplateProcessing");let Kh=vu;const Au=class Au extends Nt{post_process(t,e=null){return e&&(t=et(t,e)),{tokens:t}}};a(Au,"ByteLevelPostProcessor");let tn=Au;const Eu=class Eu extends Nt{constructor(t){super(t),this.processors=t.processors.map(e=>Nt.fromConfig(e))}post_process(t,e=null,s={}){let n;for(const i of this.processors)if(i instanceof tn)t=i.post_process(t).tokens,e&&(e=i.post_process(e).tokens);else{const r=i.post_process(t,e,s);t=r.tokens,n=r.token_type_ids}return{tokens:t,token_type_ids:n}}};a(Eu,"PostProcessorSequence");let Wh=Eu;const Nu=class Nu extends lt{constructor(t){super(),this.config=t,this.added_tokens=[],this.end_of_word_suffix=null,this.trim_offsets=t.trim_offsets}static fromConfig(t){if(t===null)return null;switch(t.type){case"WordPiece":return new Vh(t);case"Metaspace":return new ed(t);case"ByteLevel":return new Mh(t);case"Replace":return new Yh(t);case"ByteFallback":return new Jh(t);case"Fuse":return new Zh(t);case"Strip":return new Qh(t);case"Sequence":return new Th(t);case"CTC":return new Fh(t);case"BPEDecoder":return new Ph(t);default:throw new Error(`Unknown Decoder type: ${t.type}`)}}_call(t){return this.decode(t)}decode(t){return this.decode_chain(t).join("")}decode_chain(t){throw Error("`decode_chain` should be implemented in subclass.")}};a(Nu,"Decoder");let it=Nu;const Iu=class Iu extends it{decode_chain(t){const e=lh(this.config.pattern);return e===null?t:t.map(s=>s.replaceAll(e,this.config.content))}};a(Iu,"ReplaceDecoder");let Yh=Iu;const Ou=class Ou extends it{constructor(t){super(t),this.text_decoder=new TextDecoder}decode_chain(t){const e=[];let s=[];for(const n of t){let i=null;if(n.length===6&&n.startsWith("<0x")&&n.endsWith(">")){const r=parseInt(n.slice(3,5),16);isNaN(r)||(i=r)}if(i!==null)s.push(i);else{if(s.length>0){const r=this.text_decoder.decode(Uint8Array.from(s));e.push(r),s=[]}e.push(n)}}if(s.length>0){const n=this.text_decoder.decode(Uint8Array.from(s));e.push(n),s=[]}return e}};a(Ou,"ByteFallback");let Jh=Ou;const zu=class zu extends it{decode_chain(t){return[t.join("")]}};a(zu,"FuseDecoder");let Zh=zu;const Su=class Su extends it{constructor(t){super(t),this.content=this.config.content,this.start=this.config.start,this.stop=this.config.stop}decode_chain(t){return t.map(e=>{let s=0;for(let i=0;i<this.start&&e[i]===this.content;++i){s=i+1;continue}let n=e.length;for(let i=0;i<this.stop;++i){const r=e.length-i-1;if(e[r]===this.content){n=r;continue}else break}return e.slice(s,n)})}};a(Su,"StripDecoder");let Qh=Su;const ju=class ju extends it{constructor(t){super(t),this.cleanup=t.cleanup}decode_chain(t){return t.map((e,s)=>(s!==0&&(e.startsWith(this.config.prefix)?e=e.replace(this.config.prefix,""):e=" "+e),this.cleanup&&(e=Ld(e)),e))}};a(ju,"WordPieceDecoder");let Vh=ju;const $u=class $u extends it{constructor(t){super(t),this.byte_decoder=Tb,this.text_decoder=new TextDecoder("utf-8",{fatal:!1,ignoreBOM:!0}),this.end_of_word_suffix=null}convert_tokens_to_string(t){const e=t.join(""),s=new Uint8Array([...e].map(i=>this.byte_decoder[i]));return this.text_decoder.decode(s)}decode_chain(t){const e=[];let s=[];for(const n of t)this.added_tokens.find(i=>i.content===n)!==void 0?(s.length>0&&(e.push(this.convert_tokens_to_string(s)),s=[]),e.push(n)):s.push(n);return s.length>0&&e.push(this.convert_tokens_to_string(s)),e}};a($u,"ByteLevelDecoder");let Mh=$u;const Ru=class Ru extends it{constructor(t){super(t),this.pad_token=this.config.pad_token,this.word_delimiter_token=this.config.word_delimiter_token,this.cleanup=this.config.cleanup}convert_tokens_to_string(t){if(t.length===0)return"";const e=[t[0]];for(let i=1;i<t.length;++i)t[i]!==e.at(-1)&&e.push(t[i]);let n=e.filter(i=>i!==this.pad_token).join("");return this.cleanup&&(n=Ld(n).replaceAll(this.word_delimiter_token," ").trim()),n}decode_chain(t){return[this.convert_tokens_to_string(t)]}};a(Ru,"CTCDecoder");let Fh=Ru;const Uu=class Uu extends it{constructor(t){super(t),this.decoders=t.decoders.map(e=>it.fromConfig(e))}decode_chain(t){return this.decoders.reduce((e,s)=>s.decode_chain(e),t)}};a(Uu,"DecoderSequence");let Th=Uu;const Du=class Du extends it{constructor(t){super(t),this.suffix=this.config.suffix}decode_chain(t){return t.map((e,s)=>e.replaceAll(this.suffix,s===t.length-1?"":" "))}};a(Du,"BPEDecoder");let Ph=Du;const Lu=class Lu extends it{decode_chain(t){let e="";for(let s=1;s<t.length;s+=2)e+=t[s];return[e]}};a(Lu,"VitsDecoder");let td=Lu;const Gu=class Gu extends at{constructor(t){super(),this.addPrefixSpace=t.add_prefix_space,this.replacement=t.replacement,this.strRep=t.str_rep||this.replacement,this.prepend_scheme=t.prepend_scheme??"always"}pre_tokenize_text(t,{section_index:e=void 0}={}){let s=t.replaceAll(" ",this.strRep);return this.addPrefixSpace&&!s.startsWith(this.replacement)&&(this.prepend_scheme==="always"||this.prepend_scheme==="first"&&e===0)&&(s=this.strRep+s),[s]}};a(Gu,"MetaspacePreTokenizer");let en=Gu;const qu=class qu extends it{constructor(t){super(t),this.addPrefixSpace=t.add_prefix_space,this.replacement=t.replacement}decode_chain(t){const e=[];for(let s=0;s<t.length;++s){let n=t[s].replaceAll(this.replacement," ");this.addPrefixSpace&&s==0&&n.startsWith(" ")&&(n=n.substring(1)),e.push(n)}return e}};a(qu,"MetaspaceDecoder");let ed=qu;const Bu=class Bu extends nt{constructor(t){super(t),this.charsmap=t.precompiled_charsmap}normalize(t){return t=t.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm,""),t=t.replace(/[\u0009\u000A\u000C\u000D\u1680\u200B\u200C\u200E\u200F\u2028\u2029\u2581\uFEFF\uFFFD]/gm," "),t.includes("")?t=t.split("").map(s=>s.normalize("NFKC")).join(""):t=t.normalize("NFKC"),t}};a(Bu,"Precompiled");let sd=Bu;const Hu=class Hu extends at{constructor(t){super(),this.tokenizers=t.pretokenizers.map(e=>at.fromConfig(e))}pre_tokenize_text(t,e){return this.tokenizers.reduce((s,n)=>n.pre_tokenize(s,e),[t])}};a(Hu,"PreTokenizerSequence");let nd=Hu;const Xu=class Xu extends at{constructor(t){super()}pre_tokenize_text(t,e){return t.match(/\w+|[^\w\s]+/g)||[]}};a(Xu,"WhitespacePreTokenizer");let id=Xu;const Cu=class Cu extends at{constructor(t){super()}pre_tokenize_text(t,e){return Mb(t)}};a(Cu,"WhitespaceSplit");let ad=Cu;const Ku=class Ku extends at{constructor(t){super(),this.config=t,this.pattern=lh(this.config.pattern),this.content=this.config.content}pre_tokenize_text(t,e){return this.pattern===null?[t]:[t.replaceAll(this.pattern,this.config.content)]}};a(Ku,"ReplacePreTokenizer");let rd=Ku;const Pb=["bos_token","eos_token","unk_token","sep_token","pad_token","cls_token","mask_token"];function tk(o,t,e,s){for(const n of Object.keys(o)){const i=t-o[n].length,r=e(n),l=new Array(i).fill(r);o[n]=s==="right"?et(o[n],l):et(l,o[n])}}a(tk,"padHelper");function ek(o,t){for(const e of Object.keys(o))o[e].length=t}a(ek,"truncateHelper");const Wu=class Wu extends lt{constructor(e,s){super();E(this,"return_token_type_ids",!1);E(this,"_default_chat_template",`{% for message in messages %}{{'<|im_start|>' + message['role'] + '
' + message['content'] + '<|im_end|>' + '
'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant
' }}{% endif %}`);this._tokenizer_config=s,this.normalizer=nt.fromConfig(e.normalizer),this.pre_tokenizer=at.fromConfig(e.pre_tokenizer),this.model=Et.fromConfig(e.model,s),this.post_processor=Nt.fromConfig(e.post_processor),this.decoder=it.fromConfig(e.decoder),this.special_tokens=[],this.all_special_ids=[],this.added_tokens=[];for(const n of e.added_tokens){const i=new vh(n);this.added_tokens.push(i),this.model.tokens_to_ids.set(i.content,i.id),this.model.vocab[i.id]=i.content,i.special&&(this.special_tokens.push(i.content),this.all_special_ids.push(i.id))}if(this.additional_special_tokens=s.additional_special_tokens??[],this.special_tokens.push(...this.additional_special_tokens),this.special_tokens=[...new Set(this.special_tokens)],this.decoder&&(this.decoder.added_tokens=this.added_tokens,this.decoder.end_of_word_suffix=this.model.end_of_word_suffix),this.added_tokens_regex=this.added_tokens.length>0?new RegExp(this.added_tokens.map(n=>`${n.lstrip?"\\s*":""}(${Ix(n.content)})${n.rstrip?"\\s*":""}`).join("|")):null,this.mask_token=this.getToken("mask_token"),this.mask_token_id=this.model.tokens_to_ids.get(this.mask_token),this.pad_token=this.getToken("pad_token","eos_token"),this.pad_token_id=this.model.tokens_to_ids.get(this.pad_token),this.sep_token=this.getToken("sep_token"),this.sep_token_id=this.model.tokens_to_ids.get(this.sep_token),this.unk_token=this.getToken("unk_token"),this.unk_token_id=this.model.tokens_to_ids.get(this.unk_token),this.model_max_length=s.model_max_length,this.remove_space=s.remove_space,this.clean_up_tokenization_spaces=s.clean_up_tokenization_spaces??!0,this.do_lowercase_and_remove_accent=s.do_lowercase_and_remove_accent??!1,this.padding_side="right",this.legacy=!1,this.chat_template=s.chat_template??null,Array.isArray(this.chat_template)){const n=Object.create(null);for(const{name:i,template:r}of this.chat_template){if(typeof i!="string"||typeof r!="string")throw new Error('Chat template must be a list of objects with "name" and "template" properties');n[i]=r}this.chat_template=n}this._compiled_template_cache=new Map}getToken(...e){for(const s of e){const n=this._tokenizer_config[s];if(n)if(typeof n=="object"){if(n.__type==="AddedToken")return n.content;throw Error(`Unknown token: ${n}`)}else return n}return null}static async from_pretrained(e,{progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:l="main",legacy:c=null}={}){const h=await Yx(e,{progress_callback:s,cache_dir:i,local_files_only:r,revision:l,legacy:c});return new this(...h)}_call(e,{text_pair:s=null,add_special_tokens:n=!0,padding:i=!1,truncation:r=null,max_length:l=null,return_tensor:c=!0,return_token_type_ids:h=null}={}){const d=Array.isArray(e);let u;if(d){if(e.length===0)throw Error("text array must be non-empty");if(s!==null){if(Array.isArray(s)){if(e.length!==s.length)throw Error("text and text_pair must have the same length")}else throw Error("text_pair must also be an array");u=e.map((_,p)=>this._encode_plus(_,s[p],{add_special_tokens:n,return_token_type_ids:h}))}else u=e.map(_=>this._encode_plus(_,null,{add_special_tokens:n,return_token_type_ids:h}))}else{if(e==null)throw Error("text may not be null or undefined");if(Array.isArray(s))throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");u=[this._encode_plus(e,s,{add_special_tokens:n,return_token_type_ids:h})]}if(l===null?i==="max_length"?l=this.model_max_length:l=ct(u.map(_=>_.input_ids.length))[0]:r||console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=true` to explicitly truncate examples to max length."),l=Math.min(l,this.model_max_length),i||r)for(let _=0;_<u.length;++_)u[_].input_ids.length!==l&&(u[_].input_ids.length>l?r&&ek(u[_],l):i&&tk(u[_],l,p=>p==="input_ids"?this.pad_token_id:0,this.padding_side));const f={};if(c){if(!(i&&r)&&u.some(p=>{for(const m of Object.keys(p))if(p[m].length!==u[0][m]?.length)return!0;return!1}))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");const _=[u.length,u[0].input_ids.length];for(const p of Object.keys(u[0]))f[p]=new v("int64",BigInt64Array.from(u.flatMap(m=>m[p]).map(BigInt)),_)}else{for(const _ of Object.keys(u[0]))f[_]=u.map(p=>p[_]);if(!d)for(const _ of Object.keys(f))f[_]=f[_][0]}return f}_encode_text(e){return e===null?null:(this.added_tokens_regex?e.split(this.added_tokens_regex).filter(i=>i):[e]).map((i,r)=>{if(this.added_tokens.find(c=>c.content===i)!==void 0)return i;{if(this.remove_space===!0&&(i=i.trim().split(/\s+/).join(" ")),this.do_lowercase_and_remove_accent&&(i=Qb(i)),this.normalizer!==null&&(i=this.normalizer(i)),i.length===0)return[];const c=this.pre_tokenizer!==null?this.pre_tokenizer(i,{section_index:r}):[i];return this.model(c)}}).flat()}_encode_plus(e,s=null,{add_special_tokens:n=!0,return_token_type_ids:i=null}={}){const r=this._encode_text(e),l=this._encode_text(s),c=this.post_processor?this.post_processor(r,l,{add_special_tokens:n}):{tokens:et(r??[],l??[])},h=this.model.convert_tokens_to_ids(c.tokens),d={input_ids:h,attention_mask:new Array(h.length).fill(1)};return(i??this.return_token_type_ids)&&c.token_type_ids&&(d.token_type_ids=c.token_type_ids),d}encode(e,s=null,{add_special_tokens:n=!0,return_token_type_ids:i=null}={}){const{input_ids:r}=this._encode_plus(e,s,{add_special_tokens:n,return_token_type_ids:i});return r}batch_decode(e,s={}){return e instanceof v&&(e=e.tolist()),e.map(n=>this.decode(n,s))}decode(e,s={}){if(e instanceof v&&(e=Jx(e)),!Array.isArray(e)||e.length===0||!Ox(e[0]))throw Error("token_ids must be a non-empty array of integers.");return this.decode_single(e,s)}decode_single(e,{skip_special_tokens:s=!1,clean_up_tokenization_spaces:n=null}){let i=this.model.convert_ids_to_tokens(e);s&&(i=i.filter(l=>!this.special_tokens.includes(l)));let r=this.decoder?this.decoder(i):i.join(" ");return this.decoder&&this.decoder.end_of_word_suffix&&(r=r.replaceAll(this.decoder.end_of_word_suffix," "),s&&(r=r.trim())),(n??this.clean_up_tokenization_spaces)&&(r=Ld(r)),r}get default_chat_template(){return this._warned_about_chat_template||(console.warn("No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information."),this._warned_about_chat_template=!0),this._default_chat_template}apply_chat_template(e,{chat_template:s=null,add_generation_prompt:n=!1,tokenize:i=!0,padding:r=!1,truncation:l=!1,max_length:c=null,return_tensor:h=!0,tokenizer_kwargs:d={},...u}={}){if(this.chat_template&&typeof this.chat_template=="object"||this.chat_template===null&&this.default_chat_template&&typeof this.default_chat_template=="object"){const m=this.chat_template??this.default_chat_template;if(s!==null&&Object.hasOwn(m,s))s=m[s];else if(s===null&&"default"in m)s=m.default;else if(s===null)throw Error(`This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(m).sort()}.`)}else s??(s=this.chat_template??this.default_chat_template);if(typeof s!="string")throw Error(`chat_template must be a string, but got ${typeof s}`);let f=this._compiled_template_cache.get(s);f===void 0&&(f=new zb(s),this._compiled_template_cache.set(s,f));const _=Object.create(null);for(const m of Pb){const g=this.getToken(m);g&&(_[m]=g)}const p=f.render({messages:e,add_generation_prompt:n,..._,...u});return i?this._call(p,{add_special_tokens:!1,padding:r,truncation:l,max_length:c,return_tensor:h,...d}).input_ids:p}};a(Wu,"PreTrainedTokenizer");let O=Wu;const Yu=class Yu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Yu,"BertTokenizer");let sn=Yu;const Ju=class Ju extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Ju,"AlbertTokenizer");let nn=Ju;const Zu=class Zu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Zu,"MobileBertTokenizer");let an=Zu;const Qu=class Qu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Qu,"SqueezeBertTokenizer");let rn=Qu;const Vu=class Vu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Vu,"DebertaTokenizer");let on=Vu;const Mu=class Mu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Mu,"DebertaV2Tokenizer");let ln=Mu;const Fu=class Fu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Fu,"HerbertTokenizer");let cn=Fu;const Tu=class Tu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Tu,"ConvBertTokenizer");let hn=Tu;const Pu=class Pu extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(Pu,"RoFormerTokenizer");let dn=Pu;const t_=class t_ extends O{};a(t_,"DistilBertTokenizer");let un=t_;const e_=class e_ extends O{};a(e_,"CamembertTokenizer");let _n=e_;const s_=class s_ extends O{constructor(e,s){super(e,s);E(this,"return_token_type_ids",!0);console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}};a(s_,"XLMTokenizer");let fn=s_;const n_=class n_ extends O{constructor(){super(...arguments);E(this,"return_token_type_ids",!0)}};a(n_,"ElectraTokenizer");let pn=n_;const i_=class i_ extends O{};a(i_,"T5Tokenizer");let mn=i_;const a_=class a_ extends O{constructor(){super(...arguments);E(this,"_default_chat_template",'{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}')}};a(a_,"GPT2Tokenizer");let ze=a_;const r_=class r_ extends O{};a(r_,"BartTokenizer");let gn=r_;const o_=class o_ extends O{constructor(t,e){super(t,e),this.languageRegex=/^[a-z]{2}_[A-Z]{2}$/,this.language_codes=this.special_tokens.filter(s=>this.languageRegex.test(s)),this.lang_to_token=s=>s}_build_translation_inputs(t,e,s){return Gd(this,t,e,s)}};a(o_,"MBartTokenizer");let Se=o_;const l_=class l_ extends Se{};a(l_,"MBart50Tokenizer");let wn=l_;const c_=class c_ extends O{};a(c_,"RobertaTokenizer");let yn=c_;const h_=class h_ extends ze{constructor(t,e){const s=".,!?",n=t.pre_tokenizer?.pretokenizers[0]?.pattern;n&&n.Regex===` ?[^(\\s|[${s}])]+`&&(n.Regex=` ?[^\\s${s}]+`),super(t,e)}};a(h_,"BloomTokenizer");let xn=h_;const Cs="",d_=class d_ extends O{constructor(e,s){super(e,s);E(this,"_default_chat_template",`{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>
' + system_message + '
<</SYS>>

' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>
' + content.strip() + '
<</SYS>>

' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}`);E(this,"DEFAULT_SYSTEM_PROMPT",`You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.`);this.use_default_system_prompt=s.use_default_system_prompt??!1,this.legacy=s.legacy??!0,this.legacy||(this.normalizer=null,this.pre_tokenizer=new en({replacement:Cs,add_prefix_space:!0,prepend_scheme:"first"}))}_encode_text(e){if(e===null)return null;if(this.legacy||e.length===0)return super._encode_text(e);let s=super._encode_text(Cs+e.replaceAll(Cs," "));return s.length>1&&s[0]===Cs&&this.special_tokens.includes(s[1])&&(s=s.slice(1)),s}get default_chat_template(){return super.default_chat_template.replaceAll("USE_DEFAULT_PROMPT",this.use_default_system_prompt?"true":"false").replaceAll("DEFAULT_SYSTEM_MESSAGE",this.DEFAULT_SYSTEM_PROMPT.replaceAll(`
`,"\\n").replaceAll("'","\\'"))}};a(d_,"LlamaTokenizer");let je=d_;const u_=class u_ extends je{};a(u_,"CodeLlamaTokenizer");let bn=u_;const __=class __ extends O{};a(__,"XLMRobertaTokenizer");let kn=__;const f_=class f_ extends O{};a(f_,"MPNetTokenizer");let vn=f_;const p_=class p_ extends O{};a(p_,"FalconTokenizer");let An=p_;const m_=class m_ extends O{};a(m_,"GPTNeoXTokenizer");let En=m_;const g_=class g_ extends O{};a(g_,"EsmTokenizer");let Nn=g_;const w_=class w_ extends O{};a(w_,"Qwen2Tokenizer");let In=w_;const y_=class y_ extends O{constructor(){super(...arguments);E(this,"_default_chat_template",`{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '
' + message['content'] | trim + '<end_of_turn>
' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model
'}}{% endif %}`)}};a(y_,"GemmaTokenizer");let On=y_;const x_=class x_ extends O{};a(x_,"Grok1Tokenizer");let zn=x_;function Gd(o,t,e,s){if(!("language_codes"in o)||!Array.isArray(o.language_codes))throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");if(!("languageRegex"in o)||!(o.languageRegex instanceof RegExp))throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");if(!("lang_to_token"in o)||typeof o.lang_to_token!="function")throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");const n=s.src_lang,i=s.tgt_lang;if(!o.language_codes.includes(i))throw new Error(`Target language code "${i}" is not valid. Must be one of: {${o.language_codes.join(", ")}}`);if(n!==void 0){if(!o.language_codes.includes(n))throw new Error(`Source language code "${n}" is not valid. Must be one of: {${o.language_codes.join(", ")}}`);for(const r of o.post_processor.config.single)if("SpecialToken"in r&&o.languageRegex.test(r.SpecialToken.id)){r.SpecialToken.id=o.lang_to_token(n);break}}return s.forced_bos_token_id=o.model.convert_tokens_to_ids([o.lang_to_token(i)])[0],o._call(t,e)}a(Gd,"_build_translation_inputs");const b_=class b_ extends O{constructor(t,e){super(t,e),this.languageRegex=/^[a-z]{3}_[A-Z][a-z]{3}$/,this.language_codes=this.special_tokens.filter(s=>this.languageRegex.test(s)),this.lang_to_token=s=>s}_build_translation_inputs(t,e,s){return Gd(this,t,e,s)}};a(b_,"NllbTokenizer");let Sn=b_;const k_=class k_ extends O{constructor(t,e){super(t,e),this.languageRegex=/^__[a-z]{2,3}__$/,this.language_codes=this.special_tokens.filter(s=>this.languageRegex.test(s)).map(s=>s.slice(2,-2)),this.lang_to_token=s=>`__${s}__`}_build_translation_inputs(t,e,s){return Gd(this,t,e,s)}};a(k_,"M2M100Tokenizer");let jn=k_;const Vx=[["en","english"],["zh","chinese"],["de","german"],["es","spanish"],["ru","russian"],["ko","korean"],["fr","french"],["ja","japanese"],["pt","portuguese"],["tr","turkish"],["pl","polish"],["ca","catalan"],["nl","dutch"],["ar","arabic"],["sv","swedish"],["it","italian"],["id","indonesian"],["hi","hindi"],["fi","finnish"],["vi","vietnamese"],["he","hebrew"],["uk","ukrainian"],["el","greek"],["ms","malay"],["cs","czech"],["ro","romanian"],["da","danish"],["hu","hungarian"],["ta","tamil"],["no","norwegian"],["th","thai"],["ur","urdu"],["hr","croatian"],["bg","bulgarian"],["lt","lithuanian"],["la","latin"],["mi","maori"],["ml","malayalam"],["cy","welsh"],["sk","slovak"],["te","telugu"],["fa","persian"],["lv","latvian"],["bn","bengali"],["sr","serbian"],["az","azerbaijani"],["sl","slovenian"],["kn","kannada"],["et","estonian"],["mk","macedonian"],["br","breton"],["eu","basque"],["is","icelandic"],["hy","armenian"],["ne","nepali"],["mn","mongolian"],["bs","bosnian"],["kk","kazakh"],["sq","albanian"],["sw","swahili"],["gl","galician"],["mr","marathi"],["pa","punjabi"],["si","sinhala"],["km","khmer"],["sn","shona"],["yo","yoruba"],["so","somali"],["af","afrikaans"],["oc","occitan"],["ka","georgian"],["be","belarusian"],["tg","tajik"],["sd","sindhi"],["gu","gujarati"],["am","amharic"],["yi","yiddish"],["lo","lao"],["uz","uzbek"],["fo","faroese"],["ht","haitian creole"],["ps","pashto"],["tk","turkmen"],["nn","nynorsk"],["mt","maltese"],["sa","sanskrit"],["lb","luxembourgish"],["my","myanmar"],["bo","tibetan"],["tl","tagalog"],["mg","malagasy"],["as","assamese"],["tt","tatar"],["haw","hawaiian"],["ln","lingala"],["ha","hausa"],["ba","bashkir"],["jw","javanese"],["su","sundanese"]],Ks=new Map(Vx),sk=new Map([...Vx.map(([o,t])=>[t,o]),["burmese","my"],["valencian","ca"],["flemish","nl"],["haitian","ht"],["letzeburgesch","lb"],["pushto","ps"],["panjabi","pa"],["moldavian","ro"],["moldovan","ro"],["sinhalese","si"],["castilian","es"]]),v_=class v_ extends O{constructor(){super(...arguments);E(this,"_default_chat_template",'{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}')}_decode_asr(e,{return_timestamps:s=!1,return_language:n=!1,time_precision:i=null,force_full_sequences:r=!0}={}){if(i===null)throw Error("Must specify time_precision");let l=null;const c=s==="word";function h(){return{language:l,timestamp:[null,null],text:""}}a(h,"new_chunk");const d=[];let u=h(),f=0;const _=this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0]+1;let p=[],m=[],g=!1,w=null;const y=new Set(this.all_special_ids);for(const b of e){const N=b.tokens,I=c?b.token_timestamps:null;let $=null,G=_;if("stride"in b){const[q,U,D]=b.stride;if(f-=U,w=q-D,U&&(G=U/i+_),D)for(let X=N.length-1;X>=0;--X){const R=N[X];if(R>=_){if($!==null&&(R-_)*i<w)break;$=R}}}let L=[],Y=[];for(let q=0;q<N.length;++q){const U=N[q];if(y.has(U)){const D=this.decode([U]),X=Ks.get(D.slice(2,-2));if(X!==void 0){if(l!==null&&X!==l&&!s){p.push(L);const R=this.findLongestCommonSequence(p)[0],B=this.decode(R);u.text=B,d.push(u),p=[],L=[],u=h()}l=u.language=X}}else if(U>=_){const D=(U-_)*i+f,X=Tt(D,2);if($!==null&&U>=$)g=!0;else if(g||p.length>0&&U<G)g=!1;else if(u.timestamp[0]===null)u.timestamp[0]=X;else if(X!==u.timestamp[0]){u.timestamp[1]=X,p.push(L),c&&m.push(Y);const[R,B]=this.findLongestCommonSequence(p,m),K=this.decode(R);u.text=K,c&&(u.words=this.collateWordTimestamps(R,B,l)),d.push(u),p=[],L=[],m=[],Y=[],u=h()}}else if(L.push(U),c){let D=Tt(I[q]+f,2),X;q+1<I.length?X=Tt(I[q+1]+f,2):X=null,Y.push([D,X])}}if("stride"in b){const[q,U,D]=b.stride;f+=q-D}L.length>0?(p.push(L),c&&m.push(Y)):p.every(q=>q.length===0)&&(u=h(),p=[],L=[],m=[],Y=[])}if(p.length>0){if(r&&s)throw new Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");const[b,N]=this.findLongestCommonSequence(p,m),I=this.decode(b);u.text=I,c&&(u.words=this.collateWordTimestamps(b,N,l)),d.push(u)}let k=Object.create(null);const A=d.map(b=>b.text).join("");if(s||n){for(let b=0;b<d.length;++b){const N=d[b];s||delete N.timestamp,n||delete N.language}if(c){const b=[];for(const N of d)for(const I of N.words)b.push(I);k={chunks:b}}else k={chunks:d}}return[A,k]}findLongestCommonSequence(e,s=null){let n=e[0],i=n.length,r=[];const l=Array.isArray(s)&&s.length>0;let c=l?[]:null,h=l?s[0]:null;for(let d=1;d<e.length;++d){const u=e[d];let f=0,_=[i,i,0,0];const p=u.length;for(let b=1;b<i+p;++b){const N=b/1e4,I=Math.max(0,i-b),$=Math.min(i,i+p-b),G=n.slice(I,$),L=Math.max(0,b-i),Y=Math.min(p,b),q=u.slice(L,Y);if(G.length!==q.length)throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");const U=G.filter((X,R)=>X===q[R]).length,D=U/b+N;U>1&&D>f&&(f=D,_=[I,$,L,Y])}const[m,g,w,y]=_,k=Math.floor((g+m)/2),A=Math.floor((y+w)/2);r.push(...n.slice(0,k)),n=u.slice(A),i=n.length,l&&(c.push(...h.slice(0,k)),h=s[d].slice(A))}return r.push(...n),l?(c.push(...h),[r,c]):[r,[]]}collateWordTimestamps(e,s,n){const[i,r,l]=this.combineTokensIntoWords(e,n),c=[];for(let h=0;h<i.length;++h){const d=l[h];c.push({text:i[h],timestamp:[s[d.at(0)][0],s[d.at(-1)][1]]})}return c}combineTokensIntoWords(e,s,n=`"'([{-`,i=`"'.,!?:)]}`){s=s??"english";let r,l,c;return["chinese","japanese","thai","lao","myanmar"].includes(s)?[r,l,c]=this.splitTokensOnUnicode(e):[r,l,c]=this.splitTokensOnSpaces(e),this.mergePunctuations(r,l,c,n,i)}decode(e,s){let n;return s&&s.decode_with_timestamps?(e instanceof v&&(e=Jx(e)),n=this.decodeWithTimestamps(e,s)):n=super.decode(e,s),n}decodeWithTimestamps(e,s){const n=s?.time_precision??.02,i=Array.from(this.all_special_ids).at(-1)+1;let r=[[]];for(const l of e)if(l>=i){const c=Tt((l-i)*n,2);r.push(`<|${c}|>`),r.push([])}else r[r.length-1].push(l);return r=r.map(l=>typeof l=="string"?l:super.decode(l,s)),r.join("")}splitTokensOnUnicode(e){const s=this.decode(e,{decode_with_timestamps:!0}),n="",i=[],r=[],l=[];let c=[],h=[],d=0;for(let u=0;u<e.length;++u){const f=e[u];c.push(f),h.push(u);const _=this.decode(c,{decode_with_timestamps:!0});(!_.includes(n)||s[d+_.indexOf(n)]===n)&&(i.push(_),r.push(c),l.push(h),c=[],h=[],d+=_.length)}return[i,r,l]}splitTokensOnSpaces(e){const[s,n,i]=this.splitTokensOnUnicode(e),r=[],l=[],c=[],h=new RegExp(`^[${Oe}]$`,"gu");for(let d=0;d<s.length;++d){const u=s[d],f=n[d],_=i[d],p=f[0]>=this.model.tokens_to_ids.get("<|endoftext|>"),m=u.startsWith(" "),g=u.trim(),w=h.test(g);if(p||m||w||r.length===0)r.push(u),l.push(f),c.push(_);else{const y=r.length-1;r[y]+=u,l[y].push(...f),c[y].push(..._)}}return[r,l,c]}mergePunctuations(e,s,n,i,r){const l=structuredClone(e),c=structuredClone(s),h=structuredClone(n);let d=l.length-2,u=l.length-1;for(;d>=0;)l[d].startsWith(" ")&&i.includes(l[d].trim())?(l[u]=l[d]+l[u],c[u]=et(c[d],c[u]),h[u]=et(h[d],h[u]),l[d]="",c[d]=[],h[d]=[]):u=d,--d;for(d=0,u=1;u<l.length;)!l[d].endsWith(" ")&&r.includes(l[u])?(l[d]+=l[u],c[d]=et(c[d],c[u]),h[d]=et(h[d],h[u]),l[u]="",c[u]=[],h[u]=[]):d=u,++u;return[l.filter(f=>f),c.filter(f=>f.length>0),h.filter(f=>f.length>0)]}get_decoder_prompt_ids({language:e=null,task:s=null,no_timestamps:n=!0}={}){const i=[];if(e){e=e.toLowerCase();let r=sk.get(e);if(r===void 0)if(Ks.has(e))r=e;else{const h=e.length===2?Ks.keys():Ks.values();throw new Error(`Language "${e}" is not supported. Must be one of: ${JSON.stringify(h)}`)}const l=this.model.tokens_to_ids.get(`<|${r}|>`);if(l===void 0)throw new Error(`Unable to find language "${r}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);i.push(l)}else i.push(null);if(s){if(s=s.toLowerCase(),s!=="transcribe"&&s!=="translate")throw new Error(`Task "${s}" is not supported. Must be one of: ["transcribe", "translate"]`);const r=this.model.tokens_to_ids.get(`<|${s}|>`);if(r===void 0)throw new Error(`Unable to find task "${s}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`);i.push(r)}else i.push(null);if(n){const r=this.model.tokens_to_ids.get("<|notimestamps|>");if(r===void 0)throw new Error('Unable to find "<|notimestamps|>" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.');i.push(r)}return i.map((r,l)=>[l+1,r]).filter(r=>r[1]!==null)}};a(v_,"WhisperTokenizer");let $n=v_;const A_=class A_ extends O{};a(A_,"CodeGenTokenizer");let Rn=A_;const E_=class E_ extends O{};a(E_,"CLIPTokenizer");let Un=E_;const N_=class N_ extends O{};a(N_,"SiglipTokenizer");let Dn=N_;const I_=class I_ extends O{constructor(t,e){super(t,e),this.languageRegex=/^(>>\w+<<)\s*/g,this.supported_language_codes=this.model.vocab.filter(s=>this.languageRegex.test(s)),console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}_encode_text(t){if(t===null)return null;const[e,...s]=t.trim().split(this.languageRegex);if(s.length===0)return super._encode_text(e);if(s.length===2){const[n,i]=s;return this.supported_language_codes.includes(n)||console.warn(`Unsupported language code "${n}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`),et([n],super._encode_text(i))}}};a(I_,"MarianTokenizer");let Ln=I_;const O_=class O_ extends O{};a(O_,"Wav2Vec2CTCTokenizer");let Gn=O_;const z_=class z_ extends O{constructor(){super(...arguments);E(this,"_default_chat_template","{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}")}};a(z_,"BlenderbotTokenizer");let $e=z_;const S_=class S_ extends $e{};a(S_,"BlenderbotSmallTokenizer");let qn=S_;const j_=class j_ extends O{};a(j_,"SpeechT5Tokenizer");let Bn=j_;const $_=class $_ extends O{};a($_,"NougatTokenizer");let Hn=$_;const R_=class R_ extends O{constructor(t,e){super(t,e),this.decoder=new td({})}};a(R_,"VitsTokenizer");let Xn=R_;const U_=class U_ extends O{};a(U_,"CohereTokenizer");let Cn=U_;const Uc=class Uc{static async from_pretrained(t,{quantized:e=!0,progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:l="main",legacy:c=null}={}){const[h,d]=await Yx(t,{progress_callback:s,cache_dir:i,local_files_only:r,revision:l,legacy:c}),u=d.tokenizer_class?.replace(/Fast$/,"")??"PreTrainedTokenizer";let f=this.TOKENIZER_CLASS_MAPPING[u];return f||(console.warn(`Unknown tokenizer class "${u}", attempting to construct from base class.`),f=O),new f(h,d)}};a(Uc,"AutoTokenizer"),E(Uc,"TOKENIZER_CLASS_MAPPING",{T5Tokenizer:mn,DistilBertTokenizer:un,CamembertTokenizer:_n,DebertaTokenizer:on,DebertaV2Tokenizer:ln,BertTokenizer:sn,HerbertTokenizer:cn,ConvBertTokenizer:hn,RoFormerTokenizer:dn,XLMTokenizer:fn,ElectraTokenizer:pn,MobileBertTokenizer:an,SqueezeBertTokenizer:rn,AlbertTokenizer:nn,GPT2Tokenizer:ze,BartTokenizer:gn,MBartTokenizer:Se,MBart50Tokenizer:wn,RobertaTokenizer:yn,WhisperTokenizer:$n,CodeGenTokenizer:Rn,CLIPTokenizer:Un,SiglipTokenizer:Dn,MarianTokenizer:Ln,BloomTokenizer:xn,NllbTokenizer:Sn,M2M100Tokenizer:jn,LlamaTokenizer:je,CodeLlamaTokenizer:bn,XLMRobertaTokenizer:kn,MPNetTokenizer:vn,FalconTokenizer:An,GPTNeoXTokenizer:En,EsmTokenizer:Nn,Wav2Vec2CTCTokenizer:Gn,BlenderbotTokenizer:$e,BlenderbotSmallTokenizer:qn,SpeechT5Tokenizer:Bn,NougatTokenizer:Hn,VitsTokenizer:Xn,Qwen2Tokenizer:In,GemmaTokenizer:On,Grok1Tokenizer:zn,CohereTokenizer:Cn,PreTrainedTokenizer:O});let Z=Uc;typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});async function nk(o,t){return await se(o,"config.json",!0,t)}a(nk,"loadConfig");const D_=class D_{constructor(t){this.model_type=null,this.is_encoder_decoder=!1,Object.assign(this,t)}static async from_pretrained(t,{progress_callback:e=null,config:s=null,cache_dir:n=null,local_files_only:i=!1,revision:r="main"}={}){let l=s??await nk(t,{progress_callback:e,cache_dir:n,local_files_only:i,revision:r});return new this(l)}};a(D_,"PretrainedConfig");let Kn=D_;const L_=class L_{static async from_pretrained(...t){return Kn.from_pretrained(...t)}};a(L_,"AutoConfig");let gt=L_;typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});const G_=class G_ extends lt{constructor(){super(),this.processors=[]}push(t){this.processors.push(t)}extend(t){this.processors.push(...t)}_call(t,e){for(let s of e)this.processors.forEach(n=>n(t,s))}[Symbol.iterator](){return this.processors.values()}};a(G_,"LogitsProcessorList");let Wn=G_;const q_=class q_ extends lt{_call(t,e){throw Error("`_call` should be implemented in a subclass")}};a(q_,"LogitsProcessor");let ht=q_;const B_=class B_ extends ht{constructor(t){super(),this.force_token_map=Object.fromEntries(t??[])}_call(t,e){let s=this.force_token_map[t.length];return Rb(s)&&(e.data.fill(-1/0),e.data[s]=0),e}};a(B_,"ForceTokensLogitsProcessor");let od=B_;const H_=class H_ extends ht{constructor(t){super(),this.bos_token_id=t}_call(t,e){return t.length===1&&(e.data.fill(-1/0),e.data[this.bos_token_id]=0),e}};a(H_,"ForcedBOSTokenLogitsProcessor");let ld=H_;const X_=class X_ extends ht{constructor(t,e){super(),this.max_length=t,this.forced_eos_token_id=e}_call(t,e){}};a(X_,"ForcedEOSTokenLogitsProcessor");let cd=X_;const C_=class C_ extends ht{constructor(t,e){super(),this.begin_suppress_tokens=t,this.begin_index=e}_call(t,e){if(t.length===this.begin_index)for(let s of this.begin_suppress_tokens)e.data[s]=-1/0;return e}};a(C_,"SuppressTokensAtBeginLogitsProcessor");let hd=C_;const K_=class K_ extends ht{constructor(t){super(),this.eos_token_id=t.eos_token_id,this.no_timestamps_token_id=t.no_timestamps_token_id,this.timestamp_begin=this.no_timestamps_token_id+1,this.begin_index=(t.forced_decoder_ids||[]).length+2,t.forced_decoder_ids.slice(-1)[0][1]===this.no_timestamps_token_id&&(this.begin_index-=1),this.max_initial_timestamp_index=t.max_initial_timestamp_index}_call(t,e){const s=e.data;if(s[this.no_timestamps_token_id]=-1/0,t.length===this.begin_index-1)return s.fill(-1/0),s[this.timestamp_begin]=0,e;const n=t.slice(this.begin_index),i=n.length>=1&&n[n.length-1]>=this.timestamp_begin,r=n.length<2||n[n.length-2]>=this.timestamp_begin;if(i&&(r?s.subarray(this.timestamp_begin).fill(-1/0):s.subarray(0,this.eos_token_id).fill(-1/0)),t.length===this.begin_index&&this.max_initial_timestamp_index!==null){const d=this.timestamp_begin+this.max_initial_timestamp_index;s.subarray(d+1).fill(-1/0)}const l=Ux(s),c=Math.log(l.subarray(this.timestamp_begin).map(Math.exp).reduce((d,u)=>d+u)),h=ct(l.subarray(0,this.timestamp_begin))[0];return c>h&&s.subarray(0,this.timestamp_begin).fill(-1/0),e}};a(K_,"WhisperTimeStampLogitsProcessor");let dd=K_;const W_=class W_ extends ht{constructor(t){super(),this.no_repeat_ngram_size=t}getNgrams(t){const e=t.length,s=[];for(let i=0;i<e+1-this.no_repeat_ngram_size;++i){const r=[];for(let l=0;l<this.no_repeat_ngram_size;++l)r.push(t[i+l]);s.push(r)}const n=new Map;for(const i of s){const r=i.slice(0,i.length-1),l=JSON.stringify(r),c=n.get(l)??[];c.push(i[i.length-1]),n.set(l,c)}return n}getGeneratedNgrams(t,e){const s=e.slice(e.length+1-this.no_repeat_ngram_size,e.length);return t.get(JSON.stringify(s))??[]}calcBannedNgramTokens(t){const e=[];if(t.length+1<this.no_repeat_ngram_size)return e;{const s=this.getNgrams(t);return this.getGeneratedNgrams(s,t)}}_call(t,e){const s=this.calcBannedNgramTokens(t);for(const n of s)e.data[n]=-1/0;return e}};a(W_,"NoRepeatNGramLogitsProcessor");let ud=W_;const Y_=class Y_ extends ht{constructor(t){super(),this.penalty=t}_call(t,e){for(const s of t)e.data[s]<0?e.data[s]*=this.penalty:e.data[s]/=this.penalty;return e}};a(Y_,"RepetitionPenaltyLogitsProcessor");let _d=Y_;const J_=class J_ extends ht{constructor(t,e){super(),this.min_length=t,this.eos_token_id=Array.isArray(e)?e:[e]}_call(t,e){if(t.length<this.min_length)for(const s of this.eos_token_id)e.data[s]=-1/0;return e}};a(J_,"MinLengthLogitsProcessor");let fd=J_;const Z_=class Z_ extends ht{constructor(t,e,s){super(),this.prompt_length_to_skip=t,this.min_new_tokens=e,this.eos_token_id=Array.isArray(s)?s:[s]}_call(t,e){if(t.length-this.prompt_length_to_skip<this.min_new_tokens)for(const n of this.eos_token_id)e.data[n]=-1/0;return e}};a(Z_,"MinNewTokensLengthLogitsProcessor");let pd=Z_;const Q_=class Q_ extends ht{constructor(t,e){super(),this.bad_words_ids=t,this.eos_token_id=Array.isArray(e)?e:[e]}_call(t,e){for(const s of this.bad_words_ids){let n=!0;for(let i=1;i<=s.length-1&&s.length<t.length;++i)if(s.at(-i-1)!==t.at(-i)){n=!1;break}n&&(e.data[s.at(-1)]=-1/0)}return e}};a(Q_,"NoBadWordsLogitsProcessor");let md=Q_;var ee;const ik=(ee=class{constructor(t={}){this.max_length=t.max_length??20,this.max_new_tokens=t.max_new_tokens??null,this.min_length=t.min_length??0,this.min_new_tokens=t.min_new_tokens??null,this.early_stopping=t.early_stopping??!1,this.max_time=t.max_time??null,this.do_sample=t.do_sample??!1,this.num_beams=t.num_beams??1,this.num_beam_groups=t.num_beam_groups??1,this.penalty_alpha=t.penalty_alpha??null,this.use_cache=t.use_cache??!0,this.temperature=t.temperature??1,this.top_k=t.top_k??50,this.top_p=t.top_p??1,this.typical_p=t.typical_p??1,this.epsilon_cutoff=t.epsilon_cutoff??0,this.eta_cutoff=t.eta_cutoff??0,this.diversity_penalty=t.diversity_penalty??0,this.repetition_penalty=t.repetition_penalty??1,this.encoder_repetition_penalty=t.encoder_repetition_penalty??1,this.length_penalty=t.length_penalty??1,this.no_repeat_ngram_size=t.no_repeat_ngram_size??0,this.bad_words_ids=t.bad_words_ids??null,this.force_words_ids=t.force_words_ids??null,this.renormalize_logits=t.renormalize_logits??!1,this.constraints=t.constraints??null,this.forced_bos_token_id=t.forced_bos_token_id??null,this.forced_eos_token_id=t.forced_eos_token_id??null,this.remove_invalid_values=t.remove_invalid_values??!1,this.exponential_decay_length_penalty=t.exponential_decay_length_penalty??null,this.suppress_tokens=t.suppress_tokens??null,this.begin_suppress_tokens=t.begin_suppress_tokens??null,this.forced_decoder_ids=t.forced_decoder_ids??null,this.num_return_sequences=t.num_return_sequences??1,this.output_attentions=t.output_attentions??!1,this.output_hidden_states=t.output_hidden_states??!1,this.output_scores=t.output_scores??!1,this.return_dict_in_generate=t.return_dict_in_generate??!1,this.pad_token_id=t.pad_token_id??null,this.bos_token_id=t.bos_token_id??null,this.eos_token_id=t.eos_token_id??null,this.encoder_no_repeat_ngram_size=t.encoder_no_repeat_ngram_size??0,this.decoder_start_token_id=t.decoder_start_token_id??null,this.generation_kwargs=t.generation_kwargs??{}}},a(ee,"GenerationConfig"),ee),V_=class V_ extends lt{constructor(t){super(),this.generation_config=t}_call(t,e=-1){return this.sample(t,e)}sample(t,e){throw Error("sample should be implemented in subclasses.")}getLogits(t,e){let s=t.dims.at(-1),n=t.data;if(e===-1)n=n.slice(-s);else{let i=e*s;n=n.slice(i,i+s)}return this.generation_config.temperature>0&&(n=n.map(i=>i/this.generation_config.temperature)),n}randomSelect(t){let e=t.reduce((n,i)=>n+i,0),s=Math.random()*e;for(let n=0;n<t.length;++n)if(s-=t[n],s<=0)return n;return 0}static getSampler(t){if(t.do_sample)return new wd(t);if(t.num_beams>1)return new yd(t);if(t.num_return_sequences>1)throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${t.num_return_sequences}.`);return new gd(t)}};a(V_,"Sampler");let ie=V_;const M_=class M_ extends ie{sample(t,e=-1){let s=this.getLogits(t,e);return[[ct(s)[1],0]]}};a(M_,"GreedySampler");let gd=M_;const F_=class F_ extends ie{sample(t,e=-1){let s=t.dims.at(-1);this.generation_config.top_k>0&&(s=Math.min(this.generation_config.top_k,s));const n=this.getLogits(t,e),i=Qt(n,s),r=st(i.map(l=>l[1]));return Array.from({length:this.generation_config.num_beams},()=>{const l=this.randomSelect(r);return[i[l][0],Math.log(r[l])]})}};a(F_,"MultinomialSampler");let wd=F_;const T_=class T_ extends ie{sample(t,e=-1){let s=t.dims.at(-1);this.generation_config.top_k>0&&(s=Math.min(this.generation_config.top_k,s));const n=this.getLogits(t,e),i=Qt(n,s),r=st(i.map(l=>l[1]));return Array.from({length:this.generation_config.num_beams},(l,c)=>[i[c][0],Math.log(r[c])])}};a(T_,"BeamSearchSampler");let yd=T_;const{InferenceSession:xd,Tensor:ak,env:rk}=typeof _t<"u"&&_t?_t:{env:{},InferenceSession:null,Tensor:null},z={EncoderOnly:0,EncoderDecoder:1,Seq2Seq:2,Vision2Seq:3,DecoderOnly:4,MaskGeneration:5},Yn=new Map,Mx=new Map,Ae=new Map;async function bt(o,t,e){let s=`onnx/${t}${e.quantized?"_quantized":""}.onnx`,n=await jx(o,s,!0,e);try{return await xd.create(n,{executionProviders:Ws})}catch(i){if(Ws.length===1&&Ws[0]==="wasm")throw i;return console.warn(i),console.warn("Something went wrong during model construction (most likely a missing operation). Using `wasm` as a fallback. "),await xd.create(n,{executionProviders:["wasm"]})}}a(bt,"constructSession");function ok(o,t){const e=Object.create(null),s=[];for(const r of o.inputNames){const l=t[r];if(!(l instanceof v)){s.push(r);continue}e[r]=rk.wasm.proxy?l.clone():l}if(s.length>0)throw new Error(`An error occurred during model execution: "Missing the following inputs: ${s.join(", ")}.`);const n=Object.keys(t).length,i=o.inputNames.length;if(n>i){let r=Object.keys(t).filter(l=>!o.inputNames.includes(l));console.warn(`WARNING: Too many inputs were provided (${n} > ${i}). The following inputs will be ignored: "${r.join(", ")}".`)}return e}a(ok,"validateInputs");async function ae(o,t){const e=ok(o,t);try{let s=await o.run(e);return s=Fx(s),s}catch(s){throw console.error(`An error occurred during model execution: "${s}".`),console.error("Inputs given to model:",e),s}}a(ae,"sessionRun");function Fx(o){for(let t in o)o[t]instanceof ak?o[t]=new v(o[t]):typeof o[t]=="object"&&Fx(o[t]);return o}a(Fx,"replaceTensors");function lk(o){if(o instanceof v)return o;if(o.length===0)throw Error("items must be non-empty");if(Array.isArray(o[0])){if(o.some(t=>t.length!==o[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new v("int64",BigInt64Array.from(o.flat().map(t=>BigInt(t))),[o.length,o[0].length])}else return new v("int64",BigInt64Array.from(o.map(t=>BigInt(t))),[1,o.length])}a(lk,"toI64Tensor");function qd(o,t){let e=o.config.pad_token_id??null,s=o.config.eos_token_id??null;Ox(s)&&(s=[s]);let n=t.indexOf(e)!==-1,i=s===null||!s.includes(e);if(n&&i){let r=BigInt64Array.from(t.data.map(l=>l!=e));return new v("int64",r,t.dims)}else return Kx(t)}a(qd,"prepareAttentionMask");function Tx(o,t,e){if(!o.inputNames.includes("position_ids"))return;const s=new BigInt64Array(t.attention_mask.data.length);for(let n=0;n<t.attention_mask.dims[0];++n){let i=n*t.attention_mask.dims[1],r=BigInt(0);for(let l=0;l<t.attention_mask.dims[1];++l){const c=i+l;t.attention_mask.data[c]===0n?s[c]=BigInt(1):(s[c]=r,r+=t.attention_mask.data[c])}}t.position_ids=new v("int64",s,t.attention_mask.dims),e&&(t.position_ids=t.position_ids.slice(null,-1).unsqueeze_(-1))}a(Tx,"preparePositionIds");function Bd(o){return new v("bool",[o],[1])}a(Bd,"boolTensor");async function ck(o,t){let{encoder_outputs:e,past_key_values:s}=t;e||(e=(await Re(o,t)).last_hidden_state);let n={input_ids:t.decoder_input_ids,encoder_hidden_states:e};const i=!!s;o.decoder_merged_session.inputNames.includes("use_cache_branch")&&(n.use_cache_branch=Bd(i)),o.decoder_merged_session.inputNames.includes("encoder_attention_mask")&&(n.encoder_attention_mask=t.attention_mask),Tx(o.decoder_merged_session,n,i),o.addPastKeyValues(n,s);const r=await ae(o.decoder_merged_session,n);let l=r.logits;s=o.getPastKeyValues(r,s);const c=o.getAttentions(r);return new Nl({logits:l,past_key_values:s,encoder_outputs:e,...c})}a(ck,"seq2seqForward");function hk(o,t,e,s){let n=[],i=0;const r=o.requires_attention_mask??!0;let l=e.decoder_input_ids??e.decoder_start_token_id??e.bos_token_id??e.eos_token_id;l instanceof v?l=l.tolist().flat():Array.isArray(l)||(l=[l]);for(let c of t){c.dims=[1,...c.dims];let h={inputs:c,encoder_outputs:null,prev_model_outputs:null,output_token_ids:l,done:!1,score:0,id:i++};r&&(h.attention_mask=qd(o,c)),n.push(h)}return n}a(hk,"seq2seqStartBeams");async function dk(o,t){const e=o.main_input_name;let s=t.output_token_ids;t.prev_model_outputs&&(s=s.slice(-1));let n={[e]:t.inputs,decoder_input_ids:lk(s),encoder_outputs:t.encoder_outputs,past_key_values:t.prev_model_outputs?.past_key_values};t.attention_mask&&(n.attention_mask=t.attention_mask);let i=await o.forward(n);return t.prev_model_outputs=i,t.encoder_outputs=i.encoder_outputs,i}a(dk,"seq2seqRunBeam");function uk(o,t){o.output_token_ids=[...o.output_token_ids,t]}a(uk,"seq2seqUpdatebeam");async function Re(o,t){const e=Object.create(null);for(const s of o.session.inputNames)e[s]=t[s];return o.session.inputNames.includes("token_type_ids")&&!e.token_type_ids&&(e.token_type_ids=new v("int64",new BigInt64Array(e.input_ids.data.length),e.input_ids.dims)),await ae(o.session,e)}a(Re,"encoderForward");async function _k(o,t){let{input_ids:e,past_key_values:s,attention_mask:n}=t,i={input_ids:e,attention_mask:n??qd(o,e)};const r=!!s;o.session.inputNames.includes("use_cache_branch")&&(i.use_cache_branch=Bd(r)),Tx(o.session,i,r),o.addPastKeyValues(i,s);let l=await ae(o.session,i),c=l.logits;return s=o.getPastKeyValues(l,s),{logits:c,past_key_values:s}}a(_k,"decoderForward");function fk(o,t,e,s,n){let i=[],r=0;for(let l of t){let c=l.tolist().map(Number);l.dims=[1,...l.dims];let h;n?(h=n[r],h.dims=[1,...h.dims]):h=qd(o,l);let d={input:l,model_input_ids:l,attention_mask:h,prev_model_outputs:null,output_token_ids:c,num_output_tokens:s,done:!1,score:0,id:r++};i.push(d)}return i}a(fk,"decoderStartBeams");async function pk(o,t){let e=new BigInt64Array(t.output_token_ids.length).fill(1n),s={input_ids:t.model_input_ids,attention_mask:new v("int64",e,[1,e.length]),past_key_values:t.prev_model_outputs?.past_key_values},n=await o.forward(s);return t.prev_model_outputs=n,n}a(pk,"decoderRunBeam");function mk(o,t){o.output_token_ids=[...o.output_token_ids,t],o.model_input_ids=new v("int64",[BigInt(t)],[1,1])}a(mk,"decoderUpdatebeam");const P_=class P_ extends lt{constructor(e,s){super();E(this,"main_input_name","input_ids");this.config=e,this.session=s;const n=Ae.get(this.constructor),i=Yn.get(n);this.can_generate=!1,this._runBeam=null,this._getStartBeams=null,this._updateBeam=null,this._forward=null,i===z.DecoderOnly?(this.can_generate=!0,this._runBeam=pk,this._getStartBeams=fk,this._updateBeam=mk,this._forward=_k):i===z.Seq2Seq||i===z.Vision2Seq?(this.can_generate=!0,this._runBeam=dk,this._getStartBeams=hk,this._updateBeam=uk,this._forward=ck):i===z.EncoderDecoder?this._forward=Re:this._forward=Re}async dispose(){const e=[];for(let s of Object.keys(this)){const n=this[s];n instanceof xd&&e.push(n.handler.dispose())}return await Promise.all(e)}static async from_pretrained(e,{quantized:s=!0,progress_callback:n=null,config:i=null,cache_dir:r=null,local_files_only:l=!1,revision:c="main",model_file_name:h=null}={}){let d={quantized:s,progress_callback:n,config:i,cache_dir:r,local_files_only:l,revision:c,model_file_name:h};const u=Ae.get(this),f=Yn.get(u);let _;return f===z.DecoderOnly?_=await Promise.all([gt.from_pretrained(e,d),bt(e,d.model_file_name??"decoder_model_merged",d),se(e,"generation_config.json",!1,d)]):f===z.Seq2Seq||f===z.Vision2Seq?_=await Promise.all([gt.from_pretrained(e,d),bt(e,"encoder_model",d),bt(e,"decoder_model_merged",d),se(e,"generation_config.json",!1,d)]):f===z.MaskGeneration?_=await Promise.all([gt.from_pretrained(e,d),bt(e,"vision_encoder",d),bt(e,"prompt_encoder_mask_decoder",d)]):f===z.EncoderDecoder?_=await Promise.all([gt.from_pretrained(e,d),bt(e,"encoder_model",d),bt(e,"decoder_model_merged",d)]):(f!==z.EncoderOnly&&console.warn(`Model type for '${u??i?.model_type}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`),_=await Promise.all([gt.from_pretrained(e,d),bt(e,d.model_file_name??"model",d)])),new this(..._)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}_get_logits_processor(e,s,n=null){const i=new Wn;if(e.repetition_penalty!==null&&e.repetition_penalty!==1&&i.push(new _d(e.repetition_penalty)),e.no_repeat_ngram_size!==null&&e.no_repeat_ngram_size>0&&i.push(new ud(e.no_repeat_ngram_size)),e.bad_words_ids!==null&&i.push(new md(e.bad_words_ids,e.eos_token_id)),e.min_length!==null&&e.eos_token_id!==null&&e.min_length>0&&i.push(new fd(e.min_length,e.eos_token_id)),e.min_new_tokens!==null&&e.eos_token_id!==null&&e.min_new_tokens>0&&i.push(new pd(s,e.min_new_tokens,e.eos_token_id)),e.forced_bos_token_id!==null&&i.push(new ld(e.forced_bos_token_id)),e.forced_eos_token_id!==null&&i.push(new cd(e.max_length,e.forced_eos_token_id)),e.begin_suppress_tokens!==null){let r=s>1||e.forced_bos_token_id===null?s:s+1;e.forced_decoder_ids!==null&&(r+=e.forced_decoder_ids[e.forced_decoder_ids.length-1][0]),i.push(new hd(e.begin_suppress_tokens,r))}return e.forced_decoder_ids!==null&&i.push(new od(e.forced_decoder_ids)),n!==null&&i.extend(n),i}_get_generation_config(e){let s=new ik(this.config);return"generation_config"in this&&Object.assign(s,this.generation_config),e!==null&&Object.assign(s,e),s}async generate(e,s=null,n=null,{inputs_attention_mask:i=null}={}){if(!this.can_generate){let w=`The current model class (${Ae.get(this.constructor)}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;const y=this.config.model_type,k=ch.get(y)??Xd.get(y)??Hd.get(y)??Cd.get(y);throw k&&(w+=` Please use the following class instead: '${k[0]}'`),Error(w)}if(!(e instanceof v)&&!$b(e)&&!Array.isArray(e))throw Error(`\`inputs\` must be a Tensor, TypedArray, or Array, but is "${e.constructor.name}".`);let r;if(this.config.is_encoder_decoder)r=0;else if(r=e instanceof v?e.dims.at(-1):e.length,r===0)throw Error("Must supply a non-empty array of input token ids.");s=this._get_generation_config(s),n=n??new Wn,n=this._get_logits_processor(s,r,n);let l=s.eos_token_id;l!==null&&!Array.isArray(l)&&(l=[l]);let c=1;const h=c+(s.max_new_tokens??1/0),d=Number.isInteger(s.max_length)&&(s.max_new_tokens??null)===null;let u=ie.getSampler(s),f=this.getStartBeams(e,s,c,i);for(;f.some(g=>!g.done)&&c<h;){let g=[];for(let w of f){if(w.done){g.push(w);continue}if(d&&w.output_token_ids.length>=s.max_length){w.done=!0,g.push(w);continue}let y=await this.runBeam(w);s.output_attentions&&this.addAttentionsToBeam(w,y),s.output_scores;let k=y.logits.slice(null,-1,null);n(w.output_token_ids,k);let A=u(k);for(let[b,N]of A){let I={...w};this.updateBeam(I,b),I.score+=N,l&&l.includes(b)&&(I.done=!0),g.push(I)}}++c,g=this.groupBeams(g).map(w=>w.sort((y,k)=>k.score-y.score).slice(0,s.num_beams)),f=g.flat(),s.callback_function&&s.callback_function(f)}const _=this.groupBeams(f),p=a(g=>_.map(w=>s.num_return_sequences>1?w.slice(0,s.num_return_sequences).map(y=>y[g]):[w[0][g]]).flat(),"getFlattened"),m=p("output_token_ids");if(s.return_dict_in_generate){const g=p("decoder_attentions"),w=p("cross_attentions");return{sequences:m,decoder_attentions:g,cross_attentions:w}}else return m}addAttentionsToBeam(e,s){if(this.config.is_encoder_decoder){if(!s.cross_attentions||s.cross_attentions.length===0)throw Error("`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.cross_attentions||(e.cross_attentions=[]),e.cross_attentions.push(s.cross_attentions)}if(!s.decoder_attentions||s.decoder_attentions.length===0)throw Error("`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.decoder_attentions||(e.decoder_attentions=[]),e.decoder_attentions.push(s.decoder_attentions)}groupBeams(e){const s=Object.create(null);for(const n of e)s[n.id]===void 0?s[n.id]=[n]:s[n.id].push(n);return Object.values(s)}getPastKeyValues(e,s){const n=Object.create(null);for(const i in e)if(i.startsWith("present")){let r=i.replace("present","past_key_values");s&&i.includes("encoder")?n[r]=s[r]:n[r]=e[i]}return n}getAttentions(e){const s=Object.create(null);for(const n of["cross_attentions","decoder_attentions"]){const i=[];for(const r in e)if(r.startsWith(n)){const l=r.split(".").pop();i[l]=e[r]}s[n]=i}return s}addPastKeyValues(e,s){if(s)Object.assign(e,s);else if(this.config.is_encoder_decoder&&(this.add_encoder_pkv??!0)){let i=[1,this.num_encoder_heads,0,this.encoder_dim_kv],r=[1,this.num_decoder_heads,0,this.decoder_dim_kv];for(let l=0;l<this.num_decoder_layers;++l)e[`past_key_values.${l}.encoder.key`]=new v("float32",[],i),e[`past_key_values.${l}.encoder.value`]=new v("float32",[],i),e[`past_key_values.${l}.decoder.key`]=new v("float32",[],r),e[`past_key_values.${l}.decoder.value`]=new v("float32",[],r)}else if(this.config.model_type==="falcon"){let i=[1*this.num_heads,0,this.dim_kv];for(let r=0;r<this.num_layers;++r)e[`past_key_values.${r}.key`]=new v("float32",[],i),e[`past_key_values.${r}.value`]=new v("float32",[],i)}else if(this.config.multi_query){let i=[1*this.num_heads,0,2*this.dim_kv];for(let r=0;r<this.num_layers;++r)e[`past_key_values.${r}.key_value`]=new v("float32",[],i)}else if(this.config.model_type==="bloom"){let i=[1*this.num_heads,this.dim_kv,0],r=[1*this.num_heads,0,this.dim_kv];for(let l=0;l<this.num_layers;++l)e[`past_key_values.${l}.key`]=new v("float32",[],i),e[`past_key_values.${l}.value`]=new v("float32",[],r)}else{let i=[1,this.num_heads,0,this.dim_kv];for(let r=0;r<this.num_layers;++r)e[`past_key_values.${r}.key`]=new v("float32",[],i),e[`past_key_values.${r}.value`]=new v("float32",[],i)}}getStartBeams(e,s,n,i){return this._getStartBeams(this,e,s,n,i)}async runBeam(e){return await this._runBeam(this,e)}updateBeam(e,s){return this._updateBeam(e,s)}};a(P_,"PreTrainedModel");let x=P_;const tf=class tf{};a(tf,"ModelOutput");let T=tf;const ef=class ef extends T{constructor({last_hidden_state:t,hidden_states:e=null,attentions:s=null}){super(),this.last_hidden_state=t,this.hidden_states=e,this.attentions=s}};a(ef,"BaseModelOutput");let bd=ef;const sf=class sf extends x{};a(sf,"BertPreTrainedModel");let It=sf;const nf=class nf extends It{};a(nf,"BertModel");let Jn=nf;const af=class af extends It{async _call(t){return new M(await super._call(t))}};a(af,"BertForMaskedLM");let Zn=af;const rf=class rf extends It{async _call(t){return new j(await super._call(t))}};a(rf,"BertForSequenceClassification");let Qn=rf;const of=class of extends It{async _call(t){return new V(await super._call(t))}};a(of,"BertForTokenClassification");let Vn=of;const lf=class lf extends It{async _call(t){return new P(await super._call(t))}};a(lf,"BertForQuestionAnswering");let Mn=lf;const cf=class cf extends x{};a(cf,"NomicBertPreTrainedModel");let Fn=cf;const hf=class hf extends Fn{};a(hf,"NomicBertModel");let Tn=hf;const df=class df extends x{};a(df,"RoFormerPreTrainedModel");let Ot=df;const uf=class uf extends Ot{};a(uf,"RoFormerModel");let Pn=uf;const _f=class _f extends Ot{async _call(t){return new M(await super._call(t))}};a(_f,"RoFormerForMaskedLM");let ti=_f;const ff=class ff extends Ot{async _call(t){return new j(await super._call(t))}};a(ff,"RoFormerForSequenceClassification");let ei=ff;const pf=class pf extends Ot{async _call(t){return new V(await super._call(t))}};a(pf,"RoFormerForTokenClassification");let si=pf;const mf=class mf extends Ot{async _call(t){return new P(await super._call(t))}};a(mf,"RoFormerForQuestionAnswering");let ni=mf;const gf=class gf extends x{};a(gf,"ConvBertPreTrainedModel");let zt=gf;const wf=class wf extends zt{};a(wf,"ConvBertModel");let ii=wf;const yf=class yf extends zt{async _call(t){return new M(await super._call(t))}};a(yf,"ConvBertForMaskedLM");let ai=yf;const xf=class xf extends zt{async _call(t){return new j(await super._call(t))}};a(xf,"ConvBertForSequenceClassification");let ri=xf;const bf=class bf extends zt{async _call(t){return new V(await super._call(t))}};a(bf,"ConvBertForTokenClassification");let oi=bf;const kf=class kf extends zt{async _call(t){return new P(await super._call(t))}};a(kf,"ConvBertForQuestionAnswering");let li=kf;const vf=class vf extends x{};a(vf,"ElectraPreTrainedModel");let St=vf;const Af=class Af extends St{};a(Af,"ElectraModel");let ci=Af;const Ef=class Ef extends St{async _call(t){return new M(await super._call(t))}};a(Ef,"ElectraForMaskedLM");let hi=Ef;const Nf=class Nf extends St{async _call(t){return new j(await super._call(t))}};a(Nf,"ElectraForSequenceClassification");let di=Nf;const If=class If extends St{async _call(t){return new V(await super._call(t))}};a(If,"ElectraForTokenClassification");let ui=If;const Of=class Of extends St{async _call(t){return new P(await super._call(t))}};a(Of,"ElectraForQuestionAnswering");let _i=Of;const zf=class zf extends x{};a(zf,"CamembertPreTrainedModel");let jt=zf;const Sf=class Sf extends jt{};a(Sf,"CamembertModel");let fi=Sf;const jf=class jf extends jt{async _call(t){return new M(await super._call(t))}};a(jf,"CamembertForMaskedLM");let pi=jf;const $f=class $f extends jt{async _call(t){return new j(await super._call(t))}};a($f,"CamembertForSequenceClassification");let mi=$f;const Rf=class Rf extends jt{async _call(t){return new V(await super._call(t))}};a(Rf,"CamembertForTokenClassification");let gi=Rf;const Uf=class Uf extends jt{async _call(t){return new P(await super._call(t))}};a(Uf,"CamembertForQuestionAnswering");let wi=Uf;const Df=class Df extends x{};a(Df,"DebertaPreTrainedModel");let $t=Df;const Lf=class Lf extends $t{};a(Lf,"DebertaModel");let yi=Lf;const Gf=class Gf extends $t{async _call(t){return new M(await super._call(t))}};a(Gf,"DebertaForMaskedLM");let xi=Gf;const qf=class qf extends $t{async _call(t){return new j(await super._call(t))}};a(qf,"DebertaForSequenceClassification");let bi=qf;const Bf=class Bf extends $t{async _call(t){return new V(await super._call(t))}};a(Bf,"DebertaForTokenClassification");let ki=Bf;const Hf=class Hf extends $t{async _call(t){return new P(await super._call(t))}};a(Hf,"DebertaForQuestionAnswering");let vi=Hf;const Xf=class Xf extends x{};a(Xf,"DebertaV2PreTrainedModel");let Rt=Xf;const Cf=class Cf extends Rt{};a(Cf,"DebertaV2Model");let Ai=Cf;const Kf=class Kf extends Rt{async _call(t){return new M(await super._call(t))}};a(Kf,"DebertaV2ForMaskedLM");let Ei=Kf;const Wf=class Wf extends Rt{async _call(t){return new j(await super._call(t))}};a(Wf,"DebertaV2ForSequenceClassification");let Ni=Wf;const Yf=class Yf extends Rt{async _call(t){return new V(await super._call(t))}};a(Yf,"DebertaV2ForTokenClassification");let Ii=Yf;const Jf=class Jf extends Rt{async _call(t){return new P(await super._call(t))}};a(Jf,"DebertaV2ForQuestionAnswering");let Oi=Jf;const Zf=class Zf extends x{};a(Zf,"DistilBertPreTrainedModel");let Ut=Zf;const Qf=class Qf extends Ut{};a(Qf,"DistilBertModel");let zi=Qf;const Vf=class Vf extends Ut{async _call(t){return new j(await super._call(t))}};a(Vf,"DistilBertForSequenceClassification");let Si=Vf;const Mf=class Mf extends Ut{async _call(t){return new V(await super._call(t))}};a(Mf,"DistilBertForTokenClassification");let ji=Mf;const Ff=class Ff extends Ut{async _call(t){return new P(await super._call(t))}};a(Ff,"DistilBertForQuestionAnswering");let $i=Ff;const Tf=class Tf extends Ut{async _call(t){return new M(await super._call(t))}};a(Tf,"DistilBertForMaskedLM");let Ri=Tf;const Pf=class Pf extends x{};a(Pf,"EsmPreTrainedModel");let Xt=Pf;const tp=class tp extends Xt{};a(tp,"EsmModel");let Ui=tp;const ep=class ep extends Xt{async _call(t){return new M(await super._call(t))}};a(ep,"EsmForMaskedLM");let Di=ep;const sp=class sp extends Xt{async _call(t){return new j(await super._call(t))}};a(sp,"EsmForSequenceClassification");let Li=sp;const np=class np extends Xt{async _call(t){return new V(await super._call(t))}};a(np,"EsmForTokenClassification");let Gi=np;const ip=class ip extends x{};a(ip,"MobileBertPreTrainedModel");let Ct=ip;const ap=class ap extends Ct{};a(ap,"MobileBertModel");let qi=ap;const rp=class rp extends Ct{async _call(t){return new M(await super._call(t))}};a(rp,"MobileBertForMaskedLM");let Bi=rp;const op=class op extends Ct{async _call(t){return new j(await super._call(t))}};a(op,"MobileBertForSequenceClassification");let Hi=op;const lp=class lp extends Ct{async _call(t){return new P(await super._call(t))}};a(lp,"MobileBertForQuestionAnswering");let Xi=lp;const cp=class cp extends x{};a(cp,"MPNetPreTrainedModel");let Dt=cp;const hp=class hp extends Dt{};a(hp,"MPNetModel");let Ci=hp;const dp=class dp extends Dt{async _call(t){return new M(await super._call(t))}};a(dp,"MPNetForMaskedLM");let Ki=dp;const up=class up extends Dt{async _call(t){return new j(await super._call(t))}};a(up,"MPNetForSequenceClassification");let Wi=up;const _p=class _p extends Dt{async _call(t){return new V(await super._call(t))}};a(_p,"MPNetForTokenClassification");let Yi=_p;const fp=class fp extends Dt{async _call(t){return new P(await super._call(t))}};a(fp,"MPNetForQuestionAnswering");let Ji=fp;const pp=class pp extends x{};a(pp,"SqueezeBertPreTrainedModel");let Kt=pp;const mp=class mp extends Kt{};a(mp,"SqueezeBertModel");let Zi=mp;const gp=class gp extends Kt{async _call(t){return new M(await super._call(t))}};a(gp,"SqueezeBertForMaskedLM");let Qi=gp;const wp=class wp extends Kt{async _call(t){return new j(await super._call(t))}};a(wp,"SqueezeBertForSequenceClassification");let Vi=wp;const yp=class yp extends Kt{async _call(t){return new P(await super._call(t))}};a(yp,"SqueezeBertForQuestionAnswering");let Mi=yp;const xp=class xp extends x{};a(xp,"AlbertPreTrainedModel");let Wt=xp;const bp=class bp extends Wt{};a(bp,"AlbertModel");let Fi=bp;const kp=class kp extends Wt{async _call(t){return new j(await super._call(t))}};a(kp,"AlbertForSequenceClassification");let Ti=kp;const vp=class vp extends Wt{async _call(t){return new P(await super._call(t))}};a(vp,"AlbertForQuestionAnswering");let Pi=vp;const Ap=class Ap extends Wt{async _call(t){return new M(await super._call(t))}};a(Ap,"AlbertForMaskedLM");let ta=Ap;const Ep=class Ep extends x{};a(Ep,"T5PreTrainedModel");let Ue=Ep;const Np=class Np extends Ue{};a(Np,"T5Model");let ea=Np;const Ip=class Ip extends Ue{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}};a(Ip,"T5ForConditionalGeneration");let sa=Ip;const Op=class Op extends x{};a(Op,"LongT5PreTrainedModel");let De=Op;const zp=class zp extends De{};a(zp,"LongT5Model");let na=zp;const Sp=class Sp extends De{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}};a(Sp,"LongT5ForConditionalGeneration");let ia=Sp;const jp=class jp extends x{};a(jp,"MT5PreTrainedModel");let Le=jp;const $p=class $p extends Le{};a($p,"MT5Model");let aa=$p;const Rp=class Rp extends Le{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}};a(Rp,"MT5ForConditionalGeneration");let ra=Rp;const Up=class Up extends x{};a(Up,"BartPretrainedModel");let re=Up;const Dp=class Dp extends re{};a(Dp,"BartModel");let oa=Dp;const Lp=class Lp extends re{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Lp,"BartForConditionalGeneration");let la=Lp;const Gp=class Gp extends re{async _call(t){return new j(await super._call(t))}};a(Gp,"BartForSequenceClassification");let ca=Gp;const qp=class qp extends x{};a(qp,"MBartPreTrainedModel");let Yt=qp;const Bp=class Bp extends Yt{};a(Bp,"MBartModel");let ha=Bp;const Hp=class Hp extends Yt{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Hp,"MBartForConditionalGeneration");let da=Hp;const Xp=class Xp extends Yt{async _call(t){return new j(await super._call(t))}};a(Xp,"MBartForSequenceClassification");let ua=Xp;const Cp=class Cp extends Yt{constructor(t,e,s){super(t,e),this.generation_config=s,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Cp,"MBartForCausalLM");let _a=Cp;const Kp=class Kp extends x{};a(Kp,"BlenderbotPreTrainedModel");let Ge=Kp;const Wp=class Wp extends Ge{};a(Wp,"BlenderbotModel");let fa=Wp;const Yp=class Yp extends Ge{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Yp,"BlenderbotForConditionalGeneration");let pa=Yp;const Jp=class Jp extends x{};a(Jp,"BlenderbotSmallPreTrainedModel");let qe=Jp;const Zp=class Zp extends qe{};a(Zp,"BlenderbotSmallModel");let ma=Zp;const Qp=class Qp extends qe{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Qp,"BlenderbotSmallForConditionalGeneration");let ga=Qp;const Vp=class Vp extends x{};a(Vp,"RobertaPreTrainedModel");let Lt=Vp;const Mp=class Mp extends Lt{};a(Mp,"RobertaModel");let wa=Mp;const Fp=class Fp extends Lt{async _call(t){return new M(await super._call(t))}};a(Fp,"RobertaForMaskedLM");let ya=Fp;const Tp=class Tp extends Lt{async _call(t){return new j(await super._call(t))}};a(Tp,"RobertaForSequenceClassification");let xa=Tp;const Pp=class Pp extends Lt{async _call(t){return new V(await super._call(t))}};a(Pp,"RobertaForTokenClassification");let ba=Pp;const tm=class tm extends Lt{async _call(t){return new P(await super._call(t))}};a(tm,"RobertaForQuestionAnswering");let ka=tm;const em=class em extends x{};a(em,"XLMPreTrainedModel");let Gt=em;const sm=class sm extends Gt{};a(sm,"XLMModel");let va=sm;const nm=class nm extends Gt{async _call(t){return new M(await super._call(t))}};a(nm,"XLMWithLMHeadModel");let Aa=nm;const im=class im extends Gt{async _call(t){return new j(await super._call(t))}};a(im,"XLMForSequenceClassification");let Ea=im;const am=class am extends Gt{async _call(t){return new V(await super._call(t))}};a(am,"XLMForTokenClassification");let Na=am;const rm=class rm extends Gt{async _call(t){return new P(await super._call(t))}};a(rm,"XLMForQuestionAnswering");let Ia=rm;const om=class om extends x{};a(om,"XLMRobertaPreTrainedModel");let qt=om;const lm=class lm extends qt{};a(lm,"XLMRobertaModel");let Oa=lm;const cm=class cm extends qt{async _call(t){return new M(await super._call(t))}};a(cm,"XLMRobertaForMaskedLM");let za=cm;const hm=class hm extends qt{async _call(t){return new j(await super._call(t))}};a(hm,"XLMRobertaForSequenceClassification");let Sa=hm;const dm=class dm extends qt{async _call(t){return new V(await super._call(t))}};a(dm,"XLMRobertaForTokenClassification");let ja=dm;const um=class um extends qt{async _call(t){return new P(await super._call(t))}};a(um,"XLMRobertaForQuestionAnswering");let $a=um;const _m=class _m extends x{};a(_m,"ASTPreTrainedModel");let Be=_m;const fm=class fm extends Be{};a(fm,"ASTModel");let Ra=fm;const pm=class pm extends Be{};a(pm,"ASTForAudioClassification");let Ua=pm;const mm=class mm extends x{};a(mm,"WhisperPreTrainedModel");let He=mm;const gm=class gm extends He{};a(gm,"WhisperModel");let Da=gm;const wm=class wm extends He{constructor(e,s,n,i){super(e,s);E(this,"requires_attention_mask",!1);E(this,"main_input_name","input_features");this.decoder_merged_session=n,this.generation_config=i,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}async generate(e,s=null,n=null){if(s=this._get_generation_config(s),s.return_timestamps??(s.return_timestamps=!1),s.return_timestamps&&(n=[new dd(s)]),s.return_token_timestamps&&(s.output_attentions=!0,s.return_dict_in_generate=!0,s.task==="translate"&&console.warn("Token-level timestamps may not be reliable for task 'translate'."),!s.alignment_heads))throw new Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");const i=await super.generate(e,s,n);return s.return_token_timestamps&&s.alignment_heads&&(i.token_timestamps=this._extract_token_timestamps(i,s.alignment_heads,s.num_frames)),i}_extract_token_timestamps(e,s,n=null,i=.02){if(!e.cross_attentions)throw new Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");let r=this.config.median_filter_width;r===void 0&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),r=7);const l=e.cross_attentions.map(d=>{let u=Array.from({length:this.config.decoder_layers},(w,y)=>Ls(d.map(k=>k[y]),2)),f=Gs(s.map(([w,y])=>n?u[w].slice(null,y,null,[0,n]):u[w].slice(null,y)));f=f.transpose(1,0,2,3);let[_,p]=Rd(f,-2,0,!0),m=f.clone();for(let w=0;w<m.dims[0];++w){let y=m[w];for(let k=0;k<y.dims[0];++k){let A=y[k];const b=_[w][k][0],N=p[w][k][0];for(let I=0;I<A.dims[0];++I){let $=A[I];for(let G=0;G<$.data.length;++G)$.data[G]=($.data[G]-N.data[G])/b.data[G];$.data.set(Gx($.data,r))}}}return Ud(m,1)}),c=[e.sequences.length,e.sequences[0].length],h=new v("float32",new Float32Array(c[0]*c[1]),c);for(let d=0;d<c[0];++d){const u=l[d].neg().squeeze_(0);let[f,_]=Xx(u),p=Array.from({length:f.length-1},(w,y)=>f[y+1]-f[y]),m=et([1],p).map(w=>!!w),g=[];for(let w=0;w<m.length;++w)m[w]&&g.push(_[w]*i);h[d].data.set(g,1)}return h}};a(wm,"WhisperForConditionalGeneration");let La=wm;const ym=class ym extends x{constructor(e,s,n,i){super(e,s);E(this,"main_input_name","pixel_values");this.decoder_merged_session=n,this.generation_config=i;const r=this.config.encoder,l=this.config.decoder,c=r.model_type;(Px.get(c)??tb.get(c))||console.warn(`Model type for encoder '${c}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);const d=ch.get(l.model_type);if(!d)throw new Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`);const u=d[1],f=new u(l,n,i);this.add_encoder_pkv="num_decoder_layers"in f,this.add_encoder_pkv?(this.num_decoder_layers=f.num_decoder_layers,this.num_decoder_heads=f.num_decoder_heads,this.decoder_dim_kv=f.decoder_dim_kv,this.num_encoder_layers=f.num_encoder_layers,this.num_encoder_heads=f.num_encoder_heads,this.encoder_dim_kv=f.encoder_dim_kv):(this.num_layers=f.num_layers,this.num_heads=f.num_heads,this.dim_kv=f.dim_kv)}};a(ym,"VisionEncoderDecoderModel");let Xe=ym;const xm=class xm extends x{};a(xm,"CLIPPreTrainedModel");let Jt=xm;const bm=class bm extends Jt{};a(bm,"CLIPModel");let Ga=bm;const km=class km extends Jt{static async from_pretrained(t,e={}){return e.model_file_name??(e.model_file_name="text_model"),super.from_pretrained(t,e)}};a(km,"CLIPTextModelWithProjection");let qa=km;const vm=class vm extends Jt{static async from_pretrained(t,e={}){return e.model_file_name??(e.model_file_name="vision_model"),super.from_pretrained(t,e)}};a(vm,"CLIPVisionModelWithProjection");let Ba=vm;const Am=class Am extends x{};a(Am,"SiglipPreTrainedModel");let Ce=Am;const Em=class Em extends Ce{};a(Em,"SiglipModel");let Ha=Em;const Nm=class Nm extends Ce{static async from_pretrained(t,e={}){return e.model_file_name??(e.model_file_name="text_model"),super.from_pretrained(t,e)}};a(Nm,"SiglipTextModel");let Xa=Nm;const Im=class Im extends Jt{static async from_pretrained(t,e={}){return e.model_file_name??(e.model_file_name="vision_model"),super.from_pretrained(t,e)}};a(Im,"SiglipVisionModel");let Ca=Im;const Om=class Om extends x{};a(Om,"ChineseCLIPPreTrainedModel");let Ka=Om;const zm=class zm extends Ka{};a(zm,"ChineseCLIPModel");let Wa=zm;const Sm=class Sm extends x{};a(Sm,"CLIPSegPreTrainedModel");let Ke=Sm;const jm=class jm extends Ke{};a(jm,"CLIPSegModel");let Ya=jm;const $m=class $m extends Ke{};a($m,"CLIPSegForImageSegmentation");let Ja=$m;const Rm=class Rm extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};a(Rm,"GPT2PreTrainedModel");let We=Rm;const Um=class Um extends We{};a(Um,"GPT2Model");let Za=Um;const Dm=class Dm extends We{};a(Dm,"GPT2LMHeadModel");let Qa=Dm;const Lm=class Lm extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_heads,this.num_layers=this.config.num_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};a(Lm,"GPTNeoPreTrainedModel");let Ye=Lm;const Gm=class Gm extends Ye{};a(Gm,"GPTNeoModel");let Va=Gm;const qm=class qm extends Ye{};a(qm,"GPTNeoForCausalLM");let Ma=qm;const Bm=class Bm extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};a(Bm,"GPTNeoXPreTrainedModel");let Je=Bm;const Hm=class Hm extends Je{};a(Hm,"GPTNeoXModel");let Fa=Hm;const Xm=class Xm extends Je{};a(Xm,"GPTNeoXForCausalLM");let Ta=Xm;const Cm=class Cm extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};a(Cm,"GPTJPreTrainedModel");let Ze=Cm;const Km=class Km extends Ze{};a(Km,"GPTJModel");let Pa=Km;const Wm=class Wm extends Ze{};a(Wm,"GPTJForCausalLM");let tr=Wm;const Ym=class Ym extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};a(Ym,"GPTBigCodePreTrainedModel");let Qe=Ym;const Jm=class Jm extends Qe{};a(Jm,"GPTBigCodeModel");let er=Jm;const Zm=class Zm extends Qe{};a(Zm,"GPTBigCodeForCausalLM");let sr=Zm;const Qm=class Qm extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}};a(Qm,"CodeGenPreTrainedModel");let Ve=Qm;const Vm=class Vm extends Ve{};a(Vm,"CodeGenModel");let nr=Vm;const Mm=class Mm extends Ve{};a(Mm,"CodeGenForCausalLM");let ir=Mm;const Fm=class Fm extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}};a(Fm,"LlamaPreTrainedModel");let Me=Fm;const Tm=class Tm extends Me{};a(Tm,"LlamaModel");let ar=Tm;const Pm=class Pm extends Me{};a(Pm,"LlamaForCausalLM");let rr=Pm;const tg=class tg extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}};a(tg,"Qwen2PreTrainedModel");let Fe=tg;const eg=class eg extends Fe{};a(eg,"Qwen2Model");let or=eg;const sg=class sg extends Fe{};a(sg,"Qwen2ForCausalLM");let lr=sg;const ng=class ng extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};a(ng,"PhiPreTrainedModel");let Te=ng;const ig=class ig extends Te{};a(ig,"PhiModel");let cr=ig;const ag=class ag extends Te{};a(ag,"PhiForCausalLM");let hr=ag;const rg=class rg extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.hidden_size/this.num_heads}};a(rg,"BloomPreTrainedModel");let Pe=rg;const og=class og extends Pe{};a(og,"BloomModel");let dr=og;const lg=class lg extends Pe{};a(lg,"BloomForCausalLM");let ur=lg;const cg=class cg extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_heads,this.num_layers=this.config.n_layers,this.dim_kv=this.config.d_model/this.num_heads}};a(cg,"MptPreTrainedModel");let ts=cg;const hg=class hg extends ts{};a(hg,"MptModel");let _r=hg;const dg=class dg extends ts{};a(dg,"MptForCausalLM");let fr=dg;const ug=class ug extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};a(ug,"OPTPreTrainedModel");let es=ug;const _g=class _g extends es{};a(_g,"OPTModel");let pr=_g;const fg=class fg extends es{};a(fg,"OPTForCausalLM");let mr=fg;const pg=class pg extends x{};a(pg,"ViTPreTrainedModel");let ss=pg;const mg=class mg extends ss{};a(mg,"ViTModel");let gr=mg;const gg=class gg extends ss{async _call(t){return new j(await super._call(t))}};a(gg,"ViTForImageClassification");let wr=gg;const wg=class wg extends x{};a(wg,"FastViTPreTrainedModel");let ns=wg;const yg=class yg extends ns{};a(yg,"FastViTModel");let yr=yg;const xg=class xg extends ns{async _call(t){return new j(await super._call(t))}};a(xg,"FastViTForImageClassification");let xr=xg;const bg=class bg extends x{};a(bg,"VitMattePreTrainedModel");let br=bg;const kg=class kg extends br{async _call(t){return new Ol(await super._call(t))}};a(kg,"VitMatteForImageMatting");let kr=kg;const vg=class vg extends x{};a(vg,"MobileViTPreTrainedModel");let is=vg;const Ag=class Ag extends is{};a(Ag,"MobileViTModel");let vr=Ag;const Eg=class Eg extends is{async _call(t){return new j(await super._call(t))}};a(Eg,"MobileViTForImageClassification");let Ar=Eg;const Ng=class Ng extends x{};a(Ng,"MobileViTV2PreTrainedModel");let as=Ng;const Ig=class Ig extends as{};a(Ig,"MobileViTV2Model");let Er=Ig;const Og=class Og extends as{async _call(t){return new j(await super._call(t))}};a(Og,"MobileViTV2ForImageClassification");let Nr=Og;const zg=class zg extends x{};a(zg,"OwlViTPreTrainedModel");let rs=zg;const Sg=class Sg extends rs{};a(Sg,"OwlViTModel");let Ir=Sg;const jg=class jg extends rs{};a(jg,"OwlViTForObjectDetection");let Or=jg;const $g=class $g extends x{};a($g,"Owlv2PreTrainedModel");let os=$g;const Rg=class Rg extends os{};a(Rg,"Owlv2Model");let zr=Rg;const Ug=class Ug extends os{};a(Ug,"Owlv2ForObjectDetection");let Sr=Ug;const Dg=class Dg extends x{};a(Dg,"BeitPreTrainedModel");let ls=Dg;const Lg=class Lg extends ls{};a(Lg,"BeitModel");let jr=Lg;const Gg=class Gg extends ls{async _call(t){return new j(await super._call(t))}};a(Gg,"BeitForImageClassification");let $r=Gg;const qg=class qg extends x{};a(qg,"DetrPreTrainedModel");let oe=qg;const Bg=class Bg extends oe{};a(Bg,"DetrModel");let Rr=Bg;const Hg=class Hg extends oe{async _call(t){return new cs(await super._call(t))}};a(Hg,"DetrForObjectDetection");let Ur=Hg;const Xg=class Xg extends oe{async _call(t){return new Lr(await super._call(t))}};a(Xg,"DetrForSegmentation");let Dr=Xg;const Cg=class Cg extends T{constructor({logits:t,pred_boxes:e}){super(),this.logits=t,this.pred_boxes=e}};a(Cg,"DetrObjectDetectionOutput");let cs=Cg;const Kg=class Kg extends T{constructor({logits:t,pred_boxes:e,pred_masks:s}){super(),this.logits=t,this.pred_boxes=e,this.pred_masks=s}};a(Kg,"DetrSegmentationOutput");let Lr=Kg;const Wg=class Wg extends x{};a(Wg,"TableTransformerPreTrainedModel");let hs=Wg;const Yg=class Yg extends hs{};a(Yg,"TableTransformerModel");let Gr=Yg;const Jg=class Jg extends hs{async _call(t){return new Br(await super._call(t))}};a(Jg,"TableTransformerForObjectDetection");let qr=Jg;const Zg=class Zg extends cs{};a(Zg,"TableTransformerObjectDetectionOutput");let Br=Zg;const Qg=class Qg extends x{};a(Qg,"DeiTPreTrainedModel");let ds=Qg;const Vg=class Vg extends ds{};a(Vg,"DeiTModel");let Hr=Vg;const Mg=class Mg extends ds{async _call(t){return new j(await super._call(t))}};a(Mg,"DeiTForImageClassification");let Xr=Mg;const Fg=class Fg extends x{};a(Fg,"ResNetPreTrainedModel");let us=Fg;const Tg=class Tg extends us{};a(Tg,"ResNetModel");let Cr=Tg;const Pg=class Pg extends us{async _call(t){return new j(await super._call(t))}};a(Pg,"ResNetForImageClassification");let Kr=Pg;const tw=class tw extends x{};a(tw,"SwinPreTrainedModel");let _s=tw;const ew=class ew extends _s{};a(ew,"SwinModel");let Wr=ew;const sw=class sw extends _s{async _call(t){return new j(await super._call(t))}};a(sw,"SwinForImageClassification");let Yr=sw;const nw=class nw extends x{};a(nw,"Swin2SRPreTrainedModel");let fs=nw;const iw=class iw extends fs{};a(iw,"Swin2SRModel");let Jr=iw;const aw=class aw extends fs{};a(aw,"Swin2SRForImageSuperResolution");let Zr=aw;const rw=class rw extends x{};a(rw,"DPTPreTrainedModel");let ps=rw;const ow=class ow extends ps{};a(ow,"DPTModel");let Qr=ow;const lw=class lw extends ps{};a(lw,"DPTForDepthEstimation");let Vr=lw;const cw=class cw extends x{};a(cw,"DepthAnythingPreTrainedModel");let Mr=cw;const hw=class hw extends Mr{};a(hw,"DepthAnythingForDepthEstimation");let Fr=hw;const dw=class dw extends x{};a(dw,"GLPNPreTrainedModel");let ms=dw;const uw=class uw extends ms{};a(uw,"GLPNModel");let Tr=uw;const _w=class _w extends ms{};a(_w,"GLPNForDepthEstimation");let Pr=_w;const fw=class fw extends x{};a(fw,"DonutSwinPreTrainedModel");let to=fw;const pw=class pw extends to{};a(pw,"DonutSwinModel");let eo=pw;const mw=class mw extends x{};a(mw,"ConvNextPreTrainedModel");let gs=mw;const gw=class gw extends gs{};a(gw,"ConvNextModel");let so=gw;const ww=class ww extends gs{async _call(t){return new j(await super._call(t))}};a(ww,"ConvNextForImageClassification");let no=ww;const yw=class yw extends x{};a(yw,"ConvNextV2PreTrainedModel");let ws=yw;const xw=class xw extends ws{};a(xw,"ConvNextV2Model");let io=xw;const bw=class bw extends ws{async _call(t){return new j(await super._call(t))}};a(bw,"ConvNextV2ForImageClassification");let ao=bw;const kw=class kw extends x{};a(kw,"Dinov2PreTrainedModel");let ys=kw;const vw=class vw extends ys{};a(vw,"Dinov2Model");let ro=vw;const Aw=class Aw extends ys{async _call(t){return new j(await super._call(t))}};a(Aw,"Dinov2ForImageClassification");let oo=Aw;const Ew=class Ew extends x{};a(Ew,"YolosPreTrainedModel");let xs=Ew;const Nw=class Nw extends xs{};a(Nw,"YolosModel");let lo=Nw;const Iw=class Iw extends xs{async _call(t){return new ho(await super._call(t))}};a(Iw,"YolosForObjectDetection");let co=Iw;const Ow=class Ow extends T{constructor({logits:t,pred_boxes:e}){super(),this.logits=t,this.pred_boxes=e}};a(Ow,"YolosObjectDetectionOutput");let ho=Ow;const zw=class zw extends x{};a(zw,"SamPreTrainedModel");let uo=zw;const Sw=class Sw extends uo{constructor(t,e,s){super(t,e),this.prompt_encoder_mask_decoder=s}async get_image_embeddings({pixel_values:t}){return await Re(this,{pixel_values:t})}async forward(t){if((!t.image_embeddings||!t.image_positional_embeddings)&&(t={...t,...await this.get_image_embeddings(t)}),!t.input_labels){const e=t.input_points.dims.slice(0,-1),s=e.reduce((n,i)=>n*i,1);t.input_labels=new v("int64",new BigInt64Array(s).fill(1n),e)}return await ae(this.prompt_encoder_mask_decoder,{input_points:t.input_points,input_labels:t.input_labels,image_embeddings:t.image_embeddings,image_positional_embeddings:t.image_positional_embeddings})}async _call(t){return new fo(await super._call(t))}};a(Sw,"SamModel");let _o=Sw;const jw=class jw extends T{constructor({iou_scores:t,pred_masks:e}){super(),this.iou_scores=t,this.pred_masks=e}};a(jw,"SamImageSegmentationOutput");let fo=jw;const $w=class $w extends x{};a($w,"MarianPreTrainedModel");let bs=$w;const Rw=class Rw extends bs{};a(Rw,"MarianModel");let po=Rw;const Uw=class Uw extends bs{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Uw,"MarianMTModel");let mo=Uw;const Dw=class Dw extends x{};a(Dw,"M2M100PreTrainedModel");let ks=Dw;const Lw=class Lw extends ks{};a(Lw,"M2M100Model");let go=Lw;const Gw=class Gw extends ks{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}};a(Gw,"M2M100ForConditionalGeneration");let wo=Gw;const qw=class qw extends x{};a(qw,"Wav2Vec2PreTrainedModel");let ft=qw;const Bw=class Bw extends ft{};a(Bw,"Wav2Vec2Model");let yo=Bw;const Hw=class Hw extends ft{async _call(t){return new wt(await super._call(t))}};a(Hw,"Wav2Vec2ForCTC");let xo=Hw;const Xw=class Xw extends ft{async _call(t){return new j(await super._call(t))}};a(Xw,"Wav2Vec2ForSequenceClassification");let bo=Xw;const Cw=class Cw extends ft{async _call(t){return new V(await super._call(t))}};a(Cw,"Wav2Vec2ForAudioFrameClassification");let ko=Cw;const Kw=class Kw extends x{};a(Kw,"UniSpeechPreTrainedModel");let le=Kw;const Ww=class Ww extends le{};a(Ww,"UniSpeechModel");let vo=Ww;const Yw=class Yw extends le{async _call(t){return new wt(await super._call(t))}};a(Yw,"UniSpeechForCTC");let Ao=Yw;const Jw=class Jw extends le{async _call(t){return new j(await super._call(t))}};a(Jw,"UniSpeechForSequenceClassification");let Eo=Jw;const Zw=class Zw extends x{};a(Zw,"UniSpeechSatPreTrainedModel");let Zt=Zw;const Qw=class Qw extends Zt{};a(Qw,"UniSpeechSatModel");let No=Qw;const Vw=class Vw extends Zt{async _call(t){return new wt(await super._call(t))}};a(Vw,"UniSpeechSatForCTC");let Io=Vw;const Mw=class Mw extends Zt{async _call(t){return new j(await super._call(t))}};a(Mw,"UniSpeechSatForSequenceClassification");let Oo=Mw;const Fw=class Fw extends Zt{async _call(t){return new V(await super._call(t))}};a(Fw,"UniSpeechSatForAudioFrameClassification");let zo=Fw;const Tw=class Tw extends x{};a(Tw,"Wav2Vec2BertPreTrainedModel");let ce=Tw;const Pw=class Pw extends ce{};a(Pw,"Wav2Vec2BertModel");let So=Pw;const ty=class ty extends ce{async _call(t){return new wt(await super._call(t))}};a(ty,"Wav2Vec2BertForCTC");let jo=ty;const ey=class ey extends ce{async _call(t){return new j(await super._call(t))}};a(ey,"Wav2Vec2BertForSequenceClassification");let $o=ey;const sy=class sy extends x{};a(sy,"HubertPreTrainedModel");let kd=sy;const ny=class ny extends ft{};a(ny,"HubertModel");let Ro=ny;const iy=class iy extends ft{async _call(t){return new wt(await super._call(t))}};a(iy,"HubertForCTC");let Uo=iy;const ay=class ay extends ft{async _call(t){return new j(await super._call(t))}};a(ay,"HubertForSequenceClassification");let Do=ay;const ry=class ry extends x{};a(ry,"WavLMPreTrainedModel");let Bt=ry;const oy=class oy extends Bt{};a(oy,"WavLMModel");let Lo=oy;const ly=class ly extends Bt{async _call(t){return new wt(await super._call(t))}};a(ly,"WavLMForCTC");let Go=ly;const cy=class cy extends Bt{async _call(t){return new j(await super._call(t))}};a(cy,"WavLMForSequenceClassification");let qo=cy;const hy=class hy extends Bt{async _call(t){return new Il(await super._call(t))}};a(hy,"WavLMForXVector");let Bo=hy;const dy=class dy extends Bt{async _call(t){return new V(await super._call(t))}};a(dy,"WavLMForAudioFrameClassification");let Ho=dy;const uy=class uy extends x{};a(uy,"SpeechT5PreTrainedModel");let he=uy;const _y=class _y extends he{};a(_y,"SpeechT5Model");let vd=_y;const fy=class fy extends he{};a(fy,"SpeechT5ForSpeechToText");let Xo=fy;const py=class py extends he{constructor(t,e,s,n){super(t,e),this.decoder_merged_session=s,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.hidden_size/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.hidden_size/this.num_encoder_heads}async generate_speech(t,e,{threshold:s=.5,minlenratio:n=0,maxlenratio:i=20,vocoder:r=null}={}){const l={input_ids:t},{encoder_outputs:c,encoder_attention_mask:h}=await Re(this,l),d=c.dims[1]/this.config.reduction_factor,u=Math.floor(d*i),f=Math.floor(d*n),_=this.config.num_mel_bins;let p=[],m=null,g=null,w=0;for(;;){++w;const A=Bd(!!g);let b;g?b=g.output_sequence_out:b=new v("float32",new Float32Array(_),[1,1,_]);let N={use_cache_branch:A,output_sequence:b,encoder_attention_mask:h,speaker_embeddings:e,encoder_hidden_states:c};this.addPastKeyValues(N,m),g=await ae(this.decoder_merged_session,N),m=this.getPastKeyValues(g,m);const{prob:I,spectrum:$}=g;if(p.push($),w>=f&&(Array.from(I.data).filter(G=>G>=s).length>0||w>=u))break}const y=Ls(p),{waveform:k}=await ae(r.session,{spectrogram:y});return{spectrogram:y,waveform:k}}};a(py,"SpeechT5ForTextToSpeech");let Co=py;const my=class my extends x{constructor(){super(...arguments);E(this,"main_input_name","spectrogram")}};a(my,"SpeechT5HifiGan");let Ko=my;const gy=class gy extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_encoder_layers=this.num_decoder_layers=this.config.decoder_layers,this.num_encoder_heads=this.num_decoder_heads=this.config.decoder_attention_heads,this.encoder_dim_kv=this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads}};a(gy,"TrOCRPreTrainedModel");let Wo=gy;const wy=class wy extends Wo{};a(wy,"TrOCRForCausalLM");let Yo=wy;const yy=class yy extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}};a(yy,"MistralPreTrainedModel");let vs=yy;const xy=class xy extends vs{};a(xy,"MistralModel");let Jo=xy;const by=class by extends vs{};a(by,"MistralForCausalLM");let Zo=by;const ky=class ky extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}};a(ky,"Starcoder2PreTrainedModel");let As=ky;const vy=class vy extends As{};a(vy,"Starcoder2Model");let Qo=vy;const Ay=class Ay extends As{};a(Ay,"Starcoder2ForCausalLM");let Vo=Ay;const Ey=class Ey extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}};a(Ey,"FalconPreTrainedModel");let Es=Ey;const Ny=class Ny extends Es{};a(Ny,"FalconModel");let Mo=Ny;const Iy=class Iy extends Es{};a(Iy,"FalconForCausalLM");let Fo=Iy;const Oy=class Oy extends x{};a(Oy,"ClapPreTrainedModel");let de=Oy;const zy=class zy extends de{};a(zy,"ClapModel");let To=zy;const Sy=class Sy extends de{static async from_pretrained(t,e={}){return e.model_file_name??(e.model_file_name="text_model"),super.from_pretrained(t,e)}};a(Sy,"ClapTextModelWithProjection");let Po=Sy;const jy=class jy extends de{static async from_pretrained(t,e={}){return e.model_file_name??(e.model_file_name="audio_model"),super.from_pretrained(t,e)}};a(jy,"ClapAudioModelWithProjection");let tl=jy;const $y=class $y extends x{};a($y,"VitsPreTrainedModel");let el=$y;const Ry=class Ry extends el{async _call(t){return new zl(await super._call(t))}};a(Ry,"VitsModel");let Ns=Ry;const Uy=class Uy extends x{};a(Uy,"SegformerPreTrainedModel");let ue=Uy;const Dy=class Dy extends ue{};a(Dy,"SegformerModel");let Ad=Dy;const Ly=class Ly extends ue{};a(Ly,"SegformerForImageClassification");let sl=Ly;const Gy=class Gy extends ue{};a(Gy,"SegformerForSemanticSegmentation");let nl=Gy;const qy=class qy extends x{constructor(t,e,s){super(t,e),this.generation_config=s,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}};a(qy,"StableLmPreTrainedModel");let Is=qy;const By=class By extends Is{};a(By,"StableLmModel");let Ed=By;const Hy=class Hy extends Is{};a(Hy,"StableLmForCausalLM");let il=Hy;const Xy=class Xy extends x{};a(Xy,"EfficientNetPreTrainedModel");let Os=Xy;const Cy=class Cy extends Os{};a(Cy,"EfficientNetModel");let al=Cy;const Ky=class Ky extends Os{async _call(t){return new j(await super._call(t))}};a(Ky,"EfficientNetForImageClassification");let rl=Ky;const Ee=class Ee{static async from_pretrained(t,{quantized:e=!0,progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:l="main",model_file_name:c=null}={}){let h={quantized:e,progress_callback:s,config:n,cache_dir:i,local_files_only:r,revision:l,model_file_name:c};if(n=await gt.from_pretrained(t,h),h.config||(h.config=n),!this.MODEL_CLASS_MAPPINGS)throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);for(let d of this.MODEL_CLASS_MAPPINGS){const u=d.get(n.model_type);if(u)return await u[1].from_pretrained(t,h)}if(this.BASE_IF_FAIL)return console.warn(`Unknown model class "${n.model_type}", attempting to construct from base class.`),await x.from_pretrained(t,h);throw Error(`Unsupported model type: ${n.model_type}`)}};a(Ee,"PretrainedMixin"),E(Ee,"MODEL_CLASS_MAPPINGS",null),E(Ee,"BASE_IF_FAIL",!1);let H=Ee;const Px=new Map([["bert",["BertModel",Jn]],["nomic_bert",["NomicBertModel",Tn]],["roformer",["RoFormerModel",Pn]],["electra",["ElectraModel",ci]],["esm",["EsmModel",Ui]],["convbert",["ConvBertModel",ii]],["camembert",["CamembertModel",fi]],["deberta",["DebertaModel",yi]],["deberta-v2",["DebertaV2Model",Ai]],["mpnet",["MPNetModel",Ci]],["albert",["AlbertModel",Fi]],["distilbert",["DistilBertModel",zi]],["roberta",["RobertaModel",wa]],["xlm",["XLMModel",va]],["xlm-roberta",["XLMRobertaModel",Oa]],["clap",["ClapModel",To]],["clip",["CLIPModel",Ga]],["clipseg",["CLIPSegModel",Ya]],["chinese_clip",["ChineseCLIPModel",Wa]],["siglip",["SiglipModel",Ha]],["mobilebert",["MobileBertModel",qi]],["squeezebert",["SqueezeBertModel",Zi]],["wav2vec2",["Wav2Vec2Model",yo]],["wav2vec2-bert",["Wav2Vec2BertModel",So]],["unispeech",["UniSpeechModel",vo]],["unispeech-sat",["UniSpeechSatModel",No]],["hubert",["HubertModel",Ro]],["wavlm",["WavLMModel",Lo]],["audio-spectrogram-transformer",["ASTModel",Ra]],["vits",["VitsModel",Ns]],["detr",["DetrModel",Rr]],["table-transformer",["TableTransformerModel",Gr]],["vit",["ViTModel",gr]],["fastvit",["FastViTModel",yr]],["mobilevit",["MobileViTModel",vr]],["mobilevitv2",["MobileViTV2Model",Er]],["owlvit",["OwlViTModel",Ir]],["owlv2",["Owlv2Model",zr]],["beit",["BeitModel",jr]],["deit",["DeiTModel",Hr]],["convnext",["ConvNextModel",so]],["convnextv2",["ConvNextV2Model",io]],["dinov2",["Dinov2Model",ro]],["resnet",["ResNetModel",Cr]],["swin",["SwinModel",Wr]],["swin2sr",["Swin2SRModel",Jr]],["donut-swin",["DonutSwinModel",eo]],["yolos",["YolosModel",lo]],["dpt",["DPTModel",Qr]],["glpn",["GLPNModel",Tr]],["hifigan",["SpeechT5HifiGan",Ko]],["efficientnet",["EfficientNetModel",al]]]),tb=new Map([["t5",["T5Model",ea]],["longt5",["LongT5Model",na]],["mt5",["MT5Model",aa]],["bart",["BartModel",oa]],["mbart",["MBartModel",ha]],["marian",["MarianModel",po]],["whisper",["WhisperModel",Da]],["m2m_100",["M2M100Model",go]],["blenderbot",["BlenderbotModel",fa]],["blenderbot-small",["BlenderbotSmallModel",ma]]]),gk=new Map([["bloom",["BloomModel",dr]],["gpt2",["GPT2Model",Za]],["gptj",["GPTJModel",Pa]],["gpt_bigcode",["GPTBigCodeModel",er]],["gpt_neo",["GPTNeoModel",Va]],["gpt_neox",["GPTNeoXModel",Fa]],["codegen",["CodeGenModel",nr]],["llama",["LlamaModel",ar]],["qwen2",["Qwen2Model",or]],["phi",["PhiModel",cr]],["mpt",["MptModel",_r]],["opt",["OPTModel",pr]],["mistral",["MistralModel",Jo]],["starcoder2",["Starcoder2Model",Qo]],["falcon",["FalconModel",Mo]]]),Hd=new Map([["speecht5",["SpeechT5ForSpeechToText",Xo]],["whisper",["WhisperForConditionalGeneration",La]]]),eb=new Map([["speecht5",["SpeechT5ForTextToSpeech",Co]]]),sb=new Map([["vits",["VitsModel",Ns]]]),nb=new Map([["bert",["BertForSequenceClassification",Qn]],["roformer",["RoFormerForSequenceClassification",ei]],["electra",["ElectraForSequenceClassification",di]],["esm",["EsmForSequenceClassification",Li]],["convbert",["ConvBertForSequenceClassification",ri]],["camembert",["CamembertForSequenceClassification",mi]],["deberta",["DebertaForSequenceClassification",bi]],["deberta-v2",["DebertaV2ForSequenceClassification",Ni]],["mpnet",["MPNetForSequenceClassification",Wi]],["albert",["AlbertForSequenceClassification",Ti]],["distilbert",["DistilBertForSequenceClassification",Si]],["roberta",["RobertaForSequenceClassification",xa]],["xlm",["XLMForSequenceClassification",Ea]],["xlm-roberta",["XLMRobertaForSequenceClassification",Sa]],["bart",["BartForSequenceClassification",ca]],["mbart",["MBartForSequenceClassification",ua]],["mobilebert",["MobileBertForSequenceClassification",Hi]],["squeezebert",["SqueezeBertForSequenceClassification",Vi]]]),ib=new Map([["bert",["BertForTokenClassification",Vn]],["roformer",["RoFormerForTokenClassification",si]],["electra",["ElectraForTokenClassification",ui]],["esm",["EsmForTokenClassification",Gi]],["convbert",["ConvBertForTokenClassification",oi]],["camembert",["CamembertForTokenClassification",gi]],["deberta",["DebertaForTokenClassification",ki]],["deberta-v2",["DebertaV2ForTokenClassification",Ii]],["mpnet",["MPNetForTokenClassification",Yi]],["distilbert",["DistilBertForTokenClassification",ji]],["roberta",["RobertaForTokenClassification",ba]],["xlm",["XLMForTokenClassification",Na]],["xlm-roberta",["XLMRobertaForTokenClassification",ja]]]),Xd=new Map([["t5",["T5ForConditionalGeneration",sa]],["longt5",["LongT5ForConditionalGeneration",ia]],["mt5",["MT5ForConditionalGeneration",ra]],["bart",["BartForConditionalGeneration",la]],["mbart",["MBartForConditionalGeneration",da]],["marian",["MarianMTModel",mo]],["m2m_100",["M2M100ForConditionalGeneration",wo]],["blenderbot",["BlenderbotForConditionalGeneration",pa]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",ga]]]),ch=new Map([["bloom",["BloomForCausalLM",ur]],["gpt2",["GPT2LMHeadModel",Qa]],["gptj",["GPTJForCausalLM",tr]],["gpt_bigcode",["GPTBigCodeForCausalLM",sr]],["gpt_neo",["GPTNeoForCausalLM",Ma]],["gpt_neox",["GPTNeoXForCausalLM",Ta]],["codegen",["CodeGenForCausalLM",ir]],["llama",["LlamaForCausalLM",rr]],["qwen2",["Qwen2ForCausalLM",lr]],["phi",["PhiForCausalLM",hr]],["mpt",["MptForCausalLM",fr]],["opt",["OPTForCausalLM",mr]],["mbart",["MBartForCausalLM",_a]],["mistral",["MistralForCausalLM",Zo]],["starcoder2",["Starcoder2ForCausalLM",Vo]],["falcon",["FalconForCausalLM",Fo]],["trocr",["TrOCRForCausalLM",Yo]],["stablelm",["StableLmForCausalLM",il]]]),ab=new Map([["bert",["BertForMaskedLM",Zn]],["roformer",["RoFormerForMaskedLM",ti]],["electra",["ElectraForMaskedLM",hi]],["esm",["EsmForMaskedLM",Di]],["convbert",["ConvBertForMaskedLM",ai]],["camembert",["CamembertForMaskedLM",pi]],["deberta",["DebertaForMaskedLM",xi]],["deberta-v2",["DebertaV2ForMaskedLM",Ei]],["mpnet",["MPNetForMaskedLM",Ki]],["albert",["AlbertForMaskedLM",ta]],["distilbert",["DistilBertForMaskedLM",Ri]],["roberta",["RobertaForMaskedLM",ya]],["xlm",["XLMWithLMHeadModel",Aa]],["xlm-roberta",["XLMRobertaForMaskedLM",za]],["mobilebert",["MobileBertForMaskedLM",Bi]],["squeezebert",["SqueezeBertForMaskedLM",Qi]]]),rb=new Map([["bert",["BertForQuestionAnswering",Mn]],["roformer",["RoFormerForQuestionAnswering",ni]],["electra",["ElectraForQuestionAnswering",_i]],["convbert",["ConvBertForQuestionAnswering",li]],["camembert",["CamembertForQuestionAnswering",wi]],["deberta",["DebertaForQuestionAnswering",vi]],["deberta-v2",["DebertaV2ForQuestionAnswering",Oi]],["mpnet",["MPNetForQuestionAnswering",Ji]],["albert",["AlbertForQuestionAnswering",Pi]],["distilbert",["DistilBertForQuestionAnswering",$i]],["roberta",["RobertaForQuestionAnswering",ka]],["xlm",["XLMForQuestionAnswering",Ia]],["xlm-roberta",["XLMRobertaForQuestionAnswering",$a]],["mobilebert",["MobileBertForQuestionAnswering",Xi]],["squeezebert",["SqueezeBertForQuestionAnswering",Mi]]]),Cd=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",Xe]]]),wk=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",Xe]]]),ob=new Map([["vit",["ViTForImageClassification",wr]],["fastvit",["FastViTForImageClassification",xr]],["mobilevit",["MobileViTForImageClassification",Ar]],["mobilevitv2",["MobileViTV2ForImageClassification",Nr]],["beit",["BeitForImageClassification",$r]],["deit",["DeiTForImageClassification",Xr]],["convnext",["ConvNextForImageClassification",no]],["convnextv2",["ConvNextV2ForImageClassification",ao]],["dinov2",["Dinov2ForImageClassification",oo]],["resnet",["ResNetForImageClassification",Kr]],["swin",["SwinForImageClassification",Yr]],["segformer",["SegformerForImageClassification",sl]],["efficientnet",["EfficientNetForImageClassification",rl]]]),lb=new Map([["detr",["DetrForObjectDetection",Ur]],["table-transformer",["TableTransformerForObjectDetection",qr]],["yolos",["YolosForObjectDetection",co]]]),cb=new Map([["owlvit",["OwlViTForObjectDetection",Or]],["owlv2",["Owlv2ForObjectDetection",Sr]]]),hb=new Map([["detr",["DetrForSegmentation",Dr]],["clipseg",["CLIPSegForImageSegmentation",Ja]]]),db=new Map([["segformer",["SegformerForSemanticSegmentation",nl]]]),ub=new Map([["sam",["SamModel",_o]]]),_b=new Map([["wav2vec2",["Wav2Vec2ForCTC",xo]],["wav2vec2-bert",["Wav2Vec2BertForCTC",jo]],["unispeech",["UniSpeechForCTC",Ao]],["unispeech-sat",["UniSpeechSatForCTC",Io]],["wavlm",["WavLMForCTC",Go]],["hubert",["HubertForCTC",Uo]]]),fb=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",bo]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",$o]],["unispeech",["UniSpeechForSequenceClassification",Eo]],["unispeech-sat",["UniSpeechSatForSequenceClassification",Oo]],["wavlm",["WavLMForSequenceClassification",qo]],["hubert",["HubertForSequenceClassification",Do]],["audio-spectrogram-transformer",["ASTForAudioClassification",Ua]]]),pb=new Map([["wavlm",["WavLMForXVector",Bo]]]),mb=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",zo]],["wavlm",["WavLMForAudioFrameClassification",Ho]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",ko]]]),gb=new Map([["vitmatte",["VitMatteForImageMatting",kr]]]),wb=new Map([["swin2sr",["Swin2SRForImageSuperResolution",Zr]]]),yb=new Map([["dpt",["DPTForDepthEstimation",Vr]],["depth_anything",["DepthAnythingForDepthEstimation",Fr]],["glpn",["GLPNForDepthEstimation",Pr]]]),xb=new Map([["clip",["CLIPVisionModelWithProjection",Ba]],["siglip",["SiglipVisionModel",Ca]]]),bb=[[Px,z.EncoderOnly],[tb,z.EncoderDecoder],[gk,z.DecoderOnly],[nb,z.EncoderOnly],[ib,z.EncoderOnly],[Xd,z.Seq2Seq],[Hd,z.Seq2Seq],[ch,z.DecoderOnly],[ab,z.EncoderOnly],[rb,z.EncoderOnly],[Cd,z.Vision2Seq],[ob,z.EncoderOnly],[hb,z.EncoderOnly],[db,z.EncoderOnly],[gb,z.EncoderOnly],[wb,z.EncoderOnly],[yb,z.EncoderOnly],[lb,z.EncoderOnly],[cb,z.EncoderOnly],[ub,z.MaskGeneration],[_b,z.EncoderOnly],[fb,z.EncoderOnly],[eb,z.Seq2Seq],[sb,z.EncoderOnly],[pb,z.EncoderOnly],[mb,z.EncoderOnly],[xb,z.EncoderOnly]];for(const[o,t]of bb)for(const[e,s]of o.values())Yn.set(e,t),Ae.set(s,e),Mx.set(e,s);const yk=[["CLIPTextModelWithProjection",qa,z.EncoderOnly],["SiglipTextModel",Xa,z.EncoderOnly],["ClapTextModelWithProjection",Po,z.EncoderOnly],["ClapAudioModelWithProjection",tl,z.EncoderOnly]];for(const[o,t,e]of yk)Yn.set(o,e),Ae.set(t,o),Mx.set(o,t);const Ne=class Ne extends H{};a(Ne,"AutoModel"),E(Ne,"MODEL_CLASS_MAPPINGS",bb.map(t=>t[0])),E(Ne,"BASE_IF_FAIL",!0);let At=Ne;const Dc=class Dc extends H{};a(Dc,"AutoModelForSequenceClassification"),E(Dc,"MODEL_CLASS_MAPPINGS",[nb]);let zs=Dc;const Lc=class Lc extends H{};a(Lc,"AutoModelForTokenClassification"),E(Lc,"MODEL_CLASS_MAPPINGS",[ib]);let ol=Lc;const Gc=class Gc extends H{};a(Gc,"AutoModelForSeq2SeqLM"),E(Gc,"MODEL_CLASS_MAPPINGS",[Xd]);let Pt=Gc;const qc=class qc extends H{};a(qc,"AutoModelForSpeechSeq2Seq"),E(qc,"MODEL_CLASS_MAPPINGS",[Hd]);let ll=qc;const Bc=class Bc extends H{};a(Bc,"AutoModelForTextToSpectrogram"),E(Bc,"MODEL_CLASS_MAPPINGS",[eb]);let cl=Bc;const Hc=class Hc extends H{};a(Hc,"AutoModelForTextToWaveform"),E(Hc,"MODEL_CLASS_MAPPINGS",[sb]);let hl=Hc;const Xc=class Xc extends H{};a(Xc,"AutoModelForCausalLM"),E(Xc,"MODEL_CLASS_MAPPINGS",[ch]);let dl=Xc;const Cc=class Cc extends H{};a(Cc,"AutoModelForMaskedLM"),E(Cc,"MODEL_CLASS_MAPPINGS",[ab]);let ul=Cc;const Kc=class Kc extends H{};a(Kc,"AutoModelForQuestionAnswering"),E(Kc,"MODEL_CLASS_MAPPINGS",[rb]);let _l=Kc;const Wc=class Wc extends H{};a(Wc,"AutoModelForVision2Seq"),E(Wc,"MODEL_CLASS_MAPPINGS",[Cd]);let fl=Wc;const Yc=class Yc extends H{};a(Yc,"AutoModelForImageClassification"),E(Yc,"MODEL_CLASS_MAPPINGS",[ob]);let pl=Yc;const Jc=class Jc extends H{};a(Jc,"AutoModelForImageSegmentation"),E(Jc,"MODEL_CLASS_MAPPINGS",[hb]);let ml=Jc;const Zc=class Zc extends H{};a(Zc,"AutoModelForSemanticSegmentation"),E(Zc,"MODEL_CLASS_MAPPINGS",[db]);let gl=Zc;const Qc=class Qc extends H{};a(Qc,"AutoModelForObjectDetection"),E(Qc,"MODEL_CLASS_MAPPINGS",[lb]);let wl=Qc;const Vc=class Vc extends H{};a(Vc,"AutoModelForZeroShotObjectDetection"),E(Vc,"MODEL_CLASS_MAPPINGS",[cb]);let yl=Vc;const Mc=class Mc extends H{};a(Mc,"AutoModelForMaskGeneration"),E(Mc,"MODEL_CLASS_MAPPINGS",[ub]);let Nd=Mc;const Fc=class Fc extends H{};a(Fc,"AutoModelForCTC"),E(Fc,"MODEL_CLASS_MAPPINGS",[_b]);let xl=Fc;const Tc=class Tc extends H{};a(Tc,"AutoModelForAudioClassification"),E(Tc,"MODEL_CLASS_MAPPINGS",[fb]);let bl=Tc;const Pc=class Pc extends H{};a(Pc,"AutoModelForXVector"),E(Pc,"MODEL_CLASS_MAPPINGS",[pb]);let Id=Pc;const th=class th extends H{};a(th,"AutoModelForAudioFrameClassification"),E(th,"MODEL_CLASS_MAPPINGS",[mb]);let Od=th;const eh=class eh extends H{};a(eh,"AutoModelForDocumentQuestionAnswering"),E(eh,"MODEL_CLASS_MAPPINGS",[wk]);let kl=eh;const sh=class sh extends H{};a(sh,"AutoModelForImageMatting"),E(sh,"MODEL_CLASS_MAPPINGS",[gb]);let zd=sh;const nh=class nh extends H{};a(nh,"AutoModelForImageToImage"),E(nh,"MODEL_CLASS_MAPPINGS",[wb]);let vl=nh;const ih=class ih extends H{};a(ih,"AutoModelForDepthEstimation"),E(ih,"MODEL_CLASS_MAPPINGS",[yb]);let Al=ih;const ah=class ah extends H{};a(ah,"AutoModelForImageFeatureExtraction"),E(ah,"MODEL_CLASS_MAPPINGS",[xb]);let El=ah;const Wy=class Wy extends T{constructor({logits:t,past_key_values:e,encoder_outputs:s,decoder_attentions:n=null,cross_attentions:i=null}){super(),this.logits=t,this.past_key_values=e,this.encoder_outputs=s,this.decoder_attentions=n,this.cross_attentions=i}};a(Wy,"Seq2SeqLMOutput");let Nl=Wy;const Yy=class Yy extends T{constructor({logits:t}){super(),this.logits=t}};a(Yy,"SequenceClassifierOutput");let j=Yy;const Jy=class Jy extends T{constructor({logits:t,embeddings:e}){super(),this.logits=t,this.embeddings=e}};a(Jy,"XVectorOutput");let Il=Jy;const Zy=class Zy extends T{constructor({logits:t}){super(),this.logits=t}};a(Zy,"TokenClassifierOutput");let V=Zy;const Qy=class Qy extends T{constructor({logits:t}){super(),this.logits=t}};a(Qy,"MaskedLMOutput");let M=Qy;const Vy=class Vy extends T{constructor({start_logits:t,end_logits:e}){super(),this.start_logits=t,this.end_logits=e}};a(Vy,"QuestionAnsweringModelOutput");let P=Vy;const My=class My extends T{constructor({logits:t}){super(),this.logits=t}};a(My,"CausalLMOutput");let wt=My;const Fy=class Fy extends T{constructor({logits:t,past_key_values:e}){super(),this.logits=t,this.past_key_values=e}};a(Fy,"CausalLMOutputWithPast");let Sd=Fy;const Ty=class Ty extends T{constructor({alphas:t}){super(),this.alphas=t}};a(Ty,"ImageMattingOutput");let Ol=Ty;const Py=class Py extends T{constructor({waveform:t,spectrogram:e}){super(),this.waveform=t,this.spectrogram=e}};a(Py,"VitsModelOutput");let zl=Py;typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});const dt=typeof self<"u",xk=dt&&self.constructor.name==="DedicatedWorkerGlobalScope";let Ht,kb,kt;if(dt)Ht=a((o,t)=>{if(!self.OffscreenCanvas)throw new Error("OffscreenCanvas not supported by this browser.");return new self.OffscreenCanvas(o,t)},"createCanvasFunction"),kt=self.createImageBitmap,kb=self.ImageData;else if(J)kt=a(async o=>{const e=(await o.metadata()).channels;let{data:s,info:n}=await o.rotate().raw().toBuffer({resolveWithObject:!0});const i=new yt(new Uint8ClampedArray(s),n.width,n.height,n.channels);return e!==void 0&&e!==n.channels&&i.convert(e),i},"loadImageFunction");else throw new Error("Unable to load image processing library.");const bk={0:"nearest",1:"lanczos",2:"bilinear",3:"bicubic",4:"box",5:"hamming"},kk=new Map([["png","image/png"],["jpg","image/jpeg"],["jpeg","image/jpeg"],["gif","image/gif"]]),ut=class ut{constructor(t,e,s,n){this.data=t,this.width=e,this.height=s,this.channels=n}get size(){return[this.width,this.height]}static async read(t){if(t instanceof ut)return t;if(typeof t=="string"||t instanceof URL)return await this.fromURL(t);throw new Error(`Unsupported input type: ${typeof t}`)}static async fromURL(t){let e=await Zs(t);if(e.status!==200)throw new Error(`Unable to read image from "${t}" (${e.status} ${e.statusText})`);let s=await e.blob();return this.fromBlob(s)}static async fromBlob(t){if(dt){let e=await kt(t);const s=Ht(e.width,e.height).getContext("2d");return s.drawImage(e,0,0),new this(s.getImageData(0,0,e.width,e.height).data,e.width,e.height,4)}else{let e=J(await t.arrayBuffer());return await kt(e)}}static fromTensor(t,e="CHW"){if(t.dims.length!==3)throw new Error(`Tensor should have 3 dimensions, but has ${t.dims.length} dimensions.`);if(e==="CHW")t=t.transpose(1,2,0);else if(e!=="HWC")throw new Error(`Unsupported channel format: ${e}`);if(!(t.data instanceof Uint8ClampedArray||t.data instanceof Uint8Array))throw new Error(`Unsupported tensor type: ${t.type}`);switch(t.dims[2]){case 1:case 2:case 3:case 4:return new ut(t.data,t.dims[1],t.dims[0],t.dims[2]);default:throw new Error(`Unsupported number of channels: ${t.dims[2]}`)}}grayscale(){if(this.channels===1)return this;let t=new Uint8ClampedArray(this.width*this.height*1);switch(this.channels){case 3:case 4:for(let e=0,s=0;e<this.data.length;e+=this.channels){const n=this.data[e],i=this.data[e+1],r=this.data[e+2];t[s++]=Math.round(.2989*n+.587*i+.114*r)}break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(t,this.width,this.height,1)}rgb(){if(this.channels===3)return this;let t=new Uint8ClampedArray(this.width*this.height*3);switch(this.channels){case 1:for(let e=0,s=0;e<this.data.length;++e)t[s++]=this.data[e],t[s++]=this.data[e],t[s++]=this.data[e];break;case 4:for(let e=0,s=0;e<this.data.length;e+=4)t[s++]=this.data[e],t[s++]=this.data[e+1],t[s++]=this.data[e+2];break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(t,this.width,this.height,3)}rgba(){if(this.channels===4)return this;let t=new Uint8ClampedArray(this.width*this.height*4);switch(this.channels){case 1:for(let e=0,s=0;e<this.data.length;++e)t[s++]=this.data[e],t[s++]=this.data[e],t[s++]=this.data[e],t[s++]=255;break;case 3:for(let e=0,s=0;e<this.data.length;e+=3)t[s++]=this.data[e],t[s++]=this.data[e+1],t[s++]=this.data[e+2],t[s++]=255;break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(t,this.width,this.height,4)}async resize(t,e,{resample:s=2}={}){let n=bk[s]??s;if(dt){let i=this.channels,r=this.toCanvas();const l=Ht(t,e).getContext("2d");return l.drawImage(r,0,0,t,e),new ut(l.getImageData(0,0,t,e).data,t,e,4).convert(i)}else{let i=this.toSharp();switch(n){case"box":case"hamming":(n==="box"||n==="hamming")&&(console.warn(`Resampling method ${n} is not yet supported. Using bilinear instead.`),n="bilinear");case"nearest":case"bilinear":case"bicubic":i=i.affine([t/this.width,0,0,e/this.height],{interpolator:n});break;case"lanczos":i=i.resize({width:t,height:e,fit:"fill",kernel:"lanczos3"});break;default:throw new Error(`Resampling method ${n} is not supported.`)}return await kt(i)}}async pad([t,e,s,n]){if(t=Math.max(t,0),e=Math.max(e,0),s=Math.max(s,0),n=Math.max(n,0),t===0&&e===0&&s===0&&n===0)return this;if(dt){let i=this.channels,r=this.toCanvas(),l=this.width+t+e,c=this.height+s+n;const h=Ht(l,c).getContext("2d");return h.drawImage(r,0,0,this.width,this.height,t,s,l,c),new ut(h.getImageData(0,0,l,c).data,l,c,4).convert(i)}else{let i=this.toSharp().extend({left:t,right:e,top:s,bottom:n});return await kt(i)}}async crop([t,e,s,n]){if(t=Math.max(t,0),e=Math.max(e,0),s=Math.min(s,this.width-1),n=Math.min(n,this.height-1),t===0&&e===0&&s===this.width-1&&n===this.height-1)return this;const i=s-t+1,r=n-e+1;if(dt){const l=this.channels,c=this.toCanvas(),h=Ht(i,r).getContext("2d");return h.drawImage(c,t,e,i,r,0,0,i,r),new ut(h.getImageData(0,0,i,r).data,i,r,4).convert(l)}else{const l=this.toSharp().extract({left:t,top:e,width:i,height:r});return await kt(l)}}async center_crop(t,e){if(this.width===t&&this.height===e)return this;let s=(this.width-t)/2,n=(this.height-e)/2;if(dt){let i=this.channels,r=this.toCanvas();const l=Ht(t,e).getContext("2d");let c=0,h=0,d=0,u=0;return s>=0?c=s:d=-s,n>=0?h=n:u=-n,l.drawImage(r,c,h,t,e,d,u,t,e),new ut(l.getImageData(0,0,t,e).data,t,e,4).convert(i)}else{let i=this.toSharp();if(s>=0&&n>=0)i=i.extract({left:Math.floor(s),top:Math.floor(n),width:t,height:e});else if(s<=0&&n<=0){let r=Math.floor(-n),l=Math.floor(-s);i=i.extend({top:r,left:l,right:t-this.width-l,bottom:e-this.height-r})}else{let r=[0,0],l=0;n<0?(r[0]=Math.floor(-n),r[1]=e-this.height-r[0]):l=Math.floor(n);let c=[0,0],h=0;s<0?(c[0]=Math.floor(-s),c[1]=t-this.width-c[0]):h=Math.floor(s),i=i.extend({top:r[0],bottom:r[1],left:c[0],right:c[1]}).extract({left:h,top:l,width:t,height:e})}return await kt(i)}}async toBlob(t="image/png",e=1){if(!dt)throw new Error("toBlob() is only supported in browser environments.");return await this.toCanvas().convertToBlob({type:t,quality:e})}toTensor(t="CHW"){let e=new v("uint8",new Uint8Array(this.data),[this.height,this.width,this.channels]);if(t!=="HWC")if(t==="CHW")e=e.permute(2,0,1);else throw new Error(`Unsupported channel format: ${t}`);return e}toCanvas(){if(!dt)throw new Error("toCanvas() is only supported in browser environments.");let t=this.clone().rgba(),e=Ht(t.width,t.height),s=new kb(t.data,t.width,t.height);return e.getContext("2d").putImageData(s,0,0),e}_update(t,e,s,n=null){return this.data=t,this.width=e,this.height=s,n!==null&&(this.channels=n),this}clone(){return new ut(this.data.slice(),this.width,this.height,this.channels)}convert(t){if(this.channels===t)return this;switch(t){case 1:this.grayscale();break;case 3:this.rgb();break;case 4:this.rgba();break;default:throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this}async save(t){if(dt){if(xk)throw new Error("Unable to save an image from a Web Worker.");const e=t.split(".").pop().toLowerCase(),s=kk.get(e)??"image/png",n=await this.toBlob(s),i=URL.createObjectURL(n),r=document.createElement("a");r.href=i,r.download=t,r.click(),r.remove()}else{if(Q.useFS)return await this.toSharp().toFile(t);throw new Error("Unable to save the image because filesystem is disabled in this environment.")}}toSharp(){if(dt)throw new Error("toSharp() is only supported in server-side environments.");return J(this.data,{raw:{width:this.width,height:this.height,channels:this.channels}})}};a(ut,"RawImage");let yt=ut;typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});async function vb(o,t){if(typeof AudioContext>"u")throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");const e=await(await Zs(o)).arrayBuffer(),s=new AudioContext({sampleRate:t});typeof t>"u"&&console.warn(`No sampling rate provided, using default of ${s.sampleRate}Hz.`);const n=await s.decodeAudioData(e);let i;if(n.numberOfChannels===2){const r=Math.sqrt(2),l=n.getChannelData(0),c=n.getChannelData(1);i=new Float32Array(l.length);for(let h=0;h<n.length;++h)i[h]=r*(l[h]+c[h])/2}else i=n.getChannelData(0);return i}a(vb,"read_audio");function jd(o){if(o<1)return new Float64Array;if(o===1)return new Float64Array([1]);const t=o-1,e=Math.PI/t,s=new Float64Array(o);for(let n=0;n<o;++n){const i=2*n-t;s[n]=.5+.5*Math.cos(e*i)}return s}a(jd,"hanning");const vk={htk:a(o=>2595*Math.log10(1+o/700),"htk"),kaldi:a(o=>1127*Math.log(1+o/700),"kaldi"),slaney:a((o,t=1e3,e=15,s=27/Math.log(6.4))=>o>=t?e+Math.log(o/t)*s:3*o/200,"slaney")};function _h(o,t="htk"){const e=vk[t];if(!e)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return typeof o=="number"?e(o):o.map(s=>e(s))}a(_h,"hertz_to_mel");const Ak={htk:a(o=>700*(10**(o/2595)-1),"htk"),kaldi:a(o=>700*(Math.exp(o/1127)-1),"kaldi"),slaney:a((o,t=1e3,e=15,s=Math.log(6.4)/27)=>o>=e?t*Math.exp(s*(o-e)):200*o/3,"slaney")};function Ek(o,t="htk"){const e=Ak[t];if(!e)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return typeof o=="number"?e(o):o.map(s=>e(s))}a(Ek,"mel_to_hertz");function Nk(o,t){const e=Float64Array.from({length:t.length-1},(r,l)=>t[l+1]-t[l]),s=Array.from({length:o.length},()=>new Array(t.length));for(let r=0;r<o.length;++r){const l=s[r];for(let c=0;c<t.length;++c)l[c]=t[c]-o[r]}const n=t.length-2,i=Array.from({length:n},()=>new Array(o.length));for(let r=0;r<o.length;++r){const l=s[r];for(let c=0;c<n;++c){const h=-l[c]/e[c],d=l[c+2]/e[c+1];i[c][r]=Math.max(0,Math.min(h,d))}}return i}a(Nk,"_create_triangular_filter_bank");function vx(o,t,e){const s=(t-o)/(e-1);return Float64Array.from({length:e},(n,i)=>o+s*i)}a(vx,"linspace");function _e(o,t,e,s,n,i=null,r="htk",l=!1){if(i!==null&&i!=="slaney")throw new Error('norm must be one of null or "slaney"');const c=_h(e,r),h=_h(s,r),d=vx(c,h,t+2);let u=Ek(d,r),f;if(l){const p=n/(o*2);f=_h(Float64Array.from({length:o},(m,g)=>g*p),r),u=d}else f=vx(0,Math.floor(n/2),o);const _=Nk(f,u);if(i!==null&&i==="slaney")for(let p=0;p<t;++p){const m=_[p],g=2/(u[p+2]-u[p]);for(let w=0;w<o;++w)m[w]*=g}return _}a(_e,"mel_filter_bank");function Ik(o,t,e){const s=new o.constructor(o.length+t+e),n=o.length-1;for(let i=0;i<o.length;++i)s[t+i]=o[i];for(let i=1;i<=t;++i)s[t-i]=o[Ys(i,n)];for(let i=1;i<=e;++i)s[n+t+i]=o[Ys(n-i,n)];return s}a(Ik,"padReflect");function Ab(o,t,e,s,n){if(e<=0)throw new Error("reference must be greater than zero");if(s<=0)throw new Error("min_value must be greater than zero");e=Math.max(s,e);const i=Math.log10(e);for(let r=0;r<o.length;++r)o[r]=t*Math.log10(Math.max(s,o[r])-i);if(n!==null){if(n<=0)throw new Error("db_range must be greater than zero");const r=ct(o)[0]-n;for(let l=0;l<o.length;++l)o[l]=Math.max(o[l],r)}return o}a(Ab,"_db_conversion_helper");function Ok(o,t=1,e=1e-5,s=null){return Ab(o,20,t,e,s)}a(Ok,"amplitude_to_db");function zk(o,t=1,e=1e-10,s=null){return Ab(o,10,t,e,s)}a(zk,"power_to_db");function qs(o,t,e,s,{fft_length:n=null,power:i=1,center:r=!0,pad_mode:l="reflect",onesided:c=!0,preemphasis:h=null,mel_filters:d=null,mel_floor:u=1e-10,log_mel:f=null,reference:_=1,min_value:p=1e-10,db_range:m=null,remove_dc_offset:g=null,max_num_frames:w=null,do_pad:y=!0,transpose:k=!1}={}){const A=t.length;if(n===null&&(n=e),e>n)throw Error(`frame_length (${e}) may not be larger than fft_length (${n})`);if(A!==e)throw new Error(`Length of the window (${A}) must equal frame_length (${e})`);if(s<=0)throw new Error("hop_length must be greater than zero");if(i===null&&d!==null)throw new Error("You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue.");if(r){if(l!=="reflect")throw new Error(`pad_mode="${l}" not implemented yet.`);const R=Math.floor((n-1)/2)+1;o=Ik(o,R,R)}const b=Math.floor(1+Math.floor((o.length-e)/s)),N=c?Math.floor(n/2)+1:n;let I=b,$=b;w!==null&&(w>b?y&&($=w):$=I=w);const G=new Ms(n),L=new Float64Array(n),Y=new Float64Array(G.outputBufferSize),q=new Array(I);for(let R=0;R<I;++R){const B=R*s;for(let S=0;S<e;++S)L[S]=o[B+S];if(g){let S=0;for(let F=0;F<e;++F)S+=L[F];const rt=S/e;for(let F=0;F<e;++F)L[F]-=rt}if(h!==null){for(let S=e-1;S>=1;--S)L[S]-=h*L[S-1];L[0]*=1-h}for(let S=0;S<t.length;++S)L[S]*=t[S];G.realTransform(Y,L);const K=new Array(N);for(let S=0;S<K.length;++S){const rt=S<<1;K[S]=Y[rt]**2+Y[rt+1]**2}q[R]=K}if(i!==null&&i!==2){const R=2/i;for(let B=0;B<q.length;++B){const K=q[B];for(let S=0;S<K.length;++S)K[S]**=R}}const U=d.length,D=new Float32Array(U*$),X=k?[$,U]:[U,$];for(let R=0;R<U;++R){const B=d[R];for(let K=0;K<I;++K){const S=q[K];let rt=0;for(let F=0;F<N;++F)rt+=B[F]*S[F];D[k?K*U+R:R*I+K]=Math.max(u,rt)}}if(i!==null&&f!==null){const R=Math.min(D.length,I*U);switch(f){case"log":for(let B=0;B<R;++B)D[B]=Math.log(D[B]);break;case"log10":for(let B=0;B<R;++B)D[B]=Math.log10(D[B]);break;case"dB":if(i===1)Ok(D,_,p,m);else if(i===2)zk(D,_,p,m);else throw new Error(`Cannot use log_mel option '${f}' with power ${i}`);break;default:throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${f}'`)}}return{data:D,dims:X}}a(qs,"spectrogram");function Bs(o,t,{periodic:e=!0,frame_length:s=null,center:n=!0}={}){const i=e?o+1:o;let r;switch(t){case"boxcar":r=new Float64Array(i).fill(1);break;case"hann":case"hann_window":r=jd(i);break;case"povey":r=jd(i).map(l=>Math.pow(l,.85));break;default:throw new Error(`Unknown window type ${t}.`)}if(e&&(r=r.subarray(0,o)),s===null)return r;if(o>s)throw new Error(`Length of the window (${o}) may not be larger than frame_length (${s})`);return r}a(Bs,"window_function");typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});function Sk([o,t,e,s]){return[o-e/2,t-s/2,o+e/2,t+s/2]}a(Sk,"center_to_corners_format");function Kd(o,t=.5,e=null,s=!1){const n=o.logits,i=o.pred_boxes,[r,l,c]=n.dims;if(e!==null&&e.length!==r)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let h=[];for(let d=0;d<r;++d){let u=e!==null?e[d]:null,f={boxes:[],classes:[],scores:[]},_=n[d],p=i[d];for(let m=0;m<l;++m){let g=_[m],w=[],y;if(s){y=g.sigmoid().data;for(let k=0;k<y.length;++k)y[k]>t&&w.push(k)}else{let k=ct(g.data)[1];if(k===c-1)continue;w.push(k),y=st(g.data)}for(const k of w){let A=p[m].data;A=Sk(A),u!==null&&(A=A.map((b,N)=>b*u[(N+1)%2])),f.boxes.push(A),f.classes.push(k),f.scores.push(y[k])}}h.push(f)}return h}a(Kd,"post_process_object_detection");function Hs(o,t){if(!(o instanceof Float32Array||o instanceof Float64Array))throw new Error(`${t} expects input to be a Float32Array or a Float64Array, but got ${o?.constructor?.name??typeof o} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}a(Hs,"validate_audio_inputs");function Ax(o,t,e=0,s=null){const n=o/t;let i=qx(n)*t;return s!==null&&i>s&&(i=Math.floor(n)*t),i<e&&(i=Math.ceil(n)*t),i}a(Ax,"constraint_to_multiple_of");function fh([o,t],e){return[Math.max(Math.floor(o/e),1)*e,Math.max(Math.floor(t/e),1)*e]}a(fh,"enforce_size_divisibility");const t0=class t0 extends lt{constructor(t){super(),this.config=t}};a(t0,"FeatureExtractor");let pt=t0;const e0=class e0 extends pt{constructor(t){super(t),this.image_mean=this.config.image_mean??this.config.mean,this.image_std=this.config.image_std??this.config.std,this.resample=this.config.resample??2,this.do_rescale=this.config.do_rescale??!0,this.rescale_factor=this.config.rescale_factor??1/255,this.do_normalize=this.config.do_normalize,this.do_resize=this.config.do_resize,this.do_thumbnail=this.config.do_thumbnail,this.size=this.config.size,this.size_divisibility=this.config.size_divisibility??this.config.size_divisor,this.do_center_crop=this.config.do_center_crop,this.crop_size=this.config.crop_size,this.do_convert_rgb=this.config.do_convert_rgb??!0,this.do_crop_margin=this.config.do_crop_margin,this.pad_size=this.config.pad_size,this.do_pad=this.config.do_pad,this.do_pad&&!this.pad_size&&this.size&&this.size.width!==void 0&&this.size.height!==void 0&&(this.pad_size=this.size),this.do_flip_channel_order=this.config.do_flip_channel_order??!1}async thumbnail(t,e,s=2){const n=t.height,i=t.width,r=e.height,l=e.width;let c=Math.min(n,r),h=Math.min(i,l);return c===n&&h===i?t:(n>i?h=Math.floor(i*c/n):i>n&&(c=Math.floor(n*h/i)),await t.resize(h,c,{resample:s}))}async crop_margin(t,e=200){const s=t.clone().grayscale(),n=$d(s.data)[0],r=ct(s.data)[0]-n;if(r===0)return t;const l=e/255;let c=s.width,h=s.height,d=0,u=0;for(let f=0;f<s.height;++f){const _=f*s.width;for(let p=0;p<s.width;++p)(s.data[_+p]-n)/r<l&&(c=Math.min(c,p),h=Math.min(h,f),d=Math.max(d,p),u=Math.max(u,f))}return t=await t.crop([c,h,d,u]),t}pad_image(t,e,s,{mode:n="constant",center:i=!1,constant_values:r=0}={}){const[l,c,h]=e;let d,u;if(typeof s=="number"?(d=s,u=s):(d=s.width,u=s.height),d!==c||u!==l){const f=new Float32Array(d*u*h);if(Array.isArray(r))for(let m=0;m<f.length;++m)f[m]=r[m%h];else r!==0&&f.fill(r);const[_,p]=i?[Math.floor((d-c)/2),Math.floor((u-l)/2)]:[0,0];for(let m=0;m<l;++m){const g=(m+p)*d,w=m*c;for(let y=0;y<c;++y){const k=(g+y+_)*h,A=(w+y)*h;for(let b=0;b<h;++b)f[k+b]=t[A+b]}}if(n==="symmetric"){if(i)throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");const m=l-1,g=c-1;for(let w=0;w<u;++w){const y=w*d,k=Ys(w,m)*c;for(let A=0;A<d;++A){if(w<l&&A<c)continue;const b=(y+A)*h,N=(k+Ys(A,g))*h;for(let I=0;I<h;++I)f[b+I]=t[N+I]}}}t=f,e=[u,d,h]}return[t,e]}rescale(t){for(let e=0;e<t.length;++e)t[e]=this.rescale_factor*t[e]}get_resize_output_image_size(t,e){const[s,n]=t.size;let i,r;if(this.do_thumbnail){const{height:l,width:c}=e;i=Math.min(l,c)}else Number.isInteger(e)?(i=e,r=this.config.max_size??i):e!==void 0&&(i=e.shortest_edge,r=e.longest_edge);if(i!==void 0||r!==void 0){const l=i===void 0?1:Math.max(i/s,i/n),c=s*l,h=n*l,d=r===void 0?1:Math.min(r/c,r/h);let u=Math.floor(Number((c*d).toFixed(2))),f=Math.floor(Number((h*d).toFixed(2)));return this.size_divisibility!==void 0&&([u,f]=fh([u,f],this.size_divisibility)),[u,f]}else if(e!==void 0&&e.width!==void 0&&e.height!==void 0){let l=e.width,c=e.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let h=c/n,d=l/s;Math.abs(1-d)<Math.abs(1-h)?h=d:d=h,c=Ax(h*n,this.config.ensure_multiple_of),l=Ax(d*s,this.config.ensure_multiple_of)}return[l,c]}else{if(this.size_divisibility!==void 0)return fh([s,n],this.size_divisibility);throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(e)}`)}}async resize(t){const[e,s]=this.get_resize_output_image_size(t,this.size);return await t.resize(e,s,{resample:this.resample})}async preprocess(t,{do_normalize:e=null,do_pad:s=null,do_convert_rgb:n=null,do_convert_grayscale:i=null,do_flip_channel_order:r=null}={}){this.do_crop_margin&&(t=await this.crop_margin(t));const[l,c]=t.size;if(n??this.do_convert_rgb?t=t.rgb():i&&(t=t.grayscale()),this.do_resize&&(t=await this.resize(t)),this.do_thumbnail&&(t=await this.thumbnail(t,this.size,this.resample)),this.do_center_crop){let _,p;Number.isInteger(this.crop_size)?(_=this.crop_size,p=this.crop_size):(_=this.crop_size.width,p=this.crop_size.height),t=await t.center_crop(_,p)}const h=[t.height,t.width];let d=Float32Array.from(t.data),u=[t.height,t.width,t.channels];if(this.do_rescale&&this.rescale(d),e??this.do_normalize){let _=this.image_mean;Array.isArray(this.image_mean)||(_=new Array(t.channels).fill(_));let p=this.image_std;if(Array.isArray(this.image_std)||(p=new Array(t.channels).fill(_)),_.length!==t.channels||p.length!==t.channels)throw new Error(`When set to arrays, the length of \`image_mean\` (${_.length}) and \`image_std\` (${p.length}) must match the number of channels in the image (${t.channels}).`);for(let m=0;m<d.length;m+=t.channels)for(let g=0;g<t.channels;++g)d[m+g]=(d[m+g]-_[g])/p[g]}if(s??this.do_pad){if(this.pad_size)[d,u]=this.pad_image(d,[t.height,t.width,t.channels],this.pad_size);else if(this.size_divisibility){const[_,p]=fh([u[1],u[0]],this.size_divisibility);[d,u]=this.pad_image(d,u,{width:_,height:p})}}if(r??this.do_flip_channel_order){if(u[2]!==3)throw new Error("Flipping channel order is only supported for RGB images.");for(let _=0;_<d.length;_+=3){const p=d[_];d[_]=d[_+2],d[_+2]=p}}const f=new v("float32",d,u).permute(2,0,1);return{original_size:[c,l],reshaped_input_size:h,pixel_values:f}}async _call(t,...e){Array.isArray(t)||(t=[t]);const s=await Promise.all(t.map(i=>this.preprocess(i)));return{pixel_values:Gs(s.map(i=>i.pixel_values),0),original_sizes:s.map(i=>i.original_size),reshaped_input_sizes:s.map(i=>i.reshaped_input_size)}}};a(e0,"ImageFeatureExtractor");let C=e0;const s0=class s0 extends C{post_process_semantic_segmentation(t,e=null){const s=t.logits,n=s.dims[0];if(e!==null&&e.length!==n)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");const i=[];for(let r=0;r<n;++r){const l=e!==null?e[r]:null;let c=s[r];l!==null&&(c=ne(c,l,"bilinear",!1));const[h,d]=l??c.dims.slice(-2),u=new v("int32",new Int32Array(h*d),[h,d]),f=c[0].data;for(let g=1;g<c.dims[0];++g){const w=c[g].data;for(let y=0;y<w.length;++y)w[y]>f[y]&&(f[y]=w[y],u.data[y]=g)}const _=new Array(c.dims[0]),p=u.data;for(let g=0;g<p.length;++g){const w=p[g];_[w]=w}const m=_.filter(g=>g!==void 0);i.push({segmentation:u,labels:m})}return i}};a(s0,"SegformerFeatureExtractor");let Sl=s0;const n0=class n0 extends C{};a(n0,"DPTFeatureExtractor");let Ss=n0;const i0=class i0 extends Ss{};a(i0,"DPTImageProcessor");let jl=i0;const a0=class a0 extends C{};a(a0,"BitImageProcessor");let $l=a0;const r0=class r0 extends C{};a(r0,"GLPNFeatureExtractor");let Rl=r0;const o0=class o0 extends C{};a(o0,"CLIPFeatureExtractor");let Ul=o0;const l0=class l0 extends C{};a(l0,"ChineseCLIPFeatureExtractor");let Dl=l0;const c0=class c0 extends C{};a(c0,"SiglipImageProcessor");let Ll=c0;const h0=class h0 extends C{constructor(t){super(t),this.crop_pct=this.config.crop_pct??224/256}async resize(t){const e=this.size?.shortest_edge;if(e===void 0)throw new Error("Size dictionary must contain 'shortest_edge' key.");if(e<384){const s=Math.floor(e/this.crop_pct),[n,i]=this.get_resize_output_image_size(t,{shortest_edge:s});t=await t.resize(n,i,{resample:this.resample}),t=await t.center_crop(e,e)}else t=await t.resize(e,e,{resample:this.resample});return t}};a(h0,"ConvNextFeatureExtractor");let js=h0;const d0=class d0 extends js{};a(d0,"ConvNextImageProcessor");let Gl=d0;const u0=class u0 extends C{};a(u0,"ViTFeatureExtractor");let ql=u0;const _0=class _0 extends C{};a(_0,"ViTImageProcessor");let Bl=_0;const f0=class f0 extends C{constructor(t){super(t),this.include_top=this.config.include_top??!0,this.include_top&&(this.image_std=this.image_std.map(e=>e*e))}};a(f0,"EfficientNetImageProcessor");let Hl=f0;const p0=class p0 extends C{};a(p0,"MobileViTFeatureExtractor");let $s=p0;const m0=class m0 extends $s{};a(m0,"MobileViTImageProcessor");let Xl=m0;const g0=class g0 extends C{post_process_object_detection(...t){return Kd(...t)}};a(g0,"OwlViTFeatureExtractor");let Rs=g0;const w0=class w0 extends Rs{};a(w0,"Owlv2ImageProcessor");let Cl=w0;const y0=class y0 extends C{};a(y0,"DeiTFeatureExtractor");let Kl=y0;const x0=class x0 extends C{};a(x0,"BeitFeatureExtractor");let Wl=x0;const b0=class b0 extends C{pad_image(t,e,s,n={}){const[i,r,l]=e;let c=this.image_mean;Array.isArray(this.image_mean)||(c=new Array(l).fill(c));let h=this.image_std;Array.isArray(h)||(h=new Array(l).fill(c));const d=c.map((u,f)=>-u/h[f]);return super.pad_image(t,e,s,{center:!0,constant_values:d,...n})}};a(b0,"DonutFeatureExtractor");let Us=b0;const k0=class k0 extends Us{};a(k0,"NougatImageProcessor");let Yl=k0;const v0=class v0 extends C{async _call(t){const e=await super._call(t),s=[e.pixel_values.dims[0],64,64],n=new v("int64",new BigInt64Array(s.reduce((i,r)=>i*r)).fill(1n),s);return{...e,pixel_mask:n}}post_process_object_detection(...t){return Kd(...t)}remove_low_and_no_objects(t,e,s,n){let i=[],r=[],l=[];for(let c=0;c<t.dims[0];++c){let h=t[c],d=e[c],u=ct(h.data)[1];if(u===n)continue;let _=st(h.data)[u];_>s&&(i.push(d),r.push(_),l.push(u))}return[i,r,l]}check_segment_validity(t,e,s,n=.5,i=.8){let r=[],l=0,c=0;for(let d=0;d<t.length;++d)t[d]===s&&(r.push(d),++l),e[s].data[d]>=n&&++c;let h=l>0&&c>0;return h&&(h=l/c>i),[h,r]}compute_segments(t,e,s,n,i,r=null,l=null){let[c,h]=l??t[0].dims,d=new v("int32",new Int32Array(c*h),[c,h]),u=[];if(l!==null)for(let m=0;m<t.length;++m)t[m]=ne(t[m],l,"bilinear",!1);let f=new Int32Array(t[0].data.length),_=new Float32Array(t[0].data.length);for(let m=0;m<t.length;++m){let g=e[m];for(let w=0;w<t[m].data.length;++w)t[m].data[w]*=g,t[m].data[w]>_[w]&&(f[w]=m,_[w]=t[m].data[w])}let p=0;for(let m=0;m<s.length;++m){let g=s[m],[w,y]=this.check_segment_validity(f,t,m,n,i);if(w){++p;for(let k of y)d.data[k]=p;u.push({id:p,label_id:g,score:e[m]})}}return[d,u]}post_process_panoptic_segmentation(t,e=.5,s=.5,n=.8,i=null,r=null){i===null&&(console.warn("`label_ids_to_fuse` unset. No instance will be fused."),i=new Set);const l=t.logits,h=t.pred_masks.sigmoid();let[d,u,f]=l.dims;if(f-=1,r!==null&&r.length!==d)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let _=[];for(let p=0;p<d;++p){let m=r!==null?r[p]:null,g=l[p],w=h[p],[y,k,A]=this.remove_low_and_no_objects(g,w,e,f);if(A.length===0){let[I,$]=m??w.dims.slice(-2),G=new v("int32",new Int32Array(I*$).fill(-1),[I,$]);_.push({segmentation:G,segments_info:[]});continue}let[b,N]=this.compute_segments(y,k,A,s,n,i,m);_.push({segmentation:b,segments_info:N})}return _}post_process_instance_segmentation(){throw Error("Not implemented yet")}};a(v0,"DetrFeatureExtractor");let Jl=v0;const A0=class A0 extends C{post_process_object_detection(...t){return Kd(...t)}};a(A0,"YolosFeatureExtractor");let Zl=A0;const E0=class E0 extends C{reshape_input_points(t,e,s){t=structuredClone(t);let n=mx(t);if(n.length===3)n=[1,...n],t=[t];else if(n.length!==4)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let i=0;i<t.length;++i){let r=e[i],l=s[i],c=[l[0]/r[0],l[1]/r[1]];for(let h=0;h<t[i].length;++h)for(let d=0;d<t[i][h].length;++d)for(let u=0;u<t[i][h][d].length;++u)t[i][h][d][u]*=c[u]}return new v("float32",Float32Array.from(t.flat(1/0)),n)}add_input_labels(t,e){let s=mx(t);if(s.length===2)s=[1,...s],t=[t];else if(s.length!==3)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(s.some((n,i)=>n!==e.dims[i]))throw Error(`The first ${s.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new v("int64",t.flat(1/0).map(BigInt),s)}async _call(t,e=null,s=null){const n=await super._call(t);if(e&&(n.input_points=this.reshape_input_points(e,n.original_sizes,n.reshaped_input_sizes)),s){if(!n.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");n.input_labels=this.add_input_labels(s,n.input_points)}return n}post_process_masks(t,e,s,{mask_threshold:n=0,binarize:i=!0,pad_size:r=null}={}){const l=[];r=r??this.pad_size;const c=[r.height,r.width];for(let h=0;h<e.length;++h){const d=e[h],u=s[h],f=t[h],_=[];for(let p=0;p<f.dims[0];++p){const m=f[p];let g=ne(m,c,"bilinear",!1);if(g=g.slice(null,[0,u[0]],[0,u[1]]),g=ne(g,d,"bilinear",!1),i){const w=new Uint8Array(g.data.length);for(let y=0;y<g.data.length;++y)g.data[y]>n&&(w[y]=1);g=new v("bool",w,g.dims)}_.push(g)}l.push(Gs(_))}return l}};a(E0,"SamImageProcessor");let Ql=E0;const N0=class N0 extends C{pad_image(t,e,s,n={}){const[i,r,l]=e;return super.pad_image(t,e,{width:r+(s-r%s)%s,height:i+(s-i%s)%s},{mode:"symmetric",center:!1,constant_values:-1,...n})}};a(N0,"Swin2SRImageProcessor");let Vl=N0;const I0=class I0 extends C{async _call(t,e){Array.isArray(t)||(t=[t]),Array.isArray(e)||(e=[e]);const s=await Promise.all(t.map(r=>this.preprocess(r))),n=await Promise.all(e.map(r=>this.preprocess(r,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0})));return{pixel_values:Gs(s.map((r,l)=>Ls([r.pixel_values,n[l].pixel_values],0)),0),original_sizes:s.map(r=>r.original_size),reshaped_input_sizes:s.map(r=>r.reshaped_input_size)}}};a(I0,"VitMatteImageProcessor");let Ml=I0;const O0=class O0 extends pt{constructor(t){var e;super(t),(e=this.config).mel_filters??(e.mel_filters=_e(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney")),this.window=Bs(this.config.n_fft,"hann")}_extract_fbank_features(t){const{data:e,dims:s}=qs(t,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:this.config.nb_max_frames}),n=ct(e)[0];for(let i=0;i<e.length;++i)e[i]=(Math.max(e[i],n-8)+4)/4;return{data:e,dims:s}}async _call(t){Hs(t,"WhisperFeatureExtractor");let e;t.length>this.config.n_samples?(console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."),e=t.slice(0,this.config.n_samples)):(e=new Float32Array(this.config.n_samples),e.set(t));const{data:s,dims:n}=this._extract_fbank_features(e);return{input_features:new v("float32",s,[1,...n])}}};a(O0,"WhisperFeatureExtractor");let Fl=O0;const z0=class z0 extends pt{_zero_mean_unit_var_norm(t){const s=t.reduce((i,r)=>i+r,0)/t.length,n=t.reduce((i,r)=>i+(r-s)**2,0)/t.length;return t.map(i=>(i-s)/Math.sqrt(n+1e-7))}async _call(t){Hs(t,"Wav2Vec2FeatureExtractor"),t instanceof Float64Array&&(t=new Float32Array(t));let e=t;this.config.do_normalize&&(e=this._zero_mean_unit_var_norm(e));const s=[1,e.length];return{input_values:new v("float32",e,s),attention_mask:new v("int64",new BigInt64Array(e.length).fill(1n),s)}}};a(z0,"Wav2Vec2FeatureExtractor");let Tl=z0;const S0=class S0 extends pt{constructor(t){super(t);const e=this.config.sampling_rate,s=_e(256,this.config.num_mel_bins,20,Math.floor(e/2),e,null,"kaldi",!0);for(let n=0;n<s.length;++n)s[n].push(0);this.mel_filters=s,this.window=Bs(400,"povey",{periodic:!1})}_extract_fbank_features(t,e){return t=t.map(s=>s*32768),qs(t,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:e,transpose:!0})}async _call(t,{padding:e=!0,pad_to_multiple_of:s=2,do_normalize_per_mel_bins:n=!0,return_attention_mask:i=!0}={}){Hs(t,"SeamlessM4TFeatureExtractor");let r=this._extract_fbank_features(t,this.config.max_length);if(n){const[p,m]=r.dims;for(let g=0;g<m;++g){let w=0;for(let b=0;b<p;++b)w+=r.data[b*m+g];const y=w/p;let k=0;for(let b=0;b<p;++b)k+=(r.data[b*m+g]-y)**2;k/=p-1;const A=Math.sqrt(k+1e-7);for(let b=0;b<p;++b){const N=b*m+g;r.data[N]=(r.data[N]-y)/A}}}let l;if(e){const[p,m]=r.dims,g=p%s;if(g>0){const w=new Float32Array(m*(p+g));w.set(r.data),w.fill(this.config.padding_value,r.data.length);const y=p+g;r={data:w,dims:[y,m]},i&&(l=new v("int64",new BigInt64Array(y),[1,y]),l.data.fill(1n,0,p))}}const[c,h]=r.dims,d=this.config.stride;if(c%d!==0)throw new Error(`The number of frames (${c}) must be a multiple of the stride (${d}).`);const f=new v("float32",r.data,r.dims).view(1,Math.floor(c/d),h*d),_={input_features:f};if(i){const p=f.dims[1],m=new v("int64",new BigInt64Array(p),[1,p]);if(l)for(let g=1,w=0;g<c;g+=d,++w)m.data[w]=l.data[g];else m.data.fill(1n);_.attention_mask=m}return _}};a(S0,"SeamlessM4TFeatureExtractor");let Pl=S0;const j0=class j0 extends pt{constructor(t){super(t);const e=this.config.sampling_rate,s=_e(256,this.config.num_mel_bins,20,Math.floor(e/2),e,null,"kaldi",!0);for(let n=0;n<s.length;++n)s[n].push(0);this.mel_filters=s,this.window=Bs(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}_extract_fbank_features(t,e){return qs(t,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:e,transpose:!0})}async _call(t){Hs(t,"ASTFeatureExtractor");const e=this._extract_fbank_features(t,this.config.max_length);if(this.config.do_normalize){const s=this.std*2;for(let n=0;n<e.data.length;++n)e.data[n]=(e.data[n]-this.mean)/s}return{input_values:new v("float32",e.data,[1,...e.dims])}}};a(j0,"ASTFeatureExtractor");let tc=j0;const $0=class $0 extends pt{constructor(t){super(t),this.mel_filters=_e(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=_e(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=Bs(this.config.fft_window_size,"hann")}_get_input_mel(t,e,s,n){let i,r=!1;const l=t.length-e;if(l>0)if(s==="rand_trunc"){r=!0;const c=Math.floor(Math.random()*(l+1));t=t.subarray(c,c+e),i=this._extract_fbank_features(t,this.mel_filters_slaney,this.config.nb_max_samples),i.dims=[1,...i.dims]}else throw new Error(`Truncation strategy "${s}" not implemented`);else{if(l<0){let c=new Float64Array(e);if(c.set(t),n==="repeat")for(let h=t.length;h<e;h+=t.length)c.set(t.subarray(0,Math.min(t.length,e-h)),h);else if(n==="repeatpad")for(let h=t.length;h<-l;h+=t.length)c.set(t,h);t=c}if(s==="fusion")throw new Error(`Truncation strategy "${s}" not implemented`);i=this._extract_fbank_features(t,this.mel_filters_slaney,this.config.nb_max_samples),i.dims=[1,...i.dims]}return{...i,longer:r}}_extract_fbank_features(t,e,s=null){return qs(t,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:e,log_mel:"dB",max_num_frames:s,do_pad:!1,transpose:!0})}async _call(t,{max_length:e=null}={}){Hs(t,"ClapFeatureExtractor");const s=this._get_input_mel(t,e??this.config.nb_max_samples,this.config.truncation,this.config.padding);return{input_features:new v("float32",s.data,[1,...s.dims])}}};a($0,"ClapFeatureExtractor");let ec=$0;const R0=class R0 extends pt{};a(R0,"SpeechT5FeatureExtractor");let sc=R0;const U0=class U0 extends lt{constructor(t){super(),this.feature_extractor=t}async _call(t,...e){return await this.feature_extractor(t,...e)}};a(U0,"Processor");let xt=U0;const D0=class D0 extends xt{async _call(...t){return await this.feature_extractor(...t)}post_process_masks(...t){return this.feature_extractor.post_process_masks(...t)}reshape_input_points(...t){return this.feature_extractor.reshape_input_points(...t)}};a(D0,"SamProcessor");let nc=D0;const L0=class L0 extends xt{async _call(t){return await this.feature_extractor(t)}};a(L0,"WhisperProcessor");let ic=L0;const G0=class G0 extends xt{async _call(t){return await this.feature_extractor(t)}};a(G0,"Wav2Vec2ProcessorWithLM");let ac=G0;const q0=class q0 extends xt{async _call(t){return await this.feature_extractor(t)}};a(q0,"SpeechT5Processor");let rc=q0;const B0=class B0 extends xt{};a(B0,"OwlViTProcessor");let oc=B0;const Ie=class Ie{static async from_pretrained(t,{progress_callback:e=null,config:s=null,cache_dir:n=null,local_files_only:i=!1,revision:r="main"}={}){let l=s??await se(t,"preprocessor_config.json",!0,{progress_callback:e,cache_dir:n,local_files_only:i,revision:r}),c=l.feature_extractor_type??l.image_processor_type,h=this.FEATURE_EXTRACTOR_CLASS_MAPPING[c];if(!h)if(l.size!==void 0)console.warn(`Feature extractor type "${c}" not found, assuming ImageFeatureExtractor due to size parameter in config.`),h=C;else throw new Error(`Unknown Feature Extractor type: ${c}`);let d=this.PROCESSOR_CLASS_MAPPING[l.processor_class]??xt,u=new h(l);return new d(u)}};a(Ie,"AutoProcessor"),E(Ie,"FEATURE_EXTRACTOR_CLASS_MAPPING",{ImageFeatureExtractor:C,WhisperFeatureExtractor:Fl,ViTFeatureExtractor:ql,MobileViTFeatureExtractor:$s,MobileViTImageProcessor:Xl,OwlViTFeatureExtractor:Rs,Owlv2ImageProcessor:Cl,CLIPFeatureExtractor:Ul,ChineseCLIPFeatureExtractor:Dl,SiglipImageProcessor:Ll,ConvNextFeatureExtractor:js,ConvNextImageProcessor:Gl,SegformerFeatureExtractor:Sl,BitImageProcessor:$l,DPTImageProcessor:jl,DPTFeatureExtractor:Ss,GLPNFeatureExtractor:Rl,BeitFeatureExtractor:Wl,DeiTFeatureExtractor:Kl,DetrFeatureExtractor:Jl,YolosFeatureExtractor:Zl,DonutFeatureExtractor:Us,NougatImageProcessor:Yl,EfficientNetImageProcessor:Hl,ViTImageProcessor:Bl,VitMatteImageProcessor:Ml,SamImageProcessor:Ql,Swin2SRImageProcessor:Vl,Wav2Vec2FeatureExtractor:Tl,SeamlessM4TFeatureExtractor:Pl,SpeechT5FeatureExtractor:sc,ASTFeatureExtractor:tc,ClapFeatureExtractor:ec}),E(Ie,"PROCESSOR_CLASS_MAPPING",{WhisperProcessor:ic,Wav2Vec2ProcessorWithLM:ac,SamProcessor:nc,SpeechT5Processor:rc,OwlViTProcessor:oc});let tt=Ie;typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});async function mt(o){return Array.isArray(o)||(o=[o]),await Promise.all(o.map(t=>yt.read(t)))}a(mt,"prepareImages");async function lc(o,t){return Array.isArray(o)||(o=[o]),await Promise.all(o.map(e=>typeof e=="string"||e instanceof URL?vb(e,t):e instanceof Float64Array?new Float32Array(e):e))}a(lc,"prepareAudios");function Eb(o,t){t&&(o=o.map(r=>r|0));const[e,s,n,i]=o;return{xmin:e,ymin:s,xmax:n,ymax:i}}a(Eb,"get_bounding_box");const H0=class H0 extends lt{constructor({task:t,model:e,tokenizer:s=null,processor:n=null}){super(),this.task=t,this.model=e,this.tokenizer=s,this.processor=n}async dispose(){await this.model.dispose()}};a(H0,"Pipeline");let W=H0;const X0=class X0 extends W{constructor(t){super(t)}async _call(t,{topk:e=1}={}){const s=this.tokenizer(t,{padding:!0,truncation:!0}),n=await this.model(s),i=this.model.config.problem_type==="multi_label_classification"?c=>c.sigmoid().data:c=>st(c.data),r=this.model.config.id2label,l=[];for(const c of n.logits){const h=i(c),u=Qt(h,e).map(f=>({label:r[f[0]],score:f[1]}));e===1?l.push(...u):l.push(u)}return Array.isArray(t)||e===1?l:l[0]}};a(X0,"TextClassificationPipeline");let cc=X0;const C0=class C0 extends W{constructor(t){super(t)}async _call(t,{ignore_labels:e=["O"]}={}){const s=Array.isArray(t),n=this.tokenizer(s?t:[t],{padding:!0,truncation:!0}),r=(await this.model(n)).logits,l=this.model.config.id2label,c=[];for(let h=0;h<r.dims[0];++h){const d=n.input_ids[h],u=r[h],f=[];for(let _=0;_<u.dims[0];++_){const p=u[_],m=ct(p.data)[1],g=l?l[m]:`LABEL_${m}`;if(e.includes(g))continue;const w=this.tokenizer.decode([d[_].item()],{skip_special_tokens:!0});if(w==="")continue;const y=st(p.data);f.push({entity:g,score:y[m],index:_,word:w,start:null,end:null})}c.push(f)}return s?c:c[0]}};a(C0,"TokenClassificationPipeline");let hc=C0;const K0=class K0 extends W{constructor(t){super(t)}async _call(t,e,{topk:s=1}={}){const n=this.tokenizer(t,{text_pair:e,padding:!0,truncation:!0}),i=await this.model(n),r=[];for(let l=0;l<i.start_logits.dims[0];++l){const c=n.input_ids[l],h=c.indexOf(this.tokenizer.sep_token_id),d=Array.from(st(i.start_logits[l].data)).map((_,p)=>[_,p]).filter(_=>_[1]>h),u=Array.from(st(i.end_logits[l].data)).map((_,p)=>[_,p]).filter(_=>_[1]>h),f=Ub(d,u).filter(_=>_[0][1]<=_[1][1]).map(_=>[_[0][1],_[1][1],_[0][0]*_[1][0]]).sort((_,p)=>p[2]-_[2]);for(let _=0;_<Math.min(f.length,s);++_){const[p,m,g]=f[_],w=[...c].slice(p,m+1),y=this.tokenizer.decode(w,{skip_special_tokens:!0});r.push({answer:y,score:g})}}return s===1?r[0]:r}};a(K0,"QuestionAnsweringPipeline");let dc=K0;const W0=class W0 extends W{constructor(t){super(t)}async _call(t,{topk:e=5}={}){const s=this.tokenizer(t,{padding:!0,truncation:!0}),n=await this.model(s),i=[];for(let r=0;r<s.input_ids.dims[0];++r){const l=s.input_ids[r],c=l.indexOf(this.tokenizer.mask_token_id);if(c===-1)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const d=n.logits[r][c],u=Qt(st(d.data),e);i.push(u.map(f=>{const _=[...l];return _[c]=f[0],{score:f[1],token:f[0],token_str:this.tokenizer.model.vocab[f[0]],sequence:this.tokenizer.decode(_,{skip_special_tokens:!0})}}))}return Array.isArray(t)?i:i[0]}};a(W0,"FillMaskPipeline");let uc=W0;const Y0=class Y0 extends W{constructor(e){super(e);E(this,"_key","generated_text")}async _call(e,s={}){Array.isArray(e)||(e=[e]),this.model.config.prefix&&(e=e.map(h=>this.model.config.prefix+h));const n=this.model.config.task_specific_params;n&&n[this.task]&&n[this.task].prefix&&(e=e.map(h=>n[this.task].prefix+h));const i=this.tokenizer,r={padding:!0,truncation:!0};let l;this instanceof Ds&&"_build_translation_inputs"in i?l=i._build_translation_inputs(e,r,s).input_ids:l=i(e,r).input_ids;const c=await this.model.generate(l,s);return i.batch_decode(c,{skip_special_tokens:!0}).map(h=>({[this._key]:h}))}};a(Y0,"Text2TextGenerationPipeline");let fe=Y0;const J0=class J0 extends fe{constructor(e){super(e);E(this,"_key","summary_text")}};a(J0,"SummarizationPipeline");let _c=J0;const Z0=class Z0 extends fe{constructor(e){super(e);E(this,"_key","translation_text")}};a(Z0,"TranslationPipeline");let Ds=Z0;function Ex(o){return Array.isArray(o)&&o.every(t=>"role"in t&&"content"in t)}a(Ex,"isChat");const Q0=class Q0 extends W{constructor(t){super(t)}async _call(t,e={}){let s=!1,n=!1,i;if(typeof t=="string")i=t=[t];else if(Array.isArray(t)&&t.every(p=>typeof p=="string"))s=!0,i=t;else{if(Ex(t))t=[t];else if(Array.isArray(t)&&t.every(Ex))s=!0;else throw new Error("Input must be a string, an array of strings, a Chat, or an array of Chats");n=!0,i=t.map(p=>this.tokenizer.apply_chat_template(p,{tokenize:!1,add_generation_prompt:!0}))}const r=e.add_special_tokens??!1,l=n?!1:e.return_full_text??!0;this.tokenizer.padding_side="left";const{input_ids:c,attention_mask:h}=this.tokenizer(i,{add_special_tokens:r,padding:!0,truncation:!0}),d=await this.model.generate(c,e,null,{inputs_attention_mask:h});let u=this.tokenizer.batch_decode(d,{skip_special_tokens:!0}),f;!l&&c.dims.at(-1)>0&&(f=this.tokenizer.batch_decode(c,{skip_special_tokens:!0}).map(p=>p.length));const _=Array.from({length:t.length},p=>[]);for(let p=0;p<u.length;++p){const m=Math.floor(p/d.length*t.length);f&&(u[p]=u[p].slice(f[m])),_[m].push({generated_text:n?[...t[m],{role:"assistant",content:u[p]}]:u[p]})}return!s&&_.length===1?_[0]:_}};a(Q0,"TextGenerationPipeline");let fc=Q0;const V0=class V0 extends W{constructor(t){super(t),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([e,s])=>[e.toLowerCase(),s])),this.entailment_id=this.label2id.entailment,this.entailment_id===void 0&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,this.contradiction_id===void 0&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(t,e,{hypothesis_template:s="This example is {}.",multi_label:n=!1}={}){const i=Array.isArray(t);i||(t=[t]),Array.isArray(e)||(e=[e]);const r=e.map(h=>s.replace("{}",h)),l=n||e.length===1,c=[];for(const h of t){const d=[];for(const _ of r){const p=this.tokenizer(h,{text_pair:_,padding:!0,truncation:!0}),m=await this.model(p);l?d.push([m.logits.data[this.contradiction_id],m.logits.data[this.entailment_id]]):d.push(m.logits.data[this.entailment_id])}const f=(l?d.map(_=>st(_)[1]):st(d)).map((_,p)=>[_,p]).sort((_,p)=>p[0]-_[0]);c.push({sequence:h,labels:f.map(_=>e[_[1]]),scores:f.map(_=>_[0])})}return i?c:c[0]}};a(V0,"ZeroShotClassificationPipeline");let pc=V0;const M0=class M0 extends W{constructor(t){super(t)}async _call(t,{pooling:e="none",normalize:s=!1,quantize:n=!1,precision:i="binary"}={}){const r=this.tokenizer(t,{padding:!0,truncation:!0}),l=await this.model(r);let c=l.last_hidden_state??l.logits??l.token_embeddings;if(e!=="none")if(e==="mean")c=Hx(c,r.attention_mask);else if(e==="cls")c=c.slice(null,0);else throw Error(`Pooling method '${e}' not supported.`);return s&&(c=c.normalize(2,-1)),n&&(c=Wx(c,i)),c}};a(M0,"FeatureExtractionPipeline");let mc=M0;const F0=class F0 extends W{constructor(t){super(t)}async _call(t,{pool:e=null}={}){const s=await mt(t),{pixel_values:n}=await this.processor(s),i=await this.model({pixel_values:n});let r;if(e){if(!("pooler_output"in i))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");r=i.pooler_output}else r=i.last_hidden_state??i.logits??i.image_embeds;return r}};a(F0,"ImageFeatureExtractionPipeline");let gc=F0;const T0=class T0 extends W{constructor(t){super(t)}async _call(t,{topk:e=null}={}){const s=!Array.isArray(t),n=this.processor.feature_extractor.config.sampling_rate,i=await lc(t,n),r=this.model.config.id2label,l=[];for(const c of i){const h=await this.processor(c),u=(await this.model(h)).logits[0],_=Qt(st(u.data),e).map(p=>({label:r[p[0]],score:p[1]}));e===1?l.push(..._):l.push(_)}return!s||e===1?l:l[0]}};a(T0,"AudioClassificationPipeline");let wc=T0;const P0=class P0 extends W{constructor(t){super(t)}async _call(t,e,{hypothesis_template:s="This is a sound of {}."}={}){const n=!Array.isArray(t);n&&(t=[t]);const i=e.map(d=>s.replace("{}",d)),r=this.tokenizer(i,{padding:!0,truncation:!0}),l=this.processor.feature_extractor.config.sampling_rate,c=await lc(t,l),h=[];for(const d of c){const u=await this.processor(d),f=await this.model({...r,...u}),_=st(f.logits_per_audio.data);h.push([..._].map((p,m)=>({score:p,label:e[m]})))}return n?h[0]:h}};a(P0,"ZeroShotAudioClassificationPipeline");let yc=P0;const tx=class tx extends W{constructor(t){super(t)}async _call(t,e={}){switch(this.model.config.model_type){case"whisper":return this._call_whisper(t,e);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":return this._call_wav2vec2(t,e);default:throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(t,e={}){e.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),e.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');const s=!Array.isArray(t);s&&(t=[t]);const n=this.processor.feature_extractor.config.sampling_rate,i=await lc(t,n),r=[];for(const l of i){const c=await this.processor(l),d=(await this.model(c)).logits[0],u=[];for(const _ of d)u.push(ct(_.data)[1]);const f=this.tokenizer.decode(u);r.push({text:f})}return s?r[0]:r}async _call_whisper(t,e={}){const s=e.return_timestamps??!1,n=e.chunk_length_s??0,i=e.chunk_callback??null,r=e.force_full_sequences??!1;let l=e.stride_length_s??null;s==="word"&&(e.return_token_timestamps=!0);const c=gx(e,"language",null),h=gx(e,"task",null);if(c||h||s){if(e.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const g=this.tokenizer.get_decoder_prompt_ids({language:c,task:h,no_timestamps:!s});g.length>0&&(e.forced_decoder_ids=g)}const d=!Array.isArray(t);d&&(t=[t]);const u=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,f=this.processor.feature_extractor.config.hop_length,_=this.processor.feature_extractor.config.sampling_rate,p=await lc(t,_),m=[];for(const g of p){let w=[];if(n>0){if(l===null)l=n/6;else if(n<=l)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const A=_*n,b=_*l,N=A-2*b;let I=0;for(;I<g.length;){const $=g.subarray(I,I+A),G=await this.processor($),L=I===0,Y=I+N>=g.length;w.push({stride:[$.length,L?0:b,Y?0:b],input_features:G.input_features,is_last:Y}),I+=N}}else w=[{stride:[g.length,0,0],input_features:(await this.processor(g)).input_features,is_last:!0}];for(const A of w){e.num_frames=Math.floor(A.stride[0]/f);const b=await this.model.generate(A.input_features,e);s==="word"?(A.tokens=b.sequences[0],A.token_timestamps=b.token_timestamps.tolist()[0].map(N=>Tt(N,2))):A.tokens=b[0],A.stride=A.stride.map(N=>N/_),i!==null&&i(A)}const[y,k]=this.tokenizer._decode_asr(w,{time_precision:u,return_timestamps:s,force_full_sequences:r});m.push({text:y,...k})}return d?m[0]:m}};a(tx,"AutomaticSpeechRecognitionPipeline");let xc=tx;const ex=class ex extends W{constructor(t){super(t)}async _call(t,e={}){const s=Array.isArray(t),n=await mt(t),{pixel_values:i}=await this.processor(n),r=[];for(const l of i){l.dims=[1,...l.dims];const c=await this.model.generate(l,e),h=this.tokenizer.batch_decode(c,{skip_special_tokens:!0}).map(d=>({generated_text:d.trim()}));r.push(h)}return s?r:r[0]}};a(ex,"ImageToTextPipeline");let bc=ex;const sx=class sx extends W{constructor(t){super(t)}async _call(t,{topk:e=1}={}){const s=Array.isArray(t),n=await mt(t),{pixel_values:i}=await this.processor(n),r=await this.model({pixel_values:i}),l=this.model.config.id2label,c=[];for(const h of r.logits){const u=Qt(st(h.data),e).map(f=>({label:l[f[0]],score:f[1]}));e===1?c.push(...u):c.push(u)}return s||e===1?c:c[0]}};a(sx,"ImageClassificationPipeline");let kc=sx;const nx=class nx extends W{constructor(t){super(t),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(t,{threshold:e=.5,mask_threshold:s=.5,overlap_mask_area_threshold:n=.8,label_ids_to_fuse:i=null,target_sizes:r=null,subtask:l=null}={}){if(Array.isArray(t)&&t.length!==1)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const h=await mt(t),d=h.map(w=>[w.height,w.width]),{pixel_values:u,pixel_mask:f}=await this.processor(h),_=await this.model({pixel_values:u,pixel_mask:f});let p=null;if(l!==null)p=this.subtasks_mapping[l];else for(let[w,y]of Object.entries(this.subtasks_mapping))if(y in this.processor.feature_extractor){p=this.processor.feature_extractor[y].bind(this.processor.feature_extractor),l=w;break}const m=this.model.config.id2label,g=[];if(l==="panoptic"||l==="instance"){const w=p(_,e,s,n,i,r??d)[0],y=w.segmentation;for(const k of w.segments_info){const A=new Uint8ClampedArray(y.data.length);for(let N=0;N<y.data.length;++N)y.data[N]===k.id&&(A[N]=255);const b=new yt(A,y.dims[1],y.dims[0],1);g.push({score:k.score,label:m[k.label_id],mask:b})}}else if(l==="semantic"){const{segmentation:w,labels:y}=p(_,r??d)[0];for(const k of y){const A=new Uint8ClampedArray(w.data.length);for(let N=0;N<w.data.length;++N)w.data[N]===k&&(A[N]=255);const b=new yt(A,w.dims[1],w.dims[0],1);g.push({score:null,label:m[k],mask:b})}}else throw Error(`Subtask ${l} not supported.`);return g}};a(nx,"ImageSegmentationPipeline");let vc=nx;const ix=class ix extends W{constructor(t){super(t)}async _call(t,e,{hypothesis_template:s="This is a photo of {}"}={}){const n=Array.isArray(t),i=await mt(t),r=e.map(f=>s.replace("{}",f)),l=this.tokenizer(r,{padding:this.model.config.model_type==="siglip"?"max_length":!0,truncation:!0}),{pixel_values:c}=await this.processor(i),h=await this.model({...l,pixel_values:c}),d=this.model.config.model_type==="siglip"?f=>f.sigmoid().data:f=>st(f.data),u=[];for(const f of h.logits_per_image){const p=[...d(f)].map((m,g)=>({score:m,label:e[g]}));p.sort((m,g)=>g.score-m.score),u.push(p)}return n?u:u[0]}};a(ix,"ZeroShotImageClassificationPipeline");let Ac=ix;const ax=class ax extends W{constructor(t){super(t)}async _call(t,{threshold:e=.9,percentage:s=!1}={}){const n=Array.isArray(t);if(n&&t.length!==1)throw Error("Object detection pipeline currently only supports a batch size of 1.");const i=await mt(t),r=s?null:i.map(_=>[_.height,_.width]),{pixel_values:l,pixel_mask:c}=await this.processor(i),h=await this.model({pixel_values:l,pixel_mask:c}),d=this.processor.feature_extractor.post_process_object_detection(h,e,r),u=this.model.config.id2label,f=d.map(_=>_.boxes.map((p,m)=>({score:_.scores[m],label:u[_.classes[m]],box:Eb(p,!s)})));return n?f:f[0]}};a(ax,"ObjectDetectionPipeline");let Ec=ax;const rx=class rx extends W{constructor(t){super(t)}async _call(t,e,{threshold:s=.1,topk:n=null,percentage:i=!1}={}){const r=Array.isArray(t),l=await mt(t),c=this.tokenizer(e,{padding:!0,truncation:!0}),h=await this.processor(l),d=[];for(let u=0;u<l.length;++u){const f=l[u],_=i?null:[[f.height,f.width]],p=h.pixel_values[u].unsqueeze_(0),m=await this.model({...c,pixel_values:p}),g=this.processor.feature_extractor.post_process_object_detection(m,s,_,!0)[0];let w=g.boxes.map((y,k)=>({score:g.scores[k],label:e[g.classes[k]],box:Eb(y,!i)})).sort((y,k)=>k.score-y.score);n!==null&&(w=w.slice(0,n)),d.push(w)}return r?d:d[0]}};a(rx,"ZeroShotObjectDetectionPipeline");let Nc=rx;const ox=class ox extends W{constructor(t){super(t)}async _call(t,e,s={}){const n=(await mt(t))[0],{pixel_values:i}=await this.processor(n),r=`<s_docvqa><s_question>${e}</s_question><s_answer>`,l=this.tokenizer(r,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,c=await this.model.generate(i,{...s,decoder_input_ids:l,max_length:this.model.config.decoder.max_position_embeddings}),d=this.tokenizer.batch_decode(c)[0].match(/<s_answer>(.*?)<\/s_answer>/);let u=null;return d&&d.length>=2&&(u=d[1].trim()),[{answer:u}]}};a(ox,"DocumentQuestionAnsweringPipeline");let Ic=ox;const lx=class lx extends W{constructor(e){super(e);E(this,"DEFAULT_VOCODER_ID","Xenova/speecht5_hifigan");this.vocoder=e.vocoder??null}async _call(e,{speaker_embeddings:s=null}={}){return this.processor?this._call_text_to_spectrogram(e,{speaker_embeddings:s}):this._call_text_to_waveform(e)}async _call_text_to_waveform(e){const s=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:n}=await this.model(s),i=this.model.config.sampling_rate;return{audio:n.data,sampling_rate:i}}async _call_text_to_spectrogram(e,{speaker_embeddings:s}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await At.from_pretrained(this.DEFAULT_VOCODER_ID,{quantized:!1})),(typeof s=="string"||s instanceof URL)&&(s=new Float32Array(await(await fetch(s)).arrayBuffer())),s instanceof Float32Array)s=new v("float32",s,[1,s.length]);else if(!(s instanceof v))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:n}=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:i}=await this.model.generate_speech(n,s,{vocoder:this.vocoder}),r=this.processor.feature_extractor.config.sampling_rate;return{audio:i.data,sampling_rate:r}}};a(lx,"TextToAudioPipeline");let Oc=lx;const cx=class cx extends W{constructor(t){super(t)}async _call(t){const e=await mt(t),s=await this.processor(e),n=await this.model(s),i=[];for(const r of n.reconstruction){const l=r.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");i.push(yt.fromTensor(l))}return i.length>1?i:i[0]}};a(cx,"ImageToImagePipeline");let zc=cx;const hx=class hx extends W{constructor(t){super(t)}async _call(t){const e=await mt(t),s=await this.processor(e),{predicted_depth:n}=await this.model(s),i=[];for(let r=0;r<e.length;++r){const l=ne(n[r],e[r].size.reverse(),"bilinear",!1),c=l.mul_(255/ct(l.data)[0]).to("uint8");i.push({predicted_depth:n[r],depth:yt.fromTensor(c)})}return i.length>1?i:i[0]}};a(hx,"DepthEstimationPipeline");let Sc=hx;const Nx=Object.freeze({"text-classification":{tokenizer:Z,pipeline:cc,model:zs,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:Z,pipeline:hc,model:ol,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:Z,pipeline:dc,model:_l,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:Z,pipeline:uc,model:ul,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:Z,pipeline:_c,model:Pt,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:Z,pipeline:Ds,model:Pt,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:Z,pipeline:fe,model:Pt,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:Z,pipeline:fc,model:dl,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:Z,pipeline:pc,model:zs,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:wc,model:bl,processor:tt,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:Z,pipeline:yc,model:At,processor:tt,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:Z,pipeline:xc,model:[ll,xl],processor:tt,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:Z,pipeline:Oc,model:[hl,cl],processor:[tt,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:Z,pipeline:bc,model:fl,processor:tt,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:kc,model:pl,processor:tt,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:vc,model:[ml,gl],processor:tt,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:Z,pipeline:Ac,model:At,processor:tt,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:Ec,model:wl,processor:tt,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:Z,pipeline:Nc,model:yl,processor:tt,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:Z,pipeline:Ic,model:kl,processor:tt,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:zc,model:vl,processor:tt,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:Sc,model:Al,processor:tt,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:Z,pipeline:mc,model:At,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:tt,pipeline:gc,model:[El,At],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),jk=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function $k(o,t=null,{quantized:e=!0,progress_callback:s=null,config:n=null,cache_dir:i=null,local_files_only:r=!1,revision:l="main",model_file_name:c=null}={}){o=jk[o]??o;const h=Nx[o.split("_",1)[0]];if(!h)throw Error(`Unsupported pipeline: ${o}. Must be one of [${Object.keys(Nx)}]`);t||(t=h.default.model,console.log(`No model specified. Using default model: "${t}".`));const d={quantized:e,progress_callback:s,config:n,cache_dir:i,local_files_only:r,revision:l,model_file_name:c},u=new Map([["tokenizer",h.tokenizer],["model",h.model],["processor",h.processor]]),f=await Rk(u,t,d);f.task=o,Ft(s,{status:"ready",task:o,model:t});const _=h.pipeline;return new _(f)}a($k,"pipeline");async function Rk(o,t,e){const s=Object.create(null),n=[];for(let[i,r]of o.entries()){if(!r)continue;let l;Array.isArray(r)?l=new Promise(async(c,h)=>{let d;for(let u of r){if(u===null){c(null);return}try{c(await u.from_pretrained(t,e));return}catch(f){d=f}}h(d)}):l=r.from_pretrained(t,e),s[i]=l,n.push(l)}await Promise.all(n);for(let[i,r]of Object.entries(s))s[i]=await r;return s}a(Rk,"loadItems");typeof globalThis<"u"&&(globalThis.ONNX=globalThis.ONNX||{env:{}});const Lk=Object.freeze(Object.defineProperty({__proto__:null,ASTFeatureExtractor:tc,ASTForAudioClassification:Ua,ASTModel:Ra,ASTPreTrainedModel:Be,AlbertForMaskedLM:ta,AlbertForQuestionAnswering:Pi,AlbertForSequenceClassification:Ti,AlbertModel:Fi,AlbertPreTrainedModel:Wt,AlbertTokenizer:nn,AudioClassificationPipeline:wc,AutoConfig:gt,AutoModel:At,AutoModelForAudioClassification:bl,AutoModelForAudioFrameClassification:Od,AutoModelForCTC:xl,AutoModelForCausalLM:dl,AutoModelForDepthEstimation:Al,AutoModelForDocumentQuestionAnswering:kl,AutoModelForImageClassification:pl,AutoModelForImageFeatureExtraction:El,AutoModelForImageMatting:zd,AutoModelForImageSegmentation:ml,AutoModelForImageToImage:vl,AutoModelForMaskGeneration:Nd,AutoModelForMaskedLM:ul,AutoModelForObjectDetection:wl,AutoModelForQuestionAnswering:_l,AutoModelForSemanticSegmentation:gl,AutoModelForSeq2SeqLM:Pt,AutoModelForSequenceClassification:zs,AutoModelForSpeechSeq2Seq:ll,AutoModelForTextToSpectrogram:cl,AutoModelForTextToWaveform:hl,AutoModelForTokenClassification:ol,AutoModelForVision2Seq:fl,AutoModelForXVector:Id,AutoModelForZeroShotObjectDetection:yl,AutoProcessor:tt,AutoTokenizer:Z,AutomaticSpeechRecognitionPipeline:xc,BartForConditionalGeneration:la,BartForSequenceClassification:ca,BartModel:oa,BartPretrainedModel:re,BartTokenizer:gn,BaseModelOutput:bd,BeitFeatureExtractor:Wl,BeitForImageClassification:$r,BeitModel:jr,BeitPreTrainedModel:ls,BertForMaskedLM:Zn,BertForQuestionAnswering:Mn,BertForSequenceClassification:Qn,BertForTokenClassification:Vn,BertModel:Jn,BertPreTrainedModel:It,BertTokenizer:sn,BitImageProcessor:$l,BlenderbotForConditionalGeneration:pa,BlenderbotModel:fa,BlenderbotPreTrainedModel:Ge,BlenderbotSmallForConditionalGeneration:ga,BlenderbotSmallModel:ma,BlenderbotSmallPreTrainedModel:qe,BlenderbotSmallTokenizer:qn,BlenderbotTokenizer:$e,BloomForCausalLM:ur,BloomModel:dr,BloomPreTrainedModel:Pe,BloomTokenizer:xn,CLIPFeatureExtractor:Ul,CLIPModel:Ga,CLIPPreTrainedModel:Jt,CLIPSegForImageSegmentation:Ja,CLIPSegModel:Ya,CLIPSegPreTrainedModel:Ke,CLIPTextModelWithProjection:qa,CLIPTokenizer:Un,CLIPVisionModelWithProjection:Ba,CamembertForMaskedLM:pi,CamembertForQuestionAnswering:wi,CamembertForSequenceClassification:mi,CamembertForTokenClassification:gi,CamembertModel:fi,CamembertPreTrainedModel:jt,CamembertTokenizer:_n,CausalLMOutput:wt,CausalLMOutputWithPast:Sd,ChineseCLIPFeatureExtractor:Dl,ChineseCLIPModel:Wa,ChineseCLIPPreTrainedModel:Ka,ClapAudioModelWithProjection:tl,ClapFeatureExtractor:ec,ClapModel:To,ClapPreTrainedModel:de,ClapTextModelWithProjection:Po,CodeGenForCausalLM:ir,CodeGenModel:nr,CodeGenPreTrainedModel:Ve,CodeGenTokenizer:Rn,CodeLlamaTokenizer:bn,CohereTokenizer:Cn,ConvBertForMaskedLM:ai,ConvBertForQuestionAnswering:li,ConvBertForSequenceClassification:ri,ConvBertForTokenClassification:oi,ConvBertModel:ii,ConvBertPreTrainedModel:zt,ConvBertTokenizer:hn,ConvNextFeatureExtractor:js,ConvNextForImageClassification:no,ConvNextImageProcessor:Gl,ConvNextModel:so,ConvNextPreTrainedModel:gs,ConvNextV2ForImageClassification:ao,ConvNextV2Model:io,ConvNextV2PreTrainedModel:ws,DPTFeatureExtractor:Ss,DPTForDepthEstimation:Vr,DPTImageProcessor:jl,DPTModel:Qr,DPTPreTrainedModel:ps,DebertaForMaskedLM:xi,DebertaForQuestionAnswering:vi,DebertaForSequenceClassification:bi,DebertaForTokenClassification:ki,DebertaModel:yi,DebertaPreTrainedModel:$t,DebertaTokenizer:on,DebertaV2ForMaskedLM:Ei,DebertaV2ForQuestionAnswering:Oi,DebertaV2ForSequenceClassification:Ni,DebertaV2ForTokenClassification:Ii,DebertaV2Model:Ai,DebertaV2PreTrainedModel:Rt,DebertaV2Tokenizer:ln,DeiTFeatureExtractor:Kl,DeiTForImageClassification:Xr,DeiTModel:Hr,DeiTPreTrainedModel:ds,DepthAnythingForDepthEstimation:Fr,DepthAnythingPreTrainedModel:Mr,DepthEstimationPipeline:Sc,DetrFeatureExtractor:Jl,DetrForObjectDetection:Ur,DetrForSegmentation:Dr,DetrModel:Rr,DetrObjectDetectionOutput:cs,DetrPreTrainedModel:oe,DetrSegmentationOutput:Lr,Dinov2ForImageClassification:oo,Dinov2Model:ro,Dinov2PreTrainedModel:ys,DistilBertForMaskedLM:Ri,DistilBertForQuestionAnswering:$i,DistilBertForSequenceClassification:Si,DistilBertForTokenClassification:ji,DistilBertModel:zi,DistilBertPreTrainedModel:Ut,DistilBertTokenizer:un,DocumentQuestionAnsweringPipeline:Ic,DonutFeatureExtractor:Us,DonutSwinModel:eo,DonutSwinPreTrainedModel:to,EfficientNetForImageClassification:rl,EfficientNetImageProcessor:Hl,EfficientNetModel:al,EfficientNetPreTrainedModel:Os,ElectraForMaskedLM:hi,ElectraForQuestionAnswering:_i,ElectraForSequenceClassification:di,ElectraForTokenClassification:ui,ElectraModel:ci,ElectraPreTrainedModel:St,ElectraTokenizer:pn,EsmForMaskedLM:Di,EsmForSequenceClassification:Li,EsmForTokenClassification:Gi,EsmModel:Ui,EsmPreTrainedModel:Xt,EsmTokenizer:Nn,FFT:Ms,FalconForCausalLM:Fo,FalconModel:Mo,FalconPreTrainedModel:Es,FalconTokenizer:An,FastViTForImageClassification:xr,FastViTModel:yr,FastViTPreTrainedModel:ns,FeatureExtractionPipeline:mc,FeatureExtractor:pt,FillMaskPipeline:uc,GLPNFeatureExtractor:Rl,GLPNForDepthEstimation:Pr,GLPNModel:Tr,GLPNPreTrainedModel:ms,GPT2LMHeadModel:Qa,GPT2Model:Za,GPT2PreTrainedModel:We,GPT2Tokenizer:ze,GPTBigCodeForCausalLM:sr,GPTBigCodeModel:er,GPTBigCodePreTrainedModel:Qe,GPTJForCausalLM:tr,GPTJModel:Pa,GPTJPreTrainedModel:Ze,GPTNeoForCausalLM:Ma,GPTNeoModel:Va,GPTNeoPreTrainedModel:Ye,GPTNeoXForCausalLM:Ta,GPTNeoXModel:Fa,GPTNeoXPreTrainedModel:Je,GPTNeoXTokenizer:En,GemmaTokenizer:On,Grok1Tokenizer:zn,HerbertTokenizer:cn,HubertForCTC:Uo,HubertForSequenceClassification:Do,HubertModel:Ro,HubertPreTrainedModel:kd,ImageClassificationPipeline:kc,ImageFeatureExtractionPipeline:gc,ImageFeatureExtractor:C,ImageMattingOutput:Ol,ImageSegmentationPipeline:vc,ImageToImagePipeline:zc,ImageToTextPipeline:bc,LlamaForCausalLM:rr,LlamaModel:ar,LlamaPreTrainedModel:Me,LlamaTokenizer:je,LongT5ForConditionalGeneration:ia,LongT5Model:na,LongT5PreTrainedModel:De,M2M100ForConditionalGeneration:wo,M2M100Model:go,M2M100PreTrainedModel:ks,M2M100Tokenizer:jn,MBart50Tokenizer:wn,MBartForCausalLM:_a,MBartForConditionalGeneration:da,MBartForSequenceClassification:ua,MBartModel:ha,MBartPreTrainedModel:Yt,MBartTokenizer:Se,MPNetForMaskedLM:Ki,MPNetForQuestionAnswering:Ji,MPNetForSequenceClassification:Wi,MPNetForTokenClassification:Yi,MPNetModel:Ci,MPNetPreTrainedModel:Dt,MPNetTokenizer:vn,MT5ForConditionalGeneration:ra,MT5Model:aa,MT5PreTrainedModel:Le,MarianMTModel:mo,MarianModel:po,MarianPreTrainedModel:bs,MarianTokenizer:Ln,MaskedLMOutput:M,MistralForCausalLM:Zo,MistralModel:Jo,MistralPreTrainedModel:vs,MobileBertForMaskedLM:Bi,MobileBertForQuestionAnswering:Xi,MobileBertForSequenceClassification:Hi,MobileBertModel:qi,MobileBertPreTrainedModel:Ct,MobileBertTokenizer:an,MobileViTFeatureExtractor:$s,MobileViTForImageClassification:Ar,MobileViTImageProcessor:Xl,MobileViTModel:vr,MobileViTPreTrainedModel:is,MobileViTV2ForImageClassification:Nr,MobileViTV2Model:Er,MobileViTV2PreTrainedModel:as,ModelOutput:T,MptForCausalLM:fr,MptModel:_r,MptPreTrainedModel:ts,NllbTokenizer:Sn,NomicBertModel:Tn,NomicBertPreTrainedModel:Fn,NougatImageProcessor:Yl,NougatTokenizer:Hn,OPTForCausalLM:mr,OPTModel:pr,OPTPreTrainedModel:es,ObjectDetectionPipeline:Ec,OwlViTFeatureExtractor:Rs,OwlViTForObjectDetection:Or,OwlViTModel:Ir,OwlViTPreTrainedModel:rs,OwlViTProcessor:oc,Owlv2ForObjectDetection:Sr,Owlv2ImageProcessor:Cl,Owlv2Model:zr,Owlv2PreTrainedModel:os,PhiForCausalLM:hr,PhiModel:cr,PhiPreTrainedModel:Te,Pipeline:W,PreTrainedModel:x,PreTrainedTokenizer:O,PretrainedConfig:Kn,PretrainedMixin:H,Processor:xt,QuestionAnsweringModelOutput:P,QuestionAnsweringPipeline:dc,Qwen2ForCausalLM:lr,Qwen2Model:or,Qwen2PreTrainedModel:Fe,Qwen2Tokenizer:In,RawImage:yt,ResNetForImageClassification:Kr,ResNetModel:Cr,ResNetPreTrainedModel:us,RoFormerForMaskedLM:ti,RoFormerForQuestionAnswering:ni,RoFormerForSequenceClassification:ei,RoFormerForTokenClassification:si,RoFormerModel:Pn,RoFormerPreTrainedModel:Ot,RoFormerTokenizer:dn,RobertaForMaskedLM:ya,RobertaForQuestionAnswering:ka,RobertaForSequenceClassification:xa,RobertaForTokenClassification:ba,RobertaModel:wa,RobertaPreTrainedModel:Lt,RobertaTokenizer:yn,SamImageProcessor:Ql,SamImageSegmentationOutput:fo,SamModel:_o,SamPreTrainedModel:uo,SamProcessor:nc,SeamlessM4TFeatureExtractor:Pl,SegformerFeatureExtractor:Sl,SegformerForImageClassification:sl,SegformerForSemanticSegmentation:nl,SegformerModel:Ad,SegformerPreTrainedModel:ue,Seq2SeqLMOutput:Nl,SequenceClassifierOutput:j,SiglipImageProcessor:Ll,SiglipModel:Ha,SiglipPreTrainedModel:Ce,SiglipTextModel:Xa,SiglipTokenizer:Dn,SiglipVisionModel:Ca,SpeechT5FeatureExtractor:sc,SpeechT5ForSpeechToText:Xo,SpeechT5ForTextToSpeech:Co,SpeechT5HifiGan:Ko,SpeechT5Model:vd,SpeechT5PreTrainedModel:he,SpeechT5Processor:rc,SpeechT5Tokenizer:Bn,SqueezeBertForMaskedLM:Qi,SqueezeBertForQuestionAnswering:Mi,SqueezeBertForSequenceClassification:Vi,SqueezeBertModel:Zi,SqueezeBertPreTrainedModel:Kt,SqueezeBertTokenizer:rn,StableLmForCausalLM:il,StableLmModel:Ed,StableLmPreTrainedModel:Is,Starcoder2ForCausalLM:Vo,Starcoder2Model:Qo,Starcoder2PreTrainedModel:As,SummarizationPipeline:_c,Swin2SRForImageSuperResolution:Zr,Swin2SRImageProcessor:Vl,Swin2SRModel:Jr,Swin2SRPreTrainedModel:fs,SwinForImageClassification:Yr,SwinModel:Wr,SwinPreTrainedModel:_s,T5ForConditionalGeneration:sa,T5Model:ea,T5PreTrainedModel:Ue,T5Tokenizer:mn,TableTransformerForObjectDetection:qr,TableTransformerModel:Gr,TableTransformerObjectDetectionOutput:Br,TableTransformerPreTrainedModel:hs,Tensor:v,Text2TextGenerationPipeline:fe,TextClassificationPipeline:cc,TextGenerationPipeline:fc,TextToAudioPipeline:Oc,TokenClassificationPipeline:hc,TokenClassifierOutput:V,TokenizerModel:Et,TrOCRForCausalLM:Yo,TrOCRPreTrainedModel:Wo,TranslationPipeline:Ds,UniSpeechForCTC:Ao,UniSpeechForSequenceClassification:Eo,UniSpeechModel:vo,UniSpeechPreTrainedModel:le,UniSpeechSatForAudioFrameClassification:zo,UniSpeechSatForCTC:Io,UniSpeechSatForSequenceClassification:Oo,UniSpeechSatModel:No,UniSpeechSatPreTrainedModel:Zt,ViTFeatureExtractor:ql,ViTForImageClassification:wr,ViTImageProcessor:Bl,ViTModel:gr,ViTPreTrainedModel:ss,VisionEncoderDecoderModel:Xe,VitMatteForImageMatting:kr,VitMatteImageProcessor:Ml,VitMattePreTrainedModel:br,VitsModel:Ns,VitsModelOutput:zl,VitsPreTrainedModel:el,VitsTokenizer:Xn,Wav2Vec2BertForCTC:jo,Wav2Vec2BertForSequenceClassification:$o,Wav2Vec2BertModel:So,Wav2Vec2BertPreTrainedModel:ce,Wav2Vec2CTCTokenizer:Gn,Wav2Vec2FeatureExtractor:Tl,Wav2Vec2ForAudioFrameClassification:ko,Wav2Vec2ForCTC:xo,Wav2Vec2ForSequenceClassification:bo,Wav2Vec2Model:yo,Wav2Vec2PreTrainedModel:ft,Wav2Vec2ProcessorWithLM:ac,WavLMForAudioFrameClassification:Ho,WavLMForCTC:Go,WavLMForSequenceClassification:qo,WavLMForXVector:Bo,WavLMModel:Lo,WavLMPreTrainedModel:Bt,WhisperFeatureExtractor:Fl,WhisperForConditionalGeneration:La,WhisperModel:Da,WhisperPreTrainedModel:He,WhisperProcessor:ic,WhisperTokenizer:$n,XLMForQuestionAnswering:Ia,XLMForSequenceClassification:Ea,XLMForTokenClassification:Na,XLMModel:va,XLMPreTrainedModel:Gt,XLMRobertaForMaskedLM:za,XLMRobertaForQuestionAnswering:$a,XLMRobertaForSequenceClassification:Sa,XLMRobertaForTokenClassification:ja,XLMRobertaModel:Oa,XLMRobertaPreTrainedModel:qt,XLMRobertaTokenizer:kn,XLMTokenizer:fn,XLMWithLMHeadModel:Aa,XVectorOutput:Il,YolosFeatureExtractor:Zl,YolosForObjectDetection:co,YolosModel:lo,YolosObjectDetectionOutput:ho,YolosPreTrainedModel:xs,ZeroShotAudioClassificationPipeline:yc,ZeroShotClassificationPipeline:pc,ZeroShotImageClassificationPipeline:Ac,ZeroShotObjectDetectionPipeline:Nc,bankers_round:qx,cat:Ls,cos_sim:Kb,dot:Dx,dynamicTimeWarping:Xx,env:Q,getTopItems:Qt,hanning:jd,interpolate:ne,interpolate_data:$x,layer_norm:Yb,log_softmax:Ux,magnitude:wh,max:ct,mean:Ud,mean_pooling:Hx,medianFilter:Gx,mel_filter_bank:_e,min:$d,ones:Cx,ones_like:Kx,permute:Bx,permute_data:Rx,pipeline:$k,quantize_embeddings:Wx,read_audio:vb,round:Tt,softmax:st,spectrogram:qs,stack:Gs,std_mean:Rd,window_function:Bs},Symbol.toStringTag,{value:"Module"}));export{Sb as O,Lk as t};
